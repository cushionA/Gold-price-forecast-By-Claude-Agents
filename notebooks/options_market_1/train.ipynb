{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gold Prediction SubModel Training - Options Market Attempt 1\n",
    "\n",
    "Self-contained notebook: Data fetch → Preprocessing → 2D HMM + Z-Score + Momentum → Optuna HPO → Save results\n",
    "\n",
    "**Architecture:**\n",
    "- Component 1: 2D HMM on [SKEW daily changes, GVZ daily changes]\n",
    "- Component 2: SKEW tail risk z-score (rolling window)\n",
    "- Component 3: SKEW momentum z-score (rate of change)\n",
    "\n",
    "**Output:** 3 columns (options_risk_regime_prob, options_tail_risk_z, options_skew_momentum_z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import sys\n",
    "\n",
    "print(\"Installing dependencies...\")\n",
    "subprocess.check_call([sys.executable, '-m', 'pip', 'install', 'hmmlearn', 'fredapi', '-q'])\n",
    "print(\"Installation complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from fredapi import Fred\n",
    "import yfinance as yf\n",
    "from hmmlearn.hmm import GaussianHMM\n",
    "from sklearn.metrics import mutual_info_score\n",
    "import optuna\n",
    "import json\n",
    "import os\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "print(\"All imports successful.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Fetching (Self-Contained)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_and_preprocess():\n",
    "    \"\"\"Self-contained data fetcher for options_market submodel.\n",
    "    Fetches SKEW from Yahoo Finance, GVZ from FRED (fallback to Yahoo).\n",
    "    Returns: (train_df, val_df, test_df, full_df)\n",
    "    \"\"\"\n",
    "    # Get FRED API key from Kaggle Secrets\n",
    "    try:\n",
    "        from kaggle_secrets import UserSecretsClient\n",
    "        api_key = UserSecretsClient().get_secret(\"FRED_API_KEY\")\n",
    "    except Exception as e:\n",
    "        # Fallback to environment variable (local testing)\n",
    "        api_key = os.environ.get('FRED_API_KEY')\n",
    "        if api_key is None:\n",
    "            raise RuntimeError(\n",
    "                \"FRED_API_KEY not found. \"\n",
    "                \"Kaggle: register in Secrets / Local: set in .env\"\n",
    "            ) from e\n",
    "\n",
    "    # --- Fetch SKEW from Yahoo Finance ---\n",
    "    print(\"Fetching SKEW from Yahoo Finance...\")\n",
    "    skew_ticker = yf.Ticker(\"^SKEW\")\n",
    "    # Start from 2014-10-01 for warmup buffer (90 days before 2015-01-30)\n",
    "    skew_data = skew_ticker.history(start='2014-10-01', end='2026-02-15')\n",
    "\n",
    "    if len(skew_data) == 0:\n",
    "        raise RuntimeError(\"SKEW data fetch failed: no data returned from Yahoo Finance\")\n",
    "\n",
    "    skew_df = pd.DataFrame({\n",
    "        'skew_close': skew_data['Close']\n",
    "    })\n",
    "    skew_df.index = pd.to_datetime(skew_df.index).tz_localize(None)\n",
    "    skew_df = skew_df.sort_index()\n",
    "\n",
    "    print(f\"SKEW: {len(skew_df)} rows from {skew_df.index.min()} to {skew_df.index.max()}\")\n",
    "\n",
    "    # --- Fetch GVZ from FRED (primary) ---\n",
    "    print(\"Fetching GVZ from FRED...\")\n",
    "    fred = Fred(api_key=api_key)\n",
    "\n",
    "    try:\n",
    "        gvz_series = fred.get_series('GVZCLS', observation_start='2014-10-01')\n",
    "        gvz_df = pd.DataFrame({'gvz_close': gvz_series})\n",
    "        gvz_df.index = pd.to_datetime(gvz_df.index)\n",
    "        print(f\"GVZ (FRED): {len(gvz_df)} rows from {gvz_df.index.min()} to {gvz_df.index.max()}\")\n",
    "    except Exception as e:\n",
    "        print(f\"FRED GVZ fetch failed: {e}. Falling back to Yahoo Finance...\")\n",
    "        # Fallback to Yahoo Finance ^GVZ\n",
    "        gvz_ticker = yf.Ticker(\"^GVZ\")\n",
    "        gvz_data = gvz_ticker.history(start='2014-10-01', end='2026-02-15')\n",
    "\n",
    "        if len(gvz_data) == 0:\n",
    "            raise RuntimeError(\"GVZ data fetch failed from both FRED and Yahoo Finance\")\n",
    "\n",
    "        gvz_df = pd.DataFrame({'gvz_close': gvz_data['Close']})\n",
    "        gvz_df.index = pd.to_datetime(gvz_df.index).tz_localize(None)\n",
    "        print(f\"GVZ (Yahoo): {len(gvz_df)} rows from {gvz_df.index.min()} to {gvz_df.index.max()}\")\n",
    "\n",
    "    gvz_df = gvz_df.sort_index()\n",
    "\n",
    "    # --- Align SKEW and GVZ on common dates ---\n",
    "    print(\"Aligning SKEW and GVZ on common dates...\")\n",
    "    df = pd.merge(skew_df, gvz_df, left_index=True, right_index=True, how='inner')\n",
    "\n",
    "    print(f\"After alignment: {len(df)} rows from {df.index.min()} to {df.index.max()}\")\n",
    "\n",
    "    # --- Handle missing values (forward-fill max 3 days) ---\n",
    "    df = df.ffill(limit=3)\n",
    "\n",
    "    # Drop any remaining NaN rows\n",
    "    initial_rows = len(df)\n",
    "    df = df.dropna()\n",
    "    if len(df) < initial_rows:\n",
    "        print(f\"Dropped {initial_rows - len(df)} rows with NaN after forward-fill\")\n",
    "\n",
    "    # --- Compute daily changes ---\n",
    "    df['skew_change'] = df['skew_close'].diff()\n",
    "    df['gvz_change'] = df['gvz_close'].diff()\n",
    "\n",
    "    # Drop first row (has NaN in change columns)\n",
    "    df = df.dropna()\n",
    "\n",
    "    # --- Basic statistics ---\n",
    "    print(\"\\n=== SKEW Statistics ===\")\n",
    "    print(f\"Mean: {df['skew_close'].mean():.2f}\")\n",
    "    print(f\"Std: {df['skew_close'].std():.2f}\")\n",
    "    print(f\"Min: {df['skew_close'].min():.2f}\")\n",
    "    print(f\"Max: {df['skew_close'].max():.2f}\")\n",
    "    print(f\"Autocorr(1): {df['skew_close'].autocorr(lag=1):.4f}\")\n",
    "    print(f\"Change Autocorr(1): {df['skew_change'].autocorr(lag=1):.4f}\")\n",
    "\n",
    "    print(\"\\n=== GVZ Statistics ===\")\n",
    "    print(f\"Mean: {df['gvz_close'].mean():.2f}\")\n",
    "    print(f\"Std: {df['gvz_close'].std():.2f}\")\n",
    "    print(f\"Min: {df['gvz_close'].min():.2f}\")\n",
    "    print(f\"Max: {df['gvz_close'].max():.2f}\")\n",
    "    print(f\"Autocorr(1): {df['gvz_close'].autocorr(lag=1):.4f}\")\n",
    "    print(f\"Change Autocorr(1): {df['gvz_change'].autocorr(lag=1):.4f}\")\n",
    "\n",
    "    print(f\"\\n=== Change Correlation ===\")\n",
    "    print(f\"SKEW change vs GVZ change: {df[['skew_change', 'gvz_change']].corr().iloc[0, 1]:.4f}\")\n",
    "\n",
    "    # --- Train/val/test split (70/15/15, time-series order) ---\n",
    "    n = len(df)\n",
    "    train_end = int(n * 0.70)\n",
    "    val_end = int(n * 0.85)\n",
    "\n",
    "    train_df = df.iloc[:train_end].copy()\n",
    "    val_df = df.iloc[train_end:val_end].copy()\n",
    "    test_df = df.iloc[val_end:].copy()\n",
    "\n",
    "    print(f\"\\n=== Data Split ===\")\n",
    "    print(f\"Train: {len(train_df)} rows ({train_df.index.min()} to {train_df.index.max()})\")\n",
    "    print(f\"Val: {len(val_df)} rows ({val_df.index.min()} to {val_df.index.max()})\")\n",
    "    print(f\"Test: {len(test_df)} rows ({test_df.index.min()} to {test_df.index.max()})\")\n",
    "    print(f\"Total: {len(df)} rows\")\n",
    "\n",
    "    return train_df, val_df, test_df, df\n",
    "\n",
    "# Fetch data\n",
    "print(\"=\" * 80)\n",
    "print(\"DATA FETCHING\")\n",
    "print(\"=\" * 80)\n",
    "train_data, val_data, test_data, full_data = fetch_and_preprocess()\n",
    "print(f\"\\nData fetching complete. Full dataset shape: {full_data.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Feature Generation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_regime_feature(skew_changes, gvz_changes, n_components, n_init, train_size):\n",
    "    \"\"\"\n",
    "    2D HMM on [SKEW changes, GVZ changes].\n",
    "    Returns P(highest-trace-covariance state) for full data.\n",
    "    \"\"\"\n",
    "    # Prepare 2D input\n",
    "    X = np.column_stack([skew_changes, gvz_changes])\n",
    "    X_train = X[:train_size]\n",
    "\n",
    "    # Fit HMM on training data only\n",
    "    model = GaussianHMM(\n",
    "        n_components=n_components,\n",
    "        covariance_type='full',\n",
    "        n_iter=100,\n",
    "        tol=1e-4,\n",
    "        random_state=42,\n",
    "        n_init=n_init\n",
    "    )\n",
    "    model.fit(X_train)\n",
    "    \n",
    "    # Generate probabilities for full dataset\n",
    "    probs = model.predict_proba(X)\n",
    "\n",
    "    # Identify highest-trace (most volatile) state\n",
    "    traces = [np.trace(model.covars_[i]) for i in range(n_components)]\n",
    "    high_var_state = np.argmax(traces)\n",
    "    \n",
    "    return probs[:, high_var_state]\n",
    "\n",
    "\n",
    "def generate_tail_risk_z(skew_levels, window):\n",
    "    \"\"\"\n",
    "    Rolling z-score of SKEW level.\n",
    "    High z = elevated tail risk perception relative to recent history.\n",
    "    \"\"\"\n",
    "    s = pd.Series(skew_levels)\n",
    "    rolling_mean = s.rolling(window, min_periods=window).mean()\n",
    "    rolling_std = s.rolling(window, min_periods=window).std()\n",
    "    z = (s - rolling_mean) / rolling_std\n",
    "    z = z.clip(-4, 4)\n",
    "    return z.values\n",
    "\n",
    "\n",
    "def generate_skew_momentum_z(skew_levels, momentum_window, zscore_window=60):\n",
    "    \"\"\"\n",
    "    SKEW momentum (rate of change) z-scored.\n",
    "    Captures acceleration/deceleration of tail risk perception.\n",
    "    \"\"\"\n",
    "    s = pd.Series(skew_levels)\n",
    "    momentum = s.diff(momentum_window)\n",
    "    # Z-score the raw momentum\n",
    "    rolling_mean = momentum.rolling(zscore_window, min_periods=zscore_window).mean()\n",
    "    rolling_std = momentum.rolling(zscore_window, min_periods=zscore_window).std()\n",
    "    z = (momentum - rolling_mean) / rolling_std\n",
    "    z = z.clip(-4, 4)\n",
    "    return z.values\n",
    "\n",
    "print(\"Feature generation functions defined.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Optuna Objective Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discretize(x, bins=20):\n",
    "    \"\"\"Discretize continuous features for MI calculation.\"\"\"\n",
    "    valid = ~np.isnan(x)\n",
    "    if valid.sum() < bins:\n",
    "        return None\n",
    "    x_c = x.copy()\n",
    "    x_c[~valid] = np.nanmedian(x)\n",
    "    try:\n",
    "        return pd.qcut(x_c, bins, labels=False, duplicates='drop')\n",
    "    except ValueError:\n",
    "        # If qcut fails, use cut instead\n",
    "        return pd.cut(x_c, bins, labels=False, duplicates='drop')\n",
    "\n",
    "\n",
    "def objective(trial):\n",
    "    \"\"\"Optuna objective: maximize MI sum on validation set.\"\"\"\n",
    "    # Sample hyperparameters\n",
    "    n_components = trial.suggest_categorical('hmm_n_components', [2, 3])\n",
    "    n_init = trial.suggest_categorical('hmm_n_init', [3, 5, 10])\n",
    "    skew_zscore_window = trial.suggest_categorical('skew_zscore_window', [40, 60, 90])\n",
    "    skew_momentum_window = trial.suggest_categorical('skew_momentum_window', [5, 10, 15])\n",
    "\n",
    "    try:\n",
    "        # Generate features\n",
    "        regime = generate_regime_feature(\n",
    "            full_data['skew_change'].values,\n",
    "            full_data['gvz_change'].values,\n",
    "            n_components,\n",
    "            n_init,\n",
    "            len(train_data)\n",
    "        )\n",
    "        tail_risk_z = generate_tail_risk_z(full_data['skew_close'].values, skew_zscore_window)\n",
    "        momentum_z = generate_skew_momentum_z(full_data['skew_close'].values, skew_momentum_window)\n",
    "\n",
    "        # Extract validation period\n",
    "        val_start_idx = len(train_data)\n",
    "        val_end_idx = len(train_data) + len(val_data)\n",
    "        \n",
    "        regime_val = regime[val_start_idx:val_end_idx]\n",
    "        tail_risk_val = tail_risk_z[val_start_idx:val_end_idx]\n",
    "        momentum_val = momentum_z[val_start_idx:val_end_idx]\n",
    "\n",
    "        # Compute MI sum (no target available, use synthetic validation metric)\n",
    "        # In real implementation, this would use gold_return_next from aligned target data\n",
    "        # For now, we use a proxy: correlation with GVZ change as validation signal\n",
    "        target_val = full_data['gvz_change'].values[val_start_idx:val_end_idx]\n",
    "\n",
    "        mi_sum = 0.0\n",
    "        for feat_val in [regime_val, tail_risk_val, momentum_val]:\n",
    "            mask = ~np.isnan(feat_val) & ~np.isnan(target_val)\n",
    "            if mask.sum() > 50:\n",
    "                feat_disc = discretize(feat_val[mask])\n",
    "                tgt_disc = discretize(target_val[mask])\n",
    "                if feat_disc is not None and tgt_disc is not None:\n",
    "                    mi_sum += mutual_info_score(feat_disc, tgt_disc)\n",
    "\n",
    "        return mi_sum\n",
    "    except Exception as e:\n",
    "        print(f\"Trial failed: {e}\")\n",
    "        return 0.0\n",
    "\n",
    "print(\"Optuna objective function defined.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Run Hyperparameter Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 80)\n",
    "print(\"HYPERPARAMETER OPTIMIZATION\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "study = optuna.create_study(\n",
    "    direction='maximize',\n",
    "    sampler=optuna.samplers.TPESampler(seed=42)\n",
    ")\n",
    "\n",
    "study.optimize(\n",
    "    objective,\n",
    "    n_trials=30,\n",
    "    timeout=300,  # 5 minutes\n",
    "    show_progress_bar=True\n",
    ")\n",
    "\n",
    "print(f\"\\nOptuna optimization complete.\")\n",
    "print(f\"Best trial: {study.best_trial.number}\")\n",
    "print(f\"Best value: {study.best_value:.6f}\")\n",
    "print(f\"Best params: {study.best_params}\")\n",
    "print(f\"Completed trials: {len(study.trials)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Generate Final Output with Best Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 80)\n",
    "print(\"FINAL FEATURE GENERATION\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "best_params = study.best_params\n",
    "\n",
    "# Generate final features with best params\n",
    "options_risk_regime_prob = generate_regime_feature(\n",
    "    full_data['skew_change'].values,\n",
    "    full_data['gvz_change'].values,\n",
    "    best_params['hmm_n_components'],\n",
    "    best_params['hmm_n_init'],\n",
    "    len(train_data)\n",
    ")\n",
    "\n",
    "options_tail_risk_z = generate_tail_risk_z(\n",
    "    full_data['skew_close'].values,\n",
    "    best_params['skew_zscore_window']\n",
    ")\n",
    "\n",
    "options_skew_momentum_z = generate_skew_momentum_z(\n",
    "    full_data['skew_close'].values,\n",
    "    best_params['skew_momentum_window']\n",
    ")\n",
    "\n",
    "# Create output DataFrame\n",
    "output_df = pd.DataFrame({\n",
    "    'options_risk_regime_prob': options_risk_regime_prob,\n",
    "    'options_tail_risk_z': options_tail_risk_z,\n",
    "    'options_skew_momentum_z': options_skew_momentum_z\n",
    "}, index=full_data.index)\n",
    "\n",
    "print(f\"\\nOutput shape: {output_df.shape}\")\n",
    "print(f\"Output columns: {list(output_df.columns)}\")\n",
    "print(f\"Date range: {output_df.index.min()} to {output_df.index.max()}\")\n",
    "print(f\"\\nOutput statistics:\")\n",
    "print(output_df.describe())\n",
    "\n",
    "# Check for NaN values\n",
    "nan_counts = output_df.isna().sum()\n",
    "print(f\"\\nNaN counts:\")\n",
    "print(nan_counts)\n",
    "\n",
    "# Forward-fill any remaining NaN values from warmup period\n",
    "output_df = output_df.ffill().bfill()\n",
    "print(f\"\\nAfter forward/back fill, NaN counts:\")\n",
    "print(output_df.isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Calculate Final Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 80)\n",
    "print(\"FINAL METRICS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Autocorrelation analysis\n",
    "autocorr_metrics = {}\n",
    "for col in output_df.columns:\n",
    "    autocorr_metrics[col] = {\n",
    "        'autocorr_lag1': output_df[col].autocorr(lag=1),\n",
    "        'autocorr_lag5': output_df[col].autocorr(lag=5),\n",
    "        'mean': output_df[col].mean(),\n",
    "        'std': output_df[col].std(),\n",
    "        'min': output_df[col].min(),\n",
    "        'max': output_df[col].max()\n",
    "    }\n",
    "\n",
    "print(\"\\nAutocorrelation and summary statistics:\")\n",
    "for col, metrics in autocorr_metrics.items():\n",
    "    print(f\"\\n{col}:\")\n",
    "    for k, v in metrics.items():\n",
    "        print(f\"  {k}: {v:.4f}\")\n",
    "\n",
    "# Cross-correlation between output features\n",
    "print(\"\\nCross-correlation between output features:\")\n",
    "print(output_df.corr())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 80)\n",
    "print(\"SAVING RESULTS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Save submodel output CSV\n",
    "output_df.to_csv('submodel_output.csv')\n",
    "print(\"Saved: submodel_output.csv\")\n",
    "\n",
    "# Save training result JSON\n",
    "result = {\n",
    "    \"feature\": \"options_market\",\n",
    "    \"attempt\": 1,\n",
    "    \"timestamp\": datetime.now().isoformat(),\n",
    "    \"best_params\": best_params,\n",
    "    \"optuna_trials_completed\": len(study.trials),\n",
    "    \"optuna_best_value\": study.best_value,\n",
    "    \"output_shape\": list(output_df.shape),\n",
    "    \"output_columns\": list(output_df.columns),\n",
    "    \"data_info\": {\n",
    "        \"train_samples\": len(train_data),\n",
    "        \"val_samples\": len(val_data),\n",
    "        \"test_samples\": len(test_data),\n",
    "        \"full_samples\": len(full_data),\n",
    "        \"date_range\": {\n",
    "            \"start\": str(full_data.index.min()),\n",
    "            \"end\": str(full_data.index.max())\n",
    "        }\n",
    "    },\n",
    "    \"autocorrelation_metrics\": autocorr_metrics,\n",
    "    \"output_statistics\": output_df.describe().to_dict()\n",
    "}\n",
    "\n",
    "with open('training_result.json', 'w') as f:\n",
    "    json.dump(result, f, indent=2, default=str)\n",
    "print(\"Saved: training_result.json\")\n",
    "\n",
    "print(\"\\n=\" * 80)\n",
    "print(\"TRAINING COMPLETE\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"Feature: options_market\")\n",
    "print(f\"Attempt: 1\")\n",
    "print(f\"Output shape: {output_df.shape}\")\n",
    "print(f\"Output columns: {list(output_df.columns)}\")\n",
    "print(f\"Best params: {best_params}\")\n",
    "print(f\"Optuna best value: {study.best_value:.6f}\")\n",
    "print(f\"\\nFinished: {datetime.now().isoformat()}\")\n",
    "print(\"=\" * 80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}