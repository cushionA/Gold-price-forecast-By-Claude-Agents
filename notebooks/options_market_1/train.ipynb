{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gold Prediction SubModel Training - Options Market Attempt 1\n",
    "\n",
    "Self-contained: Data fetch -> Preprocessing -> HMM + Z-Score + Momentum -> Optuna HPO -> Save results\n",
    "\n",
    "**Data Sources**: Yahoo Finance ONLY (no FRED dependency)\n",
    "- SKEW: ^SKEW (Yahoo)\n",
    "- GVZ: ^GVZ (Yahoo)\n",
    "\n",
    "**Output**: 3 columns\n",
    "- options_risk_regime_prob: HMM regime probability\n",
    "- options_tail_risk_z: SKEW z-score\n",
    "- options_skew_momentum_z: SKEW momentum z-score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === 1. Libraries ===\n",
    "import subprocess\n",
    "subprocess.check_call(['pip', 'install', 'hmmlearn'])\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "from hmmlearn.hmm import GaussianHMM\n",
    "from sklearn.metrics import mutual_info_score\n",
    "import optuna\n",
    "import json\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === 2. Data Fetching ===\n",
    "print(\"Fetching data...\")\n",
    "\n",
    "# Fetch SKEW from Yahoo Finance\n",
    "skew_ticker = yf.Ticker('^SKEW')\n",
    "skew_data = skew_ticker.history(start='2014-10-01', end='2025-02-15')\n",
    "skew_close = skew_data['Close']\n",
    "print(f\"SKEW data: {len(skew_close)} rows\")\n",
    "\n",
    "# Fetch GVZ from Yahoo Finance\n",
    "gvz_ticker = yf.Ticker('^GVZ')\n",
    "gvz_data = gvz_ticker.history(start='2014-10-01', end='2025-02-15')\n",
    "gvz_close = gvz_data['Close']\n",
    "print(f\"GVZ data: {len(gvz_close)} rows\")\n",
    "\n",
    "# Fetch Gold for target variable\n",
    "gold_ticker = yf.Ticker('GC=F')\n",
    "gold_data = gold_ticker.history(start='2014-10-01', end='2025-02-15')\n",
    "gold_close = gold_data['Close']\n",
    "gold_return = gold_close.pct_change() * 100\n",
    "gold_return_next = gold_return.shift(-1)\n",
    "print(f\"Gold data: {len(gold_close)} rows\")\n",
    "\n",
    "# Align on common dates (merge on index)\n",
    "df = pd.DataFrame({\n",
    "    'skew': skew_close,\n",
    "    'gvz': gvz_close\n",
    "})\n",
    "df = df.join(gold_return_next.to_frame(name=\"gold_return_next\"), how=\"inner\")\n",
    "\n",
    "# Forward-fill gaps up to 3 days\n",
    "df = df.ffill(limit=3)\n",
    "df = df.dropna()\n",
    "\n",
    "print(f\"Aligned data: {len(df)} rows\")\n",
    "print(f\"Date range: {df.index[0]} to {df.index[-1]}\")\n",
    "print(f\"SKEW range: [{df[\"skew\"].min():.2f}, {df[\"skew\"].max():.2f}]\")\n",
    "print(f\"GVZ range: [{df[\"gvz\"].min():.2f}, {df[\"gvz\"].max():.2f}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === 3. Compute Changes ===\n",
    "df['skew_change'] = df['skew'].diff()\n",
    "df['gvz_change'] = df['gvz'].diff()\n",
    "\n",
    "# Drop initial NaN from diff\n",
    "df = df.dropna()\n",
    "\n",
    "print(f\"After computing changes: {len(df)} rows\")\n",
    "print(f\"SKEW change range: [{df['skew_change'].min():.2f}, {df['skew_change'].max():.2f}]\")\n",
    "print(f\"GVZ change range: [{df['gvz_change'].min():.2f}, {df['gvz_change'].max():.2f}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === 4. Data Split ===\n",
    "# train/val/test = 70/15/15 (time-series order)\n",
    "n = len(df)\n",
    "train_size = int(n * 0.70)\n",
    "val_size = int(n * 0.15)\n",
    "test_size = n - train_size - val_size\n",
    "\n",
    "train_mask = np.zeros(n, dtype=bool)\n",
    "train_mask[:train_size] = True\n",
    "\n",
    "val_mask = np.zeros(n, dtype=bool)\n",
    "val_mask[train_size:train_size+val_size] = True\n",
    "\n",
    "test_mask = np.zeros(n, dtype=bool)\n",
    "test_mask[train_size+val_size:] = True\n",
    "\n",
    "print(f\"Train: {train_size} rows\")\n",
    "print(f\"Val: {val_size} rows\")\n",
    "print(f\"Test: {test_size} rows\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === 5. Feature Generation Functions ===\n",
    "\n",
    "def generate_regime_feature(skew_changes, gvz_changes, n_components, train_size):\n",
    "    \"\"\"\n",
    "    2D HMM on [SKEW changes, GVZ changes].\n",
    "    Returns P(highest-trace-covariance state) for full data.\n",
    "    \"\"\"\n",
    "    X = np.column_stack([skew_changes, gvz_changes])\n",
    "    X_train = X[:train_size]\n",
    "    model = GaussianHMM(\n",
    "        n_components=n_components,\n",
    "        covariance_type='full',\n",
    "        n_iter=100,\n",
    "        tol=1e-4,\n",
    "        random_state=42\n",
    "    )\n",
    "    model.fit(X_train)\n",
    "    probs = model.predict_proba(X)\n",
    "    # Identify highest-trace (most volatile) state\n",
    "    traces = [np.trace(model.covars_[i]) for i in range(n_components)]\n",
    "    high_var_state = np.argmax(traces)\n",
    "    return probs[:, high_var_state]\n",
    "\n",
    "def generate_tail_risk_z(skew_levels, window):\n",
    "    \"\"\"\n",
    "    Rolling z-score of SKEW level.\n",
    "    High z = elevated tail risk perception relative to recent history.\n",
    "    \"\"\"\n",
    "    s = pd.Series(skew_levels)\n",
    "    rolling_mean = s.rolling(window, min_periods=window).mean()\n",
    "    rolling_std = s.rolling(window, min_periods=window).std()\n",
    "    z = (s - rolling_mean) / rolling_std\n",
    "    z = z.clip(-4, 4)\n",
    "    return z.values\n",
    "\n",
    "def generate_skew_momentum_z(skew_levels, momentum_window, zscore_window=60):\n",
    "    \"\"\"\n",
    "    SKEW momentum (rate of change) z-scored.\n",
    "    Captures acceleration/deceleration of tail risk perception.\n",
    "    \"\"\"\n",
    "    s = pd.Series(skew_levels)\n",
    "    momentum = s.diff(momentum_window)\n",
    "    # Z-score the raw momentum\n",
    "    rolling_mean = momentum.rolling(zscore_window, min_periods=zscore_window).mean()\n",
    "    rolling_std = momentum.rolling(zscore_window, min_periods=zscore_window).std()\n",
    "    z = (momentum - rolling_mean) / rolling_std\n",
    "    z = z.clip(-4, 4)\n",
    "    return z.values\n",
    "\n",
    "print(\"Feature generation functions defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === 6. Optuna Objective ===\n",
    "\n",
    "def objective(trial):\n",
    "    n_components = trial.suggest_categorical('hmm_n_components', [2, 3])\n",
    "    skew_zscore_window = trial.suggest_categorical('skew_zscore_window', [40, 60, 90])\n",
    "    skew_momentum_window = trial.suggest_categorical('skew_momentum_window', [5, 10, 15])\n",
    "    \n",
    "    try:\n",
    "        # Generate features\n",
    "        regime = generate_regime_feature(\n",
    "            df['skew_change'].values,\n",
    "            df['gvz_change'].values,\n",
    "            n_components,\n",
    "            train_size\n",
    "        )\n",
    "        tail_risk_z = generate_tail_risk_z(df['skew'].values, skew_zscore_window)\n",
    "        momentum_z = generate_skew_momentum_z(df['skew'].values, skew_momentum_window)\n",
    "        \n",
    "        # Extract validation period\n",
    "        regime_val = regime[val_mask]\n",
    "        tail_risk_val = tail_risk_z[val_mask]\n",
    "        momentum_val = momentum_z[val_mask]\n",
    "        target_val = df['gold_return_next'].values[val_mask]\n",
    "        \n",
    "        # Compute MI sum\n",
    "        def discretize(x, bins=20):\n",
    "            valid = ~np.isnan(x)\n",
    "            if valid.sum() < bins:\n",
    "                return None\n",
    "            x_c = x.copy()\n",
    "            x_c[~valid] = np.nanmedian(x)\n",
    "            return pd.qcut(x_c, bins, labels=False, duplicates='drop')\n",
    "        \n",
    "        mi_sum = 0.0\n",
    "        for feat_val in [regime_val, tail_risk_val, momentum_val]:\n",
    "            mask = ~np.isnan(feat_val) & ~np.isnan(target_val)\n",
    "            if mask.sum() > 50:\n",
    "                feat_disc = discretize(feat_val[mask])\n",
    "                tgt_disc = discretize(target_val[mask])\n",
    "                if feat_disc is not None and tgt_disc is not None:\n",
    "                    mi_sum += mutual_info_score(feat_disc, tgt_disc)\n",
    "        \n",
    "        return mi_sum\n",
    "    except Exception as e:\n",
    "        print(f\"Trial failed: {e}\")\n",
    "        return 0.0\n",
    "\n",
    "print(\"Optuna objective defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === 7. Run Optuna HPO ===\n",
    "print(\"Running Optuna HPO...\")\n",
    "\n",
    "study = optuna.create_study(\n",
    "    direction='maximize',\n",
    "    sampler=optuna.samplers.TPESampler(seed=42)\n",
    ")\n",
    "\n",
    "study.optimize(objective, n_trials=30, timeout=300)\n",
    "\n",
    "print(f\"Best trial: {study.best_trial.number}\")\n",
    "print(f\"Best value: {study.best_value:.6f}\")\n",
    "print(f\"Best params: {study.best_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === 8. Generate Final Output with Best Params ===\n",
    "print(\"Generating final output with best params...\")\n",
    "\n",
    "best_params = study.best_params\n",
    "\n",
    "regime_final = generate_regime_feature(\n",
    "    df['skew_change'].values,\n",
    "    df['gvz_change'].values,\n",
    "    best_params['hmm_n_components'],\n",
    "    train_size\n",
    ")\n",
    "\n",
    "tail_risk_z_final = generate_tail_risk_z(\n",
    "    df['skew'].values,\n",
    "    best_params['skew_zscore_window']\n",
    ")\n",
    "\n",
    "momentum_z_final = generate_skew_momentum_z(\n",
    "    df['skew'].values,\n",
    "    best_params['skew_momentum_window']\n",
    ")\n",
    "\n",
    "# Create output DataFrame\n",
    "output = pd.DataFrame({\n",
    "    'options_risk_regime_prob': regime_final,\n",
    "    'options_tail_risk_z': tail_risk_z_final,\n",
    "    'options_skew_momentum_z': momentum_z_final\n",
    "}, index=df.index)\n",
    "\n",
    "# Forward-fill NaN values from warmup period\n",
    "output = output.fillna(method='ffill')\n",
    "\n",
    "print(f\"Output shape: {output.shape}\")\n",
    "print(f\"Output columns: {list(output.columns)}\")\n",
    "print(f\"NaN counts: {output.isna().sum().to_dict()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === 9. Compute Metrics ===\n",
    "print(\"Computing metrics...\")\n",
    "\n",
    "# Autocorrelation on test set\n",
    "test_output = output[test_mask]\n",
    "autocorr = {\n",
    "    col: test_output[col].autocorr(lag=1)\n",
    "    for col in output.columns\n",
    "}\n",
    "\n",
    "# MI on validation set\n",
    "def compute_mi(feature, target, bins=20):\n",
    "    mask = ~np.isnan(feature) & ~np.isnan(target)\n",
    "    if mask.sum() < bins:\n",
    "        return 0.0\n",
    "    feat_disc = pd.qcut(feature[mask], bins, labels=False, duplicates='drop')\n",
    "    tgt_disc = pd.qcut(target[mask], bins, labels=False, duplicates='drop')\n",
    "    return mutual_info_score(feat_disc, tgt_disc)\n",
    "\n",
    "val_output = output[val_mask]\n",
    "target_val = df['gold_return_next'].values[val_mask]\n",
    "\n",
    "mi_scores = {\n",
    "    col: compute_mi(val_output[col].values, target_val)\n",
    "    for col in output.columns\n",
    "}\n",
    "\n",
    "print(f\"Autocorrelation (lag 1): {autocorr}\")\n",
    "print(f\"MI scores (validation): {mi_scores}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === 10. Save Results ===\n",
    "print(\"Saving results...\")\n",
    "\n",
    "# Save submodel output\n",
    "output.to_csv('submodel_output.csv')\n",
    "\n",
    "# Save training result JSON\n",
    "result = {\n",
    "    'feature': 'options_market',\n",
    "    'attempt': 1,\n",
    "    'timestamp': datetime.now().isoformat(),\n",
    "    'best_params': best_params,\n",
    "    'optuna_trials_completed': len(study.trials),\n",
    "    'optuna_best_value': study.best_value,\n",
    "    'output_shape': list(output.shape),\n",
    "    'output_columns': list(output.columns),\n",
    "    'data_info': {\n",
    "        'train_samples': train_size,\n",
    "        'val_samples': val_size,\n",
    "        'test_samples': test_size,\n",
    "        'full_samples': len(df)\n",
    "    },\n",
    "    'metrics': {\n",
    "        'autocorr_lag1': autocorr,\n",
    "        'mi_scores_validation': mi_scores\n",
    "    }\n",
    "}\n",
    "\n",
    "with open('training_result.json', 'w') as f:\n",
    "    json.dump(result, f, indent=2, default=str)\n",
    "\n",
    "print(\"=== Training complete! ===\")\n",
    "print(f\"Finished: {datetime.now().isoformat()}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}