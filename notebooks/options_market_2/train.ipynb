{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gold Prediction SubModel Training - Options Market Attempt 2\n",
    "\n",
    "**Self-contained training notebook**: Data fetch → Preprocessing → HMM Regime Detection → Optuna HPO → Save results\n",
    "\n",
    "## Key Changes from Attempt 1\n",
    "\n",
    "- **Output reduced from 3 columns to 1**: Only `options_risk_regime_prob` is retained\n",
    "- **Dropped features**: `options_tail_risk_z` (MI=0.002, noise) and `options_skew_momentum_z` (MI=0.017, marginal)\n",
    "- **Optuna objective**: Single-column MI (not sum of 3)\n",
    "- **Added parameter**: `input_scaling` to optionally standardize HMM inputs\n",
    "\n",
    "## Architecture\n",
    "\n",
    "- 2D HMM on [SKEW daily changes, GVZ daily changes]\n",
    "- Output: P(highest-variance regime) in [0, 1]\n",
    "- Optuna search space: n_components (2-3), input_scaling (True/False)\n",
    "- 30 trials, 5 minute timeout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import sys\n",
    "\n",
    "print(\"Installing hmmlearn...\")\n",
    "subprocess.check_call([sys.executable, '-m', 'pip', 'install', 'hmmlearn', '--quiet'])\n",
    "print(\"hmmlearn installed successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "from hmmlearn.hmm import GaussianHMM\n",
    "from sklearn.metrics import mutual_info_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import optuna\n",
    "import json\n",
    "import os\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "print(\"All libraries imported successfully\")\n",
    "print(f\"Execution started: {datetime.now().isoformat()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Fetching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_data():\n",
    "    \"\"\"\n",
    "    Fetch SKEW, GVZ, and Gold price data.\n",
    "    Returns aligned DataFrame with daily changes.\n",
    "    \"\"\"\n",
    "    print(\"\\n=== Fetching Data ===\")\n",
    "    \n",
    "    # Date range: 2014-10-01 to 2025-02-15 (includes warmup buffer)\n",
    "    start_date = '2014-10-01'\n",
    "    end_date = '2025-02-15'\n",
    "    \n",
    "    # 1. Fetch SKEW from Yahoo Finance\n",
    "    print(\"Fetching SKEW Index (^SKEW)...\")\n",
    "    try:\n",
    "        skew_ticker = yf.Ticker('^SKEW')\n",
    "        skew_data = skew_ticker.history(start=start_date, end=end_date, auto_adjust=True)\n",
    "        if skew_data.empty:\n",
    "            raise ValueError(\"SKEW data is empty\")\n",
    "        skew_df = skew_data[['Close']].rename(columns={'Close': 'skew_close'})\n",
    "        print(f\"  SKEW: {len(skew_df)} rows fetched, range {skew_df.index.min()} to {skew_df.index.max()}\")\n",
    "    except Exception as e:\n",
    "        print(f\"  ERROR fetching SKEW: {e}\")\n",
    "        raise\n",
    "    \n",
    "    # 2. Fetch GVZ from Yahoo Finance (primary, no FRED dependency)\n",
    "    print(\"Fetching Gold Volatility Index (^GVZ)...\")\n",
    "    try:\n",
    "        gvz_ticker = yf.Ticker('^GVZ')\n",
    "        gvz_data = gvz_ticker.history(start=start_date, end=end_date, auto_adjust=True)\n",
    "        if gvz_data.empty:\n",
    "            raise ValueError(\"GVZ data is empty\")\n",
    "        gvz_df = gvz_data[['Close']].rename(columns={'Close': 'gvz_close'})\n",
    "        print(f\"  GVZ: {len(gvz_df)} rows fetched, range {gvz_df.index.min()} to {gvz_df.index.max()}\")\n",
    "    except Exception as e:\n",
    "        print(f\"  ERROR fetching GVZ: {e}\")\n",
    "        raise\n",
    "    \n",
    "    # 3. Fetch Gold price (GC=F) for target variable\n",
    "    print(\"Fetching Gold futures (GC=F)...\")\n",
    "    try:\n",
    "        gold_ticker = yf.Ticker('GC=F')\n",
    "        gold_data = gold_ticker.history(start=start_date, end=end_date, auto_adjust=True)\n",
    "        if gold_data.empty:\n",
    "            raise ValueError(\"Gold data is empty\")\n",
    "        gold_df = gold_data[['Close']].rename(columns={'Close': 'gold_close'})\n",
    "        print(f\"  Gold: {len(gold_df)} rows fetched, range {gold_df.index.min()} to {gold_df.index.max()}\")\n",
    "    except Exception as e:\n",
    "        print(f\"  ERROR fetching Gold: {e}\")\n",
    "        raise\n",
    "    \n",
    "    # 4. Align data on common dates (inner join)\n",
    "    print(\"\\nAligning data on common dates...\")\n",
    "    df = skew_df.join(gvz_df, how='inner').join(gold_df, how='inner')\n",
    "    print(f\"  Aligned: {len(df)} rows\")\n",
    "    \n",
    "    # 5. Forward-fill gaps up to 3 days\n",
    "    print(\"Forward-filling gaps (max 3 days)...\")\n",
    "    df = df.ffill(limit=3)\n",
    "    \n",
    "    # 6. Compute daily changes\n",
    "    print(\"Computing daily changes...\")\n",
    "    df['skew_change'] = df['skew_close'].diff()\n",
    "    df['gvz_change'] = df['gvz_close'].diff()\n",
    "    df['gold_return'] = df['gold_close'].pct_change() * 100  # Percentage return\n",
    "    \n",
    "    # 7. Create target: next-day gold return\n",
    "    df['gold_return_next'] = df['gold_return'].shift(-1)\n",
    "    \n",
    "    # 8. Drop NaN rows from diff operations\n",
    "    df = df.dropna(subset=['skew_change', 'gvz_change', 'gold_return_next'])\n",
    "    \n",
    "    print(f\"\\nFinal dataset: {len(df)} rows\")\n",
    "    print(f\"Date range: {df.index.min()} to {df.index.max()}\")\n",
    "    print(f\"\\nData summary:\")\n",
    "    print(df[['skew_close', 'gvz_close', 'skew_change', 'gvz_change']].describe())\n",
    "    \n",
    "    # Quality checks\n",
    "    print(\"\\n=== Data Quality Checks ===\")\n",
    "    print(f\"SKEW range: [{df['skew_close'].min():.1f}, {df['skew_close'].max():.1f}]\")\n",
    "    print(f\"GVZ range: [{df['gvz_close'].min():.1f}, {df['gvz_close'].max():.1f}]\")\n",
    "    print(f\"SKEW change std: {df['skew_change'].std():.2f}\")\n",
    "    print(f\"GVZ change std: {df['gvz_change'].std():.2f}\")\n",
    "    print(f\"Missing data: {df[['skew_change', 'gvz_change']].isna().sum().sum()} cells\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Fetch data\n",
    "data = fetch_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Data Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time-series split: 70/15/15 (train/val/test)\n",
    "n = len(data)\n",
    "train_size = int(n * 0.70)\n",
    "val_size = int(n * 0.15)\n",
    "test_size = n - train_size - val_size\n",
    "\n",
    "train_end = train_size\n",
    "val_end = train_size + val_size\n",
    "\n",
    "# Create masks\n",
    "train_mask = np.arange(train_size)\n",
    "val_mask = np.arange(train_size, val_end)\n",
    "test_mask = np.arange(val_end, n)\n",
    "\n",
    "print(f\"\\n=== Data Split ===\")\n",
    "print(f\"Total samples: {n}\")\n",
    "print(f\"Train: {len(train_mask)} samples ({train_mask[0]} to {train_mask[-1]})\")\n",
    "print(f\"Val:   {len(val_mask)} samples ({val_mask[0]} to {val_mask[-1]})\")\n",
    "print(f\"Test:  {len(test_mask)} samples ({test_mask[0]} to {test_mask[-1]})\")\n",
    "print(f\"\\nDate ranges:\")\n",
    "print(f\"Train: {data.index[train_mask[0]]} to {data.index[train_mask[-1]]}\")\n",
    "print(f\"Val:   {data.index[val_mask[0]]} to {data.index[val_mask[-1]]}\")\n",
    "print(f\"Test:  {data.index[test_mask[0]]} to {data.index[test_mask[-1]]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Feature Generation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_regime_feature(data, n_components, train_size, input_scaling=False):\n",
    "    \"\"\"\n",
    "    Generate regime probability feature using 2D HMM.\n",
    "    \n",
    "    Args:\n",
    "        data: DataFrame with skew_change and gvz_change columns\n",
    "        n_components: number of HMM states (2 or 3)\n",
    "        train_size: index for train/val split (fit HMM on train only)\n",
    "        input_scaling: whether to standardize inputs before HMM fit\n",
    "    \n",
    "    Returns:\n",
    "        regime_prob: array of P(highest-variance state) for full dataset\n",
    "    \"\"\"\n",
    "    # Extract 2D input: [skew_change, gvz_change]\n",
    "    X = data[['skew_change', 'gvz_change']].values\n",
    "    \n",
    "    # Optional input scaling\n",
    "    if input_scaling:\n",
    "        scaler = StandardScaler()\n",
    "        X_train = X[:train_size]\n",
    "        scaler.fit(X_train)\n",
    "        X = scaler.transform(X)\n",
    "    \n",
    "    # Split into train portion for HMM fitting\n",
    "    X_train = X[:train_size]\n",
    "    \n",
    "    # Fit HMM on training data only\n",
    "    # Note: hmmlearn 0.3.3 does NOT support n_init parameter\n",
    "    # We'll fit once with fixed random_state for reproducibility\n",
    "    model = GaussianHMM(\n",
    "        n_components=n_components,\n",
    "        covariance_type='full',\n",
    "        n_iter=100,\n",
    "        tol=1e-4,\n",
    "        random_state=42\n",
    "    )\n",
    "    \n",
    "    model.fit(X_train)\n",
    "    \n",
    "    # Generate probabilities for full dataset\n",
    "    probs = model.predict_proba(X)\n",
    "    \n",
    "    # Identify highest-variance state (highest trace of covariance matrix)\n",
    "    traces = [np.trace(model.covars_[i]) for i in range(n_components)]\n",
    "    high_var_state = np.argmax(traces)\n",
    "    \n",
    "    # Return P(high-variance state)\n",
    "    regime_prob = probs[:, high_var_state]\n",
    "    \n",
    "    return regime_prob\n",
    "\n",
    "print(\"Feature generation function defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Optuna Objective Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discretize(x, bins=20):\n",
    "    \"\"\"\n",
    "    Discretize continuous feature into quantile bins for MI calculation.\n",
    "    \"\"\"\n",
    "    valid = ~np.isnan(x)\n",
    "    if valid.sum() < bins:\n",
    "        return None\n",
    "    \n",
    "    x_c = x.copy()\n",
    "    x_c[~valid] = np.nanmedian(x)\n",
    "    \n",
    "    return pd.qcut(x_c, bins, labels=False, duplicates='drop')\n",
    "\n",
    "\n",
    "def objective(trial):\n",
    "    \"\"\"\n",
    "    Optuna objective: Maximize MI between regime_prob and gold_return_next on validation set.\n",
    "    \"\"\"\n",
    "    # Hyperparameters\n",
    "    n_components = trial.suggest_categorical('hmm_n_components', [2, 3])\n",
    "    input_scaling = trial.suggest_categorical('input_scaling', [True, False])\n",
    "    \n",
    "    try:\n",
    "        # Generate regime feature\n",
    "        regime = generate_regime_feature(\n",
    "            data, \n",
    "            n_components=n_components,\n",
    "            train_size=train_size,\n",
    "            input_scaling=input_scaling\n",
    "        )\n",
    "        \n",
    "        # Extract validation portion\n",
    "        regime_val = regime[val_mask]\n",
    "        target_val = data['gold_return_next'].values[val_mask]\n",
    "        \n",
    "        # Remove NaN values\n",
    "        mask = ~np.isnan(regime_val) & ~np.isnan(target_val)\n",
    "        if mask.sum() < 50:\n",
    "            return 0.0\n",
    "        \n",
    "        # Discretize for MI calculation\n",
    "        feat_disc = discretize(regime_val[mask])\n",
    "        tgt_disc = discretize(target_val[mask])\n",
    "        \n",
    "        if feat_disc is not None and tgt_disc is not None:\n",
    "            mi = mutual_info_score(feat_disc, tgt_disc)\n",
    "            return mi\n",
    "        \n",
    "        return 0.0\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Trial failed: {e}\")\n",
    "        return 0.0\n",
    "\n",
    "print(\"Optuna objective function defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Run Optuna HPO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n=== Running Optuna Hyperparameter Optimization ===\")\n",
    "print(\"Objective: Maximize MI(regime_prob, gold_return_next) on validation set\")\n",
    "print(\"Search space:\")\n",
    "print(\"  hmm_n_components: [2, 3]\")\n",
    "print(\"  input_scaling: [True, False]\")\n",
    "print(\"Trials: 30\")\n",
    "print(\"Timeout: 300 seconds (5 minutes)\")\n",
    "print()\n",
    "\n",
    "# Create study\n",
    "study = optuna.create_study(\n",
    "    direction='maximize',\n",
    "    sampler=optuna.samplers.TPESampler(seed=42)\n",
    ")\n",
    "\n",
    "# Run optimization\n",
    "study.optimize(objective, n_trials=30, timeout=300)\n",
    "\n",
    "# Results\n",
    "print(\"\\n=== Optuna Results ===\")\n",
    "print(f\"Completed trials: {len(study.trials)}\")\n",
    "print(f\"Best value (MI): {study.best_value:.6f}\")\n",
    "print(f\"Best params: {study.best_params}\")\n",
    "\n",
    "best_params = study.best_params\n",
    "best_value = study.best_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Generate Final Output with Best Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n=== Generating Final Submodel Output ===\")\n",
    "print(f\"Using best parameters: {best_params}\")\n",
    "\n",
    "# Generate regime feature with best parameters\n",
    "regime_prob = generate_regime_feature(\n",
    "    data,\n",
    "    n_components=best_params['hmm_n_components'],\n",
    "    train_size=train_size,\n",
    "    input_scaling=best_params['input_scaling']\n",
    ")\n",
    "\n",
    "# Create output DataFrame\n",
    "output = pd.DataFrame({\n",
    "    'options_risk_regime_prob': regime_prob\n",
    "}, index=data.index)\n",
    "\n",
    "print(f\"\\nOutput shape: {output.shape}\")\n",
    "print(f\"Output columns: {list(output.columns)}\")\n",
    "print(f\"\\nOutput statistics:\")\n",
    "print(output.describe())\n",
    "print(f\"\\nAutocorrelation (lag 1): {output['options_risk_regime_prob'].autocorr(lag=1):.4f}\")\n",
    "print(f\"NaN count: {output.isna().sum().sum()}\")\n",
    "\n",
    "# Verify output quality\n",
    "assert output.shape[1] == 1, \"Output must have exactly 1 column\"\n",
    "assert output.isna().sum().sum() == 0, \"Output contains NaN values\"\n",
    "assert output['options_risk_regime_prob'].std() > 0.01, \"Output is nearly constant\"\n",
    "assert output['options_risk_regime_prob'].autocorr(lag=1) < 0.99, \"Output has excessive autocorrelation\"\n",
    "\n",
    "print(\"\\nOutput validation: PASS\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n=== Saving Results ===\")\n",
    "\n",
    "# Save submodel output CSV\n",
    "output.to_csv('submodel_output.csv')\n",
    "print(\"Saved: submodel_output.csv\")\n",
    "\n",
    "# Create training result summary\n",
    "result = {\n",
    "    \"feature\": \"options_market\",\n",
    "    \"attempt\": 2,\n",
    "    \"timestamp\": datetime.now().isoformat(),\n",
    "    \"best_params\": best_params,\n",
    "    \"optuna_trials_completed\": len(study.trials),\n",
    "    \"optuna_best_value\": float(best_value),\n",
    "    \"output_shape\": list(output.shape),\n",
    "    \"output_columns\": list(output.columns),\n",
    "    \"output_stats\": {\n",
    "        \"mean\": float(output['options_risk_regime_prob'].mean()),\n",
    "        \"std\": float(output['options_risk_regime_prob'].std()),\n",
    "        \"min\": float(output['options_risk_regime_prob'].min()),\n",
    "        \"max\": float(output['options_risk_regime_prob'].max()),\n",
    "        \"autocorr_lag1\": float(output['options_risk_regime_prob'].autocorr(lag=1))\n",
    "    },\n",
    "    \"data_info\": {\n",
    "        \"total_samples\": int(n),\n",
    "        \"train_samples\": int(len(train_mask)),\n",
    "        \"val_samples\": int(len(val_mask)),\n",
    "        \"test_samples\": int(len(test_mask)),\n",
    "        \"date_range_start\": str(data.index.min()),\n",
    "        \"date_range_end\": str(data.index.max())\n",
    "    },\n",
    "    \"design_changes_from_attempt_1\": {\n",
    "        \"output_columns\": \"Reduced from 3 to 1\",\n",
    "        \"dropped_features\": [\"options_tail_risk_z (MI=0.002)\", \"options_skew_momentum_z (MI=0.017)\"],\n",
    "        \"retained_feature\": \"options_risk_regime_prob (MI=0.031, rank #2/22)\",\n",
    "        \"optuna_objective\": \"Single-column MI (was sum of 3)\",\n",
    "        \"new_parameter\": \"input_scaling (standardize HMM inputs)\"\n",
    "    }\n",
    "}\n",
    "\n",
    "# Save JSON\n",
    "with open('training_result.json', 'w') as f:\n",
    "    json.dump(result, f, indent=2)\n",
    "print(\"Saved: training_result.json\")\n",
    "\n",
    "print(\"\\n=== Training Complete ===\")\n",
    "print(f\"Finished: {datetime.now().isoformat()}\")\n",
    "print(f\"\\nFinal summary:\")\n",
    "print(f\"  Feature: options_market\")\n",
    "print(f\"  Attempt: 2\")\n",
    "print(f\"  Output: 1 column (options_risk_regime_prob)\")\n",
    "print(f\"  Best MI: {best_value:.6f}\")\n",
    "print(f\"  Best params: {best_params}\")\n",
    "print(f\"  Data: {n} samples ({data.index.min()} to {data.index.max()})\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
