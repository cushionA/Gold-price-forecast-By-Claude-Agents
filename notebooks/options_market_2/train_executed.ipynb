{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gold Prediction SubModel Training - Options Market Attempt 2\n",
    "\n",
    "**Self-contained training notebook**: Data fetch → Preprocessing → HMM Regime Detection → Optuna HPO → Save results\n",
    "\n",
    "## Key Changes from Attempt 1\n",
    "\n",
    "- **Output reduced from 3 columns to 1**: Only `options_risk_regime_prob` is retained\n",
    "- **Dropped features**: `options_tail_risk_z` (MI=0.002, noise) and `options_skew_momentum_z` (MI=0.017, marginal)\n",
    "- **Optuna objective**: Single-column MI (not sum of 3)\n",
    "- **Added parameter**: `input_scaling` to optionally standardize HMM inputs\n",
    "\n",
    "## Architecture\n",
    "\n",
    "- 2D HMM on [SKEW daily changes, GVZ daily changes]\n",
    "- Output: P(highest-variance regime) in [0, 1]\n",
    "- Optuna search space: n_components (2-3), input_scaling (True/False)\n",
    "- 30 trials, 5 minute timeout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-17T16:31:56.002294Z",
     "iopub.status.busy": "2026-02-17T16:31:56.002113Z",
     "iopub.status.idle": "2026-02-17T16:31:57.757558Z",
     "shell.execute_reply": "2026-02-17T16:31:57.756476Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Installing hmmlearn...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hmmlearn installed successfully\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "import sys\n",
    "\n",
    "print(\"Installing hmmlearn...\")\n",
    "subprocess.check_call([sys.executable, '-m', 'pip', 'install', 'hmmlearn', '--quiet'])\n",
    "print(\"hmmlearn installed successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-17T16:31:57.759704Z",
     "iopub.status.busy": "2026-02-17T16:31:57.759449Z",
     "iopub.status.idle": "2026-02-17T16:31:59.384701Z",
     "shell.execute_reply": "2026-02-17T16:31:59.383975Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All libraries imported successfully\n",
      "Execution started: 2026-02-18T01:31:59.382131\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tatuk\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "from hmmlearn.hmm import GaussianHMM\n",
    "from sklearn.metrics import mutual_info_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import optuna\n",
    "import json\n",
    "import os\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "print(\"All libraries imported successfully\")\n",
    "print(f\"Execution started: {datetime.now().isoformat()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Fetching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-17T16:31:59.386738Z",
     "iopub.status.busy": "2026-02-17T16:31:59.386404Z",
     "iopub.status.idle": "2026-02-17T16:32:01.636844Z",
     "shell.execute_reply": "2026-02-17T16:32:01.636000Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Fetching Data ===\n",
      "Fetching SKEW Index (^SKEW)...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  SKEW: 2803 rows fetched, range 2014-10-01 00:00:00-04:00 to 2026-02-13 00:00:00-05:00\n",
      "Fetching Gold Volatility Index (^GVZ)...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  GVZ: 2861 rows fetched, range 2014-10-01 00:00:00-04:00 to 2026-02-17 00:00:00-05:00\n",
      "Fetching Gold futures (GC=F)...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Gold: 2860 rows fetched, range 2014-10-01 00:00:00-04:00 to 2026-02-17 00:00:00-05:00\n",
      "\n",
      "Aligning data on common dates...\n",
      "  Aligned: 2800 rows\n",
      "Forward-filling gaps (max 3 days)...\n",
      "Computing daily changes...\n",
      "\n",
      "Final dataset: 2798 rows\n",
      "Date range: 2014-10-02 00:00:00-04:00 to 2026-02-12 00:00:00-05:00\n",
      "\n",
      "Data summary:\n",
      "        skew_close    gvz_close  skew_change   gvz_change\n",
      "count  2798.000000  2798.000000  2798.000000  2798.000000\n",
      "mean    134.433463    16.475161     0.006909     0.004110\n",
      "std      12.125912     4.456463     3.906112     1.007897\n",
      "min     110.339996     8.880000   -22.810005    -9.500000\n",
      "25%     125.040001    13.262500    -1.810013    -0.460000\n",
      "50%     133.375000    16.155000     0.000000    -0.070000\n",
      "75%     142.295002    18.510000     1.919998     0.370000\n",
      "max     183.119995    48.980000    24.749992     7.250000\n",
      "\n",
      "=== Data Quality Checks ===\n",
      "SKEW range: [110.3, 183.1]\n",
      "GVZ range: [8.9, 49.0]\n",
      "SKEW change std: 3.91\n",
      "GVZ change std: 1.01\n",
      "Missing data: 0 cells\n"
     ]
    }
   ],
   "source": [
    "def fetch_data():\n",
    "    \"\"\"\n",
    "    Fetch SKEW, GVZ, and Gold price data.\n",
    "    Returns aligned DataFrame with daily changes.\n",
    "    \"\"\"\n",
    "    print(\"\\n=== Fetching Data ===\")\n",
    "    \n",
    "    # Date range: 2014-10-01 to today (dynamic)\n",
    "    start_date = '2014-10-01'\n",
    "    end_date = datetime.now().strftime('%Y-%m-%d')\n",
    "    \n",
    "    # 1. Fetch SKEW from Yahoo Finance\n",
    "    print(\"Fetching SKEW Index (^SKEW)...\")\n",
    "    try:\n",
    "        skew_ticker = yf.Ticker('^SKEW')\n",
    "        skew_data = skew_ticker.history(start=start_date, end=end_date, auto_adjust=True)\n",
    "        if skew_data.empty:\n",
    "            raise ValueError(\"SKEW data is empty\")\n",
    "        skew_df = skew_data[['Close']].rename(columns={'Close': 'skew_close'})\n",
    "        print(f\"  SKEW: {len(skew_df)} rows fetched, range {skew_df.index.min()} to {skew_df.index.max()}\")\n",
    "    except Exception as e:\n",
    "        print(f\"  ERROR fetching SKEW: {e}\")\n",
    "        raise\n",
    "    \n",
    "    # 2. Fetch GVZ from Yahoo Finance (primary, no FRED dependency)\n",
    "    print(\"Fetching Gold Volatility Index (^GVZ)...\")\n",
    "    try:\n",
    "        gvz_ticker = yf.Ticker('^GVZ')\n",
    "        gvz_data = gvz_ticker.history(start=start_date, end=end_date, auto_adjust=True)\n",
    "        if gvz_data.empty:\n",
    "            raise ValueError(\"GVZ data is empty\")\n",
    "        gvz_df = gvz_data[['Close']].rename(columns={'Close': 'gvz_close'})\n",
    "        print(f\"  GVZ: {len(gvz_df)} rows fetched, range {gvz_df.index.min()} to {gvz_df.index.max()}\")\n",
    "    except Exception as e:\n",
    "        print(f\"  ERROR fetching GVZ: {e}\")\n",
    "        raise\n",
    "    \n",
    "    # 3. Fetch Gold price (GC=F) for target variable\n",
    "    print(\"Fetching Gold futures (GC=F)...\")\n",
    "    try:\n",
    "        gold_ticker = yf.Ticker('GC=F')\n",
    "        gold_data = gold_ticker.history(start=start_date, end=end_date, auto_adjust=True)\n",
    "        if gold_data.empty:\n",
    "            raise ValueError(\"Gold data is empty\")\n",
    "        gold_df = gold_data[['Close']].rename(columns={'Close': 'gold_close'})\n",
    "        print(f\"  Gold: {len(gold_df)} rows fetched, range {gold_df.index.min()} to {gold_df.index.max()}\")\n",
    "    except Exception as e:\n",
    "        print(f\"  ERROR fetching Gold: {e}\")\n",
    "        raise\n",
    "    \n",
    "    # 4. Align data on common dates (inner join)\n",
    "    print(\"\\nAligning data on common dates...\")\n",
    "    df = skew_df.join(gvz_df, how='inner').join(gold_df, how='inner')\n",
    "    print(f\"  Aligned: {len(df)} rows\")\n",
    "    \n",
    "    # 5. Forward-fill gaps up to 3 days\n",
    "    print(\"Forward-filling gaps (max 3 days)...\")\n",
    "    df = df.ffill(limit=3)\n",
    "    \n",
    "    # 6. Compute daily changes\n",
    "    print(\"Computing daily changes...\")\n",
    "    df['skew_change'] = df['skew_close'].diff()\n",
    "    df['gvz_change'] = df['gvz_close'].diff()\n",
    "    df['gold_return'] = df['gold_close'].pct_change() * 100  # Percentage return\n",
    "    \n",
    "    # 7. Create target: next-day gold return\n",
    "    df['gold_return_next'] = df['gold_return'].shift(-1)\n",
    "    \n",
    "    # 8. Drop NaN rows from diff operations\n",
    "    df = df.dropna(subset=['skew_change', 'gvz_change', 'gold_return_next'])\n",
    "    \n",
    "    print(f\"\\nFinal dataset: {len(df)} rows\")\n",
    "    print(f\"Date range: {df.index.min()} to {df.index.max()}\")\n",
    "    print(f\"\\nData summary:\")\n",
    "    print(df[['skew_close', 'gvz_close', 'skew_change', 'gvz_change']].describe())\n",
    "    \n",
    "    # Quality checks\n",
    "    print(\"\\n=== Data Quality Checks ===\")\n",
    "    print(f\"SKEW range: [{df['skew_close'].min():.1f}, {df['skew_close'].max():.1f}]\")\n",
    "    print(f\"GVZ range: [{df['gvz_close'].min():.1f}, {df['gvz_close'].max():.1f}]\")\n",
    "    print(f\"SKEW change std: {df['skew_change'].std():.2f}\")\n",
    "    print(f\"GVZ change std: {df['gvz_change'].std():.2f}\")\n",
    "    print(f\"Missing data: {df[['skew_change', 'gvz_change']].isna().sum().sum()} cells\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Fetch data\n",
    "data = fetch_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Data Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-17T16:32:01.638837Z",
     "iopub.status.busy": "2026-02-17T16:32:01.638650Z",
     "iopub.status.idle": "2026-02-17T16:32:01.644402Z",
     "shell.execute_reply": "2026-02-17T16:32:01.643505Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Data Split ===\n",
      "Total samples: 2798\n",
      "Train: 1958 samples (0 to 1957)\n",
      "Val:   419 samples (1958 to 2376)\n",
      "Test:  421 samples (2377 to 2797)\n",
      "\n",
      "Date ranges:\n",
      "Train: 2014-10-02 00:00:00-04:00 to 2022-08-26 00:00:00-04:00\n",
      "Val:   2022-08-29 00:00:00-04:00 to 2024-05-24 00:00:00-04:00\n",
      "Test:  2024-05-28 00:00:00-04:00 to 2026-02-12 00:00:00-05:00\n"
     ]
    }
   ],
   "source": [
    "# Time-series split: 70/15/15 (train/val/test)\n",
    "n = len(data)\n",
    "train_size = int(n * 0.70)\n",
    "val_size = int(n * 0.15)\n",
    "test_size = n - train_size - val_size\n",
    "\n",
    "train_end = train_size\n",
    "val_end = train_size + val_size\n",
    "\n",
    "# Create masks\n",
    "train_mask = np.arange(train_size)\n",
    "val_mask = np.arange(train_size, val_end)\n",
    "test_mask = np.arange(val_end, n)\n",
    "\n",
    "print(f\"\\n=== Data Split ===\")\n",
    "print(f\"Total samples: {n}\")\n",
    "print(f\"Train: {len(train_mask)} samples ({train_mask[0]} to {train_mask[-1]})\")\n",
    "print(f\"Val:   {len(val_mask)} samples ({val_mask[0]} to {val_mask[-1]})\")\n",
    "print(f\"Test:  {len(test_mask)} samples ({test_mask[0]} to {test_mask[-1]})\")\n",
    "print(f\"\\nDate ranges:\")\n",
    "print(f\"Train: {data.index[train_mask[0]]} to {data.index[train_mask[-1]]}\")\n",
    "print(f\"Val:   {data.index[val_mask[0]]} to {data.index[val_mask[-1]]}\")\n",
    "print(f\"Test:  {data.index[test_mask[0]]} to {data.index[test_mask[-1]]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Feature Generation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-17T16:32:01.646429Z",
     "iopub.status.busy": "2026-02-17T16:32:01.646179Z",
     "iopub.status.idle": "2026-02-17T16:32:01.651196Z",
     "shell.execute_reply": "2026-02-17T16:32:01.650595Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature generation function defined\n"
     ]
    }
   ],
   "source": [
    "def generate_regime_feature(data, n_components, train_size, input_scaling=False):\n",
    "    \"\"\"\n",
    "    Generate regime probability feature using 2D HMM.\n",
    "    \n",
    "    Args:\n",
    "        data: DataFrame with skew_change and gvz_change columns\n",
    "        n_components: number of HMM states (2 or 3)\n",
    "        train_size: index for train/val split (fit HMM on train only)\n",
    "        input_scaling: whether to standardize inputs before HMM fit\n",
    "    \n",
    "    Returns:\n",
    "        regime_prob: array of P(highest-variance state) for full dataset\n",
    "    \"\"\"\n",
    "    # Extract 2D input: [skew_change, gvz_change]\n",
    "    X = data[['skew_change', 'gvz_change']].values\n",
    "    \n",
    "    # Optional input scaling\n",
    "    if input_scaling:\n",
    "        scaler = StandardScaler()\n",
    "        X_train = X[:train_size]\n",
    "        scaler.fit(X_train)\n",
    "        X = scaler.transform(X)\n",
    "    \n",
    "    # Split into train portion for HMM fitting\n",
    "    X_train = X[:train_size]\n",
    "    \n",
    "    # Fit HMM on training data only\n",
    "    # Note: hmmlearn 0.3.3 does NOT support n_init parameter\n",
    "    # We'll fit once with fixed random_state for reproducibility\n",
    "    model = GaussianHMM(\n",
    "        n_components=n_components,\n",
    "        covariance_type='full',\n",
    "        n_iter=100,\n",
    "        tol=1e-4,\n",
    "        random_state=42\n",
    "    )\n",
    "    \n",
    "    model.fit(X_train)\n",
    "    \n",
    "    # Generate probabilities for full dataset\n",
    "    probs = model.predict_proba(X)\n",
    "    \n",
    "    # Identify highest-variance state (highest trace of covariance matrix)\n",
    "    traces = [np.trace(model.covars_[i]) for i in range(n_components)]\n",
    "    high_var_state = np.argmax(traces)\n",
    "    \n",
    "    # Return P(high-variance state)\n",
    "    regime_prob = probs[:, high_var_state]\n",
    "    \n",
    "    return regime_prob\n",
    "\n",
    "print(\"Feature generation function defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Optuna Objective Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-17T16:32:01.653068Z",
     "iopub.status.busy": "2026-02-17T16:32:01.652787Z",
     "iopub.status.idle": "2026-02-17T16:32:01.657689Z",
     "shell.execute_reply": "2026-02-17T16:32:01.657202Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optuna objective function defined\n"
     ]
    }
   ],
   "source": [
    "def discretize(x, bins=20):\n",
    "    \"\"\"\n",
    "    Discretize continuous feature into quantile bins for MI calculation.\n",
    "    \"\"\"\n",
    "    valid = ~np.isnan(x)\n",
    "    if valid.sum() < bins:\n",
    "        return None\n",
    "    \n",
    "    x_c = x.copy()\n",
    "    x_c[~valid] = np.nanmedian(x)\n",
    "    \n",
    "    return pd.qcut(x_c, bins, labels=False, duplicates='drop')\n",
    "\n",
    "\n",
    "def objective(trial):\n",
    "    \"\"\"\n",
    "    Optuna objective: Maximize MI between regime_prob and gold_return_next on validation set.\n",
    "    \"\"\"\n",
    "    # Hyperparameters\n",
    "    n_components = trial.suggest_categorical('hmm_n_components', [2, 3])\n",
    "    input_scaling = trial.suggest_categorical('input_scaling', [True, False])\n",
    "    \n",
    "    try:\n",
    "        # Generate regime feature\n",
    "        regime = generate_regime_feature(\n",
    "            data, \n",
    "            n_components=n_components,\n",
    "            train_size=train_size,\n",
    "            input_scaling=input_scaling\n",
    "        )\n",
    "        \n",
    "        # Extract validation portion\n",
    "        regime_val = regime[val_mask]\n",
    "        target_val = data['gold_return_next'].values[val_mask]\n",
    "        \n",
    "        # Remove NaN values\n",
    "        mask = ~np.isnan(regime_val) & ~np.isnan(target_val)\n",
    "        if mask.sum() < 50:\n",
    "            return 0.0\n",
    "        \n",
    "        # Discretize for MI calculation\n",
    "        feat_disc = discretize(regime_val[mask])\n",
    "        tgt_disc = discretize(target_val[mask])\n",
    "        \n",
    "        if feat_disc is not None and tgt_disc is not None:\n",
    "            mi = mutual_info_score(feat_disc, tgt_disc)\n",
    "            return mi\n",
    "        \n",
    "        return 0.0\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Trial failed: {e}\")\n",
    "        return 0.0\n",
    "\n",
    "print(\"Optuna objective function defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Run Optuna HPO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-17T16:32:01.659668Z",
     "iopub.status.busy": "2026-02-17T16:32:01.659417Z",
     "iopub.status.idle": "2026-02-17T16:32:06.527790Z",
     "shell.execute_reply": "2026-02-17T16:32:06.527017Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2026-02-18 01:32:01,662]\u001b[0m A new study created in memory with name: no-name-62be12eb-cc25-44c9-a8c5-fa512dd0ddcd\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Running Optuna Hyperparameter Optimization ===\n",
      "Objective: Maximize MI(regime_prob, gold_return_next) on validation set\n",
      "Search space:\n",
      "  hmm_n_components: [2, 3]\n",
      "  input_scaling: [True, False]\n",
      "Trials: 30\n",
      "Timeout: 300 seconds (5 minutes)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2026-02-18 01:32:03,303]\u001b[0m Trial 0 finished with value: 0.5243753022959359 and parameters: {'hmm_n_components': 3, 'input_scaling': True}. Best is trial 0 with value: 0.5243753022959359.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2026-02-18 01:32:03,379]\u001b[0m Trial 1 finished with value: 0.5266649675779264 and parameters: {'hmm_n_components': 2, 'input_scaling': False}. Best is trial 1 with value: 0.5266649675779264.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2026-02-18 01:32:03,584]\u001b[0m Trial 2 finished with value: 0.48902180262307354 and parameters: {'hmm_n_components': 3, 'input_scaling': False}. Best is trial 1 with value: 0.5266649675779264.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2026-02-18 01:32:03,658]\u001b[0m Trial 3 finished with value: 0.5266649675779264 and parameters: {'hmm_n_components': 2, 'input_scaling': False}. Best is trial 1 with value: 0.5266649675779264.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2026-02-18 01:32:03,922]\u001b[0m Trial 4 finished with value: 0.5243753022959359 and parameters: {'hmm_n_components': 3, 'input_scaling': True}. Best is trial 1 with value: 0.5266649675779264.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2026-02-18 01:32:03,993]\u001b[0m Trial 5 finished with value: 0.5266649675779264 and parameters: {'hmm_n_components': 2, 'input_scaling': False}. Best is trial 1 with value: 0.5266649675779264.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2026-02-18 01:32:04,190]\u001b[0m Trial 6 finished with value: 0.48902180262307354 and parameters: {'hmm_n_components': 3, 'input_scaling': False}. Best is trial 1 with value: 0.5266649675779264.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2026-02-18 01:32:04,268]\u001b[0m Trial 7 finished with value: 0.5266649675779264 and parameters: {'hmm_n_components': 2, 'input_scaling': True}. Best is trial 1 with value: 0.5266649675779264.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2026-02-18 01:32:04,532]\u001b[0m Trial 8 finished with value: 0.5243753022959359 and parameters: {'hmm_n_components': 3, 'input_scaling': True}. Best is trial 1 with value: 0.5266649675779264.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2026-02-18 01:32:04,611]\u001b[0m Trial 9 finished with value: 0.5266649675779264 and parameters: {'hmm_n_components': 2, 'input_scaling': True}. Best is trial 1 with value: 0.5266649675779264.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2026-02-18 01:32:04,686]\u001b[0m Trial 10 finished with value: 0.5266649675779264 and parameters: {'hmm_n_components': 2, 'input_scaling': False}. Best is trial 1 with value: 0.5266649675779264.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2026-02-18 01:32:04,761]\u001b[0m Trial 11 finished with value: 0.5266649675779264 and parameters: {'hmm_n_components': 2, 'input_scaling': False}. Best is trial 1 with value: 0.5266649675779264.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2026-02-18 01:32:04,837]\u001b[0m Trial 12 finished with value: 0.5266649675779264 and parameters: {'hmm_n_components': 2, 'input_scaling': False}. Best is trial 1 with value: 0.5266649675779264.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2026-02-18 01:32:04,912]\u001b[0m Trial 13 finished with value: 0.5266649675779264 and parameters: {'hmm_n_components': 2, 'input_scaling': False}. Best is trial 1 with value: 0.5266649675779264.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2026-02-18 01:32:04,987]\u001b[0m Trial 14 finished with value: 0.5266649675779264 and parameters: {'hmm_n_components': 2, 'input_scaling': False}. Best is trial 1 with value: 0.5266649675779264.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2026-02-18 01:32:05,062]\u001b[0m Trial 15 finished with value: 0.5266649675779264 and parameters: {'hmm_n_components': 2, 'input_scaling': False}. Best is trial 1 with value: 0.5266649675779264.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2026-02-18 01:32:05,139]\u001b[0m Trial 16 finished with value: 0.5266649675779264 and parameters: {'hmm_n_components': 2, 'input_scaling': False}. Best is trial 1 with value: 0.5266649675779264.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2026-02-18 01:32:05,215]\u001b[0m Trial 17 finished with value: 0.5266649675779264 and parameters: {'hmm_n_components': 2, 'input_scaling': False}. Best is trial 1 with value: 0.5266649675779264.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2026-02-18 01:32:05,291]\u001b[0m Trial 18 finished with value: 0.5266649675779264 and parameters: {'hmm_n_components': 2, 'input_scaling': False}. Best is trial 1 with value: 0.5266649675779264.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2026-02-18 01:32:05,366]\u001b[0m Trial 19 finished with value: 0.5266649675779264 and parameters: {'hmm_n_components': 2, 'input_scaling': False}. Best is trial 1 with value: 0.5266649675779264.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2026-02-18 01:32:05,442]\u001b[0m Trial 20 finished with value: 0.5266649675779264 and parameters: {'hmm_n_components': 2, 'input_scaling': False}. Best is trial 1 with value: 0.5266649675779264.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2026-02-18 01:32:05,516]\u001b[0m Trial 21 finished with value: 0.5266649675779264 and parameters: {'hmm_n_components': 2, 'input_scaling': False}. Best is trial 1 with value: 0.5266649675779264.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2026-02-18 01:32:05,591]\u001b[0m Trial 22 finished with value: 0.5266649675779264 and parameters: {'hmm_n_components': 2, 'input_scaling': False}. Best is trial 1 with value: 0.5266649675779264.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2026-02-18 01:32:05,669]\u001b[0m Trial 23 finished with value: 0.5266649675779264 and parameters: {'hmm_n_components': 2, 'input_scaling': False}. Best is trial 1 with value: 0.5266649675779264.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2026-02-18 01:32:05,746]\u001b[0m Trial 24 finished with value: 0.5266649675779264 and parameters: {'hmm_n_components': 2, 'input_scaling': False}. Best is trial 1 with value: 0.5266649675779264.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2026-02-18 01:32:05,825]\u001b[0m Trial 25 finished with value: 0.5266649675779264 and parameters: {'hmm_n_components': 2, 'input_scaling': False}. Best is trial 1 with value: 0.5266649675779264.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2026-02-18 01:32:06,104]\u001b[0m Trial 26 finished with value: 0.5243753022959359 and parameters: {'hmm_n_components': 3, 'input_scaling': True}. Best is trial 1 with value: 0.5266649675779264.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2026-02-18 01:32:06,177]\u001b[0m Trial 27 finished with value: 0.5266649675779264 and parameters: {'hmm_n_components': 2, 'input_scaling': False}. Best is trial 1 with value: 0.5266649675779264.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2026-02-18 01:32:06,253]\u001b[0m Trial 28 finished with value: 0.5266649675779264 and parameters: {'hmm_n_components': 2, 'input_scaling': False}. Best is trial 1 with value: 0.5266649675779264.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2026-02-18 01:32:06,523]\u001b[0m Trial 29 finished with value: 0.5243753022959359 and parameters: {'hmm_n_components': 3, 'input_scaling': True}. Best is trial 1 with value: 0.5266649675779264.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Optuna Results ===\n",
      "Completed trials: 30\n",
      "Best value (MI): 0.526665\n",
      "Best params: {'hmm_n_components': 2, 'input_scaling': False}\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n=== Running Optuna Hyperparameter Optimization ===\")\n",
    "print(\"Objective: Maximize MI(regime_prob, gold_return_next) on validation set\")\n",
    "print(\"Search space:\")\n",
    "print(\"  hmm_n_components: [2, 3]\")\n",
    "print(\"  input_scaling: [True, False]\")\n",
    "print(\"Trials: 30\")\n",
    "print(\"Timeout: 300 seconds (5 minutes)\")\n",
    "print()\n",
    "\n",
    "# Create study\n",
    "study = optuna.create_study(\n",
    "    direction='maximize',\n",
    "    sampler=optuna.samplers.TPESampler(seed=42)\n",
    ")\n",
    "\n",
    "# Run optimization\n",
    "study.optimize(objective, n_trials=30, timeout=300)\n",
    "\n",
    "# Results\n",
    "print(\"\\n=== Optuna Results ===\")\n",
    "print(f\"Completed trials: {len(study.trials)}\")\n",
    "print(f\"Best value (MI): {study.best_value:.6f}\")\n",
    "print(f\"Best params: {study.best_params}\")\n",
    "\n",
    "best_params = study.best_params\n",
    "best_value = study.best_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Generate Final Output with Best Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-17T16:32:06.529799Z",
     "iopub.status.busy": "2026-02-17T16:32:06.529544Z",
     "iopub.status.idle": "2026-02-17T16:32:06.607139Z",
     "shell.execute_reply": "2026-02-17T16:32:06.606234Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Generating Final Submodel Output ===\n",
      "Using best parameters: {'hmm_n_components': 2, 'input_scaling': False}\n",
      "\n",
      "Output shape: (2798, 1)\n",
      "Output columns: ['options_risk_regime_prob']\n",
      "\n",
      "Output statistics:\n",
      "       options_risk_regime_prob\n",
      "count              2.798000e+03\n",
      "mean               2.321048e-01\n",
      "std                3.420855e-01\n",
      "min                5.840006e-12\n",
      "25%                8.321567e-03\n",
      "50%                3.586692e-02\n",
      "75%                3.260285e-01\n",
      "max                1.000000e+00\n",
      "\n",
      "Autocorrelation (lag 1): 0.8316\n",
      "NaN count: 0\n",
      "\n",
      "Output validation: PASS\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n=== Generating Final Submodel Output ===\")\n",
    "print(f\"Using best parameters: {best_params}\")\n",
    "\n",
    "# Generate regime feature with best parameters\n",
    "regime_prob = generate_regime_feature(\n",
    "    data,\n",
    "    n_components=best_params['hmm_n_components'],\n",
    "    train_size=train_size,\n",
    "    input_scaling=best_params['input_scaling']\n",
    ")\n",
    "\n",
    "# Create output DataFrame\n",
    "output = pd.DataFrame({\n",
    "    'options_risk_regime_prob': regime_prob\n",
    "}, index=data.index)\n",
    "\n",
    "print(f\"\\nOutput shape: {output.shape}\")\n",
    "print(f\"Output columns: {list(output.columns)}\")\n",
    "print(f\"\\nOutput statistics:\")\n",
    "print(output.describe())\n",
    "print(f\"\\nAutocorrelation (lag 1): {output['options_risk_regime_prob'].autocorr(lag=1):.4f}\")\n",
    "print(f\"NaN count: {output.isna().sum().sum()}\")\n",
    "\n",
    "# Verify output quality\n",
    "assert output.shape[1] == 1, \"Output must have exactly 1 column\"\n",
    "assert output.isna().sum().sum() == 0, \"Output contains NaN values\"\n",
    "assert output['options_risk_regime_prob'].std() > 0.01, \"Output is nearly constant\"\n",
    "assert output['options_risk_regime_prob'].autocorr(lag=1) < 0.99, \"Output has excessive autocorrelation\"\n",
    "\n",
    "print(\"\\nOutput validation: PASS\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-17T16:32:06.609262Z",
     "iopub.status.busy": "2026-02-17T16:32:06.608945Z",
     "iopub.status.idle": "2026-02-17T16:32:06.641691Z",
     "shell.execute_reply": "2026-02-17T16:32:06.640668Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Saving Results ===\n",
      "Saved: submodel_output.csv\n",
      "Saved: training_result.json\n",
      "\n",
      "=== Training Complete ===\n",
      "Finished: 2026-02-18T01:32:06.638892\n",
      "\n",
      "Final summary:\n",
      "  Feature: options_market\n",
      "  Attempt: 2\n",
      "  Output: 1 column (options_risk_regime_prob)\n",
      "  Best MI: 0.526665\n",
      "  Best params: {'hmm_n_components': 2, 'input_scaling': False}\n",
      "  Data: 2798 samples (2014-10-02 00:00:00-04:00 to 2026-02-12 00:00:00-05:00)\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n=== Saving Results ===\")\n",
    "\n",
    "# Save submodel output CSV\n",
    "output.to_csv('submodel_output.csv')\n",
    "print(\"Saved: submodel_output.csv\")\n",
    "\n",
    "# Create training result summary\n",
    "result = {\n",
    "    \"feature\": \"options_market\",\n",
    "    \"attempt\": 2,\n",
    "    \"timestamp\": datetime.now().isoformat(),\n",
    "    \"best_params\": best_params,\n",
    "    \"optuna_trials_completed\": len(study.trials),\n",
    "    \"optuna_best_value\": float(best_value),\n",
    "    \"output_shape\": list(output.shape),\n",
    "    \"output_columns\": list(output.columns),\n",
    "    \"output_stats\": {\n",
    "        \"mean\": float(output['options_risk_regime_prob'].mean()),\n",
    "        \"std\": float(output['options_risk_regime_prob'].std()),\n",
    "        \"min\": float(output['options_risk_regime_prob'].min()),\n",
    "        \"max\": float(output['options_risk_regime_prob'].max()),\n",
    "        \"autocorr_lag1\": float(output['options_risk_regime_prob'].autocorr(lag=1))\n",
    "    },\n",
    "    \"data_info\": {\n",
    "        \"total_samples\": int(n),\n",
    "        \"train_samples\": int(len(train_mask)),\n",
    "        \"val_samples\": int(len(val_mask)),\n",
    "        \"test_samples\": int(len(test_mask)),\n",
    "        \"date_range_start\": str(data.index.min()),\n",
    "        \"date_range_end\": str(data.index.max())\n",
    "    },\n",
    "    \"design_changes_from_attempt_1\": {\n",
    "        \"output_columns\": \"Reduced from 3 to 1\",\n",
    "        \"dropped_features\": [\"options_tail_risk_z (MI=0.002)\", \"options_skew_momentum_z (MI=0.017)\"],\n",
    "        \"retained_feature\": \"options_risk_regime_prob (MI=0.031, rank #2/22)\",\n",
    "        \"optuna_objective\": \"Single-column MI (was sum of 3)\",\n",
    "        \"new_parameter\": \"input_scaling (standardize HMM inputs)\"\n",
    "    }\n",
    "}\n",
    "\n",
    "# Save JSON\n",
    "with open('training_result.json', 'w') as f:\n",
    "    json.dump(result, f, indent=2)\n",
    "print(\"Saved: training_result.json\")\n",
    "\n",
    "print(\"\\n=== Training Complete ===\")\n",
    "print(f\"Finished: {datetime.now().isoformat()}\")\n",
    "print(f\"\\nFinal summary:\")\n",
    "print(f\"  Feature: options_market\")\n",
    "print(f\"  Attempt: 2\")\n",
    "print(f\"  Output: 1 column (options_risk_regime_prob)\")\n",
    "print(f\"  Best MI: {best_value:.6f}\")\n",
    "print(f\"  Best params: {best_params}\")\n",
    "print(f\"  Data: {n} samples ({data.index.min()} to {data.index.max()})\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
