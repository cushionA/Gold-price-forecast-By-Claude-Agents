{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Gold Meta-Model Training - Attempt 8\n\n**Architecture:** GBDT Stacking (XGBoost + LightGBM + CatBoost) + Ridge Meta-Learner\n\n**Key Changes from Attempt 7:**\n1. **3-model GBDT stacking**: XGBoost + LightGBM + CatBoost with Ridge meta-learner\n2. **+6 regime-conditional features** (30 total features, was 24)\n3. **Updated Optuna weights**: 35/35/10/20 (Sharpe/DA/MAE/HCDA), was 40/30/10/20\n4. **max_depth widened** to [2,5] for XGBoost (was [2,4])\n5. **CPU mode** for 12-hour Kaggle quota\n\n**Inherited from Attempt 7:**\n- Bootstrap variance-based confidence (5 XGBoost models for HCDA)\n- OLS output scaling (validation-derived, capped at 10x)\n- All metric functions unchanged\n\n**Design:** `docs/design/meta_model_attempt_8.md`"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import pandas as pd\nimport numpy as np\nimport xgboost as xgb\nimport lightgbm as lgb\nimport catboost as cb\nfrom sklearn.linear_model import Ridge\nimport optuna\nfrom optuna.samplers import TPESampler\nimport json\nfrom datetime import datetime\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# Set random seeds\nnp.random.seed(42)\n\nprint(f\"XGBoost version: {xgb.__version__}\")\nprint(f\"LightGBM version: {lgb.__version__}\")\nprint(f\"CatBoost version: {cb.__version__}\")\nprint(f\"Optuna version: {optuna.__version__}\")\nprint(f\"Started: {datetime.now().isoformat()}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# === Base features (24, from attempt 7) ===\nBASE_FEATURE_COLUMNS = [\n    # Base features (5)\n    'real_rate_change', 'dxy_change', 'vix',\n    'yield_spread_change', 'inflation_exp_change',\n    # VIX submodel (3)\n    'vix_regime_probability', 'vix_mean_reversion_z', 'vix_persistence',\n    # Technical submodel (3)\n    'tech_trend_regime_prob', 'tech_mean_reversion_z', 'tech_volatility_regime',\n    # Cross-asset submodel (3)\n    'xasset_regime_prob', 'xasset_recession_signal', 'xasset_divergence',\n    # Yield curve submodel (2)\n    'yc_spread_velocity_z', 'yc_curvature_z',\n    # ETF flow submodel (3)\n    'etf_regime_prob', 'etf_capital_intensity', 'etf_pv_divergence',\n    # Inflation expectation submodel (3)\n    'ie_regime_prob', 'ie_anchoring_z', 'ie_gold_sensitivity_z',\n    # Options market submodel (1)\n    'options_risk_regime_prob',\n    # Temporal context submodel (1)\n    'temporal_context_score',\n]\nassert len(BASE_FEATURE_COLUMNS) == 24\n\n# === Regime-conditional features (6, NEW in Attempt 8) ===\nREGIME_FEATURE_COLUMNS = [\n    'real_rate_x_high_vol',      # real_rate_change * (vix_persistence > 0.7)\n    'dxy_x_high_vol',            # dxy_change * (vix_persistence > 0.7)\n    'etf_flow_x_risk_off',      # etf_capital_intensity * (xasset_recession_signal > 0.5)\n    'yc_curvature_x_risk_off',  # yc_curvature_z * (xasset_recession_signal > 0.5)\n    'inflation_x_trend',         # inflation_exp_change * (tech_trend_regime_prob > 0.7)\n    'temporal_x_trend',          # temporal_context_score * (tech_trend_regime_prob > 0.7)\n]\nassert len(REGIME_FEATURE_COLUMNS) == 6\n\n# === Combined feature set (30) ===\nFEATURE_COLUMNS = BASE_FEATURE_COLUMNS + REGIME_FEATURE_COLUMNS\nTARGET = 'gold_return_next'\n\nassert len(FEATURE_COLUMNS) == 30, f\"Expected 30 features, got {len(FEATURE_COLUMNS)}\"\nprint(f\"Features defined: {len(FEATURE_COLUMNS)} features (24 base + 6 regime)\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Fetching (API-Based)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# ============================================================\n# API-BASED DATA FETCHING\n# ============================================================\nprint(\"=\"*60)\nprint(\"FETCHING DATA FROM APIs\")\nprint(\"=\"*60)\n\n# === Import libraries ===\nimport os\nimport yfinance as yf\n\n# FRED API (install if needed)\ntry:\n    from fredapi import Fred\nexcept ImportError:\n    import subprocess\n    subprocess.run([\"pip\", \"install\", \"fredapi\"], check=True)\n    from fredapi import Fred\n\n# === Resolve dataset mount path (API v2 vs Web UI) ===\nDATASET_CANDIDATES = [\n    '../input/gold-prediction-submodels/',\n    '/kaggle/input/gold-prediction-submodels/',\n    '/kaggle/input/datasets/bigbigzabuton/gold-prediction-submodels/',\n]\nDATASET_PATH = None\nfor candidate in DATASET_CANDIDATES:\n    if os.path.isdir(candidate):\n        DATASET_PATH = candidate\n        break\nif DATASET_PATH is None:\n    # List what IS available under /kaggle/input/\n    import glob\n    available = glob.glob('/kaggle/input/*') + glob.glob('/kaggle/input/datasets/*') + glob.glob('/kaggle/input/datasets/*/*')\n    raise FileNotFoundError(\n        f\"Dataset not found at any candidate path: {DATASET_CANDIDATES}\\n\"\n        f\"Available under /kaggle/input/: {available}\"\n    )\nprint(f\"Dataset found at: {DATASET_PATH}\")\n\n# === FRED API key (hardcoded) ===\nFRED_API_KEY = \"3ffb68facdf6321e180e380c00e909c8\"\nfred = Fred(api_key=FRED_API_KEY)\nprint(\"✓ FRED API initialized\")\n\n# === 1. Fetch Gold Price (target) ===\nprint(\"\\nFetching gold price (GC=F)...\")\ngold = yf.download('GC=F', start='2014-01-01', end='2026-02-20', progress=False)\ngold_df = gold[['Close']].copy()\ngold_df.columns = ['gold_price']\ngold_df['gold_return'] = gold_df['gold_price'].pct_change() * 100\ngold_df['gold_return_next'] = gold_df['gold_return'].shift(-1)  # Next-day return\ngold_df = gold_df.dropna(subset=['gold_return_next'])\ngold_df.index = pd.to_datetime(gold_df.index).strftime('%Y-%m-%d')\nprint(f\"  Gold: {len(gold_df)} rows\")\n\n# === 2. Fetch Base Features ===\nprint(\"\\nFetching base features...\")\n\n# Real Rate (DFII10)\nprint(\"  Fetching real rate (DFII10)...\")\nreal_rate = fred.get_series('DFII10', observation_start='2014-01-01')\nreal_rate_df = real_rate.to_frame('real_rate_real_rate')\nreal_rate_df.index = pd.to_datetime(real_rate_df.index).strftime('%Y-%m-%d')\n\n# DXY (DX-Y.NYB)\nprint(\"  Fetching DXY (DX-Y.NYB)...\")\ndxy = yf.download('DX-Y.NYB', start='2014-01-01', end='2026-02-20', progress=False)\ndxy_df = dxy[['Close']].copy()\ndxy_df.columns = ['dxy_dxy']\ndxy_df.index = pd.to_datetime(dxy_df.index).strftime('%Y-%m-%d')\n\n# VIX (VIXCLS)\nprint(\"  Fetching VIX (VIXCLS)...\")\nvix = fred.get_series('VIXCLS', observation_start='2014-01-01')\nvix_df = vix.to_frame('vix_vix')\nvix_df.index = pd.to_datetime(vix_df.index).strftime('%Y-%m-%d')\n\n# Yield Curve (DGS10 - DGS2)\nprint(\"  Fetching yield curve (DGS10, DGS2)...\")\ndgs10 = fred.get_series('DGS10', observation_start='2014-01-01')\ndgs2 = fred.get_series('DGS2', observation_start='2014-01-01')\nyc_df = pd.DataFrame({'DGS10': dgs10, 'DGS2': dgs2})\nyc_df['yield_curve_yield_spread'] = yc_df['DGS10'] - yc_df['DGS2']\nyc_df = yc_df[['yield_curve_yield_spread']]\nyc_df.index = pd.to_datetime(yc_df.index).strftime('%Y-%m-%d')\n\n# Inflation Expectation (T10YIE)\nprint(\"  Fetching inflation expectation (T10YIE)...\")\ninfl_exp = fred.get_series('T10YIE', observation_start='2014-01-01')\ninfl_exp_df = infl_exp.to_frame('inflation_expectation_inflation_expectation')\ninfl_exp_df.index = pd.to_datetime(infl_exp_df.index).strftime('%Y-%m-%d')\n\n# Merge base features\nbase_features = gold_df[['gold_return_next']].copy()\nfor df in [real_rate_df, dxy_df, vix_df, yc_df, infl_exp_df]:\n    base_features = base_features.join(df, how='left')\n\n# Forward-fill missing values (weekends, holidays)\nbase_features = base_features.ffill()\nprint(f\"  Base features: {len(base_features)} rows, {len(base_features.columns)} columns\")\n\n# === 3. Load Submodel Outputs (from Kaggle Dataset) ===\nprint(\"\\nLoading submodel outputs from Kaggle Dataset...\")\n\nsubmodel_files = {\n    'vix': {\n        'path': DATASET_PATH + 'vix.csv',\n        'columns': ['vix_regime_probability', 'vix_mean_reversion_z', 'vix_persistence'],\n        'date_col': 'date',\n        'tz_aware': False,\n    },\n    'technical': {\n        'path': DATASET_PATH + 'technical.csv',\n        'columns': ['tech_trend_regime_prob', 'tech_mean_reversion_z', 'tech_volatility_regime'],\n        'date_col': 'date',\n        'tz_aware': True,  # CRITICAL: timezone-aware dates\n    },\n    'cross_asset': {\n        'path': DATASET_PATH + 'cross_asset.csv',\n        'columns': ['xasset_regime_prob', 'xasset_recession_signal', 'xasset_divergence'],\n        'date_col': 'Date',\n        'tz_aware': False,\n    },\n    'yield_curve': {\n        'path': DATASET_PATH + 'yield_curve.csv',\n        'columns': ['yc_spread_velocity_z', 'yc_curvature_z'],\n        'date_col': 'index',  # Special: dates in first unnamed column\n        'tz_aware': False,\n    },\n    'etf_flow': {\n        'path': DATASET_PATH + 'etf_flow.csv',\n        'columns': ['etf_regime_prob', 'etf_capital_intensity', 'etf_pv_divergence'],\n        'date_col': 'Date',\n        'tz_aware': False,\n    },\n    'inflation_expectation': {\n        'path': DATASET_PATH + 'inflation_expectation.csv',\n        'columns': ['ie_regime_prob', 'ie_anchoring_z', 'ie_gold_sensitivity_z'],\n        'date_col': 'Unnamed: 0',  # Special: dates in unnamed column\n        'tz_aware': False,\n    },\n    'options_market': {\n        'path': DATASET_PATH + 'options_market.csv',\n        'columns': ['options_risk_regime_prob'],\n        'date_col': 'Date',\n        'tz_aware': True,  # CRITICAL: timezone-aware dates (same as technical.csv)\n    },\n    'temporal_context': {\n        'path': DATASET_PATH + 'temporal_context.csv',\n        'columns': ['temporal_context_score'],\n        'date_col': 'date',\n        'tz_aware': False,\n    },\n}\n\nsubmodel_dfs = {}\nfor feature, spec in submodel_files.items():\n    # Load CSV\n    df = pd.read_csv(spec['path'])\n\n    # Normalize date column\n    date_col = spec['date_col']\n    if spec['tz_aware']:\n        # CRITICAL: timezone-aware dates require utc=True\n        df['Date'] = pd.to_datetime(df[date_col], utc=True).dt.strftime('%Y-%m-%d')\n    else:\n        if date_col == 'index':\n            # yield_curve.csv has dates in first unnamed column (index 0)\n            df['Date'] = pd.to_datetime(df.iloc[:, 0]).dt.strftime('%Y-%m-%d')\n        elif date_col == 'Unnamed: 0':\n            # inflation_expectation.csv has dates in unnamed column\n            df['Date'] = pd.to_datetime(df['Unnamed: 0']).dt.strftime('%Y-%m-%d')\n        else:\n            df['Date'] = pd.to_datetime(df[date_col]).dt.strftime('%Y-%m-%d')\n\n    df = df[['Date'] + spec['columns']]\n    df = df.set_index('Date')\n    submodel_dfs[feature] = df\n    print(f\"  {feature}: {len(df)} rows\")\n\nprint(f\"\\n✓ Data fetching complete\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Transformation and NaN Imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# === Apply transformations (stationary conversion) ===\nprint(\"\\nApplying transformations...\")\n\n# Create final feature DataFrame\nfinal_df = base_features.copy()\n\n# Base features (4 diff, 1 level)\nfinal_df['real_rate_change'] = final_df['real_rate_real_rate'].diff()\nfinal_df['dxy_change'] = final_df['dxy_dxy'].diff()\nfinal_df['vix'] = final_df['vix_vix']  # Level (stationary)\nfinal_df['yield_spread_change'] = final_df['yield_curve_yield_spread'].diff()\nfinal_df['inflation_exp_change'] = final_df['inflation_expectation_inflation_expectation'].diff()\n\n# Drop original raw columns\nfinal_df = final_df.drop(columns=['real_rate_real_rate', 'dxy_dxy', 'vix_vix',\n                                    'yield_curve_yield_spread', 'inflation_expectation_inflation_expectation'])\n\n# === Merge submodel features ===\nprint(\"\\nMerging submodel outputs...\")\nfor feature, df in submodel_dfs.items():\n    final_df = final_df.join(df, how='left')\n\nprint(f\"  Features after merge: {final_df.shape[1]} columns, {len(final_df)} rows\")\n\n# === NaN Imputation (domain-specific) ===\nprint(\"\\nApplying NaN imputation...\")\nnan_before = final_df.isna().sum().sum()\nprint(f\"  NaN before imputation: {nan_before}\")\n\n# Regime probability columns -> 0.5 (maximum uncertainty)\nregime_cols = ['vix_regime_probability', 'tech_trend_regime_prob',\n               'xasset_regime_prob', 'etf_regime_prob', 'ie_regime_prob',\n               'options_risk_regime_prob', 'temporal_context_score']\nfor col in regime_cols:\n    if col in final_df.columns:\n        final_df[col] = final_df[col].fillna(0.5)\n\n# Z-score columns -> 0.0 (at mean)\nz_cols = ['vix_mean_reversion_z', 'tech_mean_reversion_z',\n          'yc_spread_velocity_z', 'yc_curvature_z',\n          'etf_capital_intensity', 'etf_pv_divergence',\n          'ie_anchoring_z', 'ie_gold_sensitivity_z']\nfor col in z_cols:\n    if col in final_df.columns:\n        final_df[col] = final_df[col].fillna(0.0)\n\n# Divergence/signal columns -> 0.0 (neutral)\ndiv_cols = ['xasset_recession_signal', 'xasset_divergence']\nfor col in div_cols:\n    if col in final_df.columns:\n        final_df[col] = final_df[col].fillna(0.0)\n\n# Continuous state columns -> median\ncont_cols = ['tech_volatility_regime', 'vix_persistence']\nfor col in cont_cols:\n    if col in final_df.columns:\n        final_df[col] = final_df[col].fillna(final_df[col].median())\n\n# Drop rows with NaN in target or base features\nfinal_df = final_df.dropna(subset=['gold_return_next', 'real_rate_change', 'dxy_change',\n                                     'vix', 'yield_spread_change', 'inflation_exp_change'])\n\nnan_after = final_df.isna().sum().sum()\nprint(f\"  NaN after base imputation: {nan_after}\")\n\n# === Generate Regime-Conditional Features (NEW in Attempt 8) ===\n# CRITICAL: Must be generated AFTER NaN imputation\nprint(\"\\nGenerating regime-conditional features...\")\n\n# High-vol regime (vix_persistence > 0.7)\nhigh_vol = (final_df['vix_persistence'] > 0.7).astype(float)\nfinal_df['real_rate_x_high_vol'] = final_df['real_rate_change'] * high_vol\nfinal_df['dxy_x_high_vol'] = final_df['dxy_change'] * high_vol\n\n# Risk-off regime (xasset_recession_signal > 0.5)\nrisk_off = (final_df['xasset_recession_signal'] > 0.5).astype(float)\nfinal_df['etf_flow_x_risk_off'] = final_df['etf_capital_intensity'] * risk_off\nfinal_df['yc_curvature_x_risk_off'] = final_df['yc_curvature_z'] * risk_off\n\n# Trend regime (tech_trend_regime_prob > 0.7)\ntrend_on = (final_df['tech_trend_regime_prob'] > 0.7).astype(float)\nfinal_df['inflation_x_trend'] = final_df['inflation_exp_change'] * trend_on\nfinal_df['temporal_x_trend'] = final_df['temporal_context_score'] * trend_on\n\n# Report regime activation rates\nprint(f\"  High-vol regime active:  {high_vol.mean()*100:.1f}% of samples\")\nprint(f\"  Risk-off regime active:  {risk_off.mean()*100:.1f}% of samples\")\nprint(f\"  Trend regime active:     {trend_on.mean()*100:.1f}% of samples\")\n\nprint(f\"  Final dataset: {len(final_df)} rows\")\n\n# === Verify feature set ===\nassert all(col in final_df.columns for col in FEATURE_COLUMNS), \"Missing features after merge!\"\nassert TARGET in final_df.columns, \"Target not found!\"\nremaining_nan = final_df[FEATURE_COLUMNS].isna().sum().sum()\nprint(f\"\\n  All {len(FEATURE_COLUMNS)} features present\")\nprint(f\"  Remaining NaN in features: {remaining_nan}\")\nprint(f\"  Dataset shape: {final_df.shape}\")\nprint(f\"  Date range: {final_df.index.min()} to {final_df.index.max()}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train/Val/Test Split (70/15/15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Train/Val/Test Split (70/15/15, time-series order) ===\n",
    "n_total = len(final_df)\n",
    "n_train = int(n_total * 0.70)\n",
    "n_val = int(n_total * 0.15)\n",
    "\n",
    "train_df = final_df.iloc[:n_train].copy()\n",
    "val_df = final_df.iloc[n_train:n_train+n_val].copy()\n",
    "test_df = final_df.iloc[n_train+n_val:].copy()\n",
    "\n",
    "print(f\"\\n✓ Data split complete:\")\n",
    "print(f\"  Train: {len(train_df)} rows ({len(train_df)/n_total*100:.1f}%) - {train_df.index.min()} to {train_df.index.max()}\")\n",
    "print(f\"  Val:   {len(val_df)} rows ({len(val_df)/n_total*100:.1f}%) - {val_df.index.min()} to {val_df.index.max()}\")\n",
    "print(f\"  Test:  {len(test_df)} rows ({len(test_df)/n_total*100:.1f}%) - {test_df.index.min()} to {test_df.index.max()}\")\n",
    "print(f\"  Total: {n_total} rows\")\n",
    "print(f\"  Samples per feature: {n_train / len(FEATURE_COLUMNS):.1f}:1 (train)\")\n",
    "\n",
    "# Verify no data leakage\n",
    "assert train_df.index.max() < val_df.index.min(), \"Train-val overlap detected!\"\n",
    "assert val_df.index.max() < test_df.index.min(), \"Val-test overlap detected!\"\n",
    "print(f\"\\n✓ No time-series leakage detected\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Prepare arrays for training\n",
    "X_train = train_df[FEATURE_COLUMNS].values\n",
    "y_train = train_df[TARGET].values\n",
    "\n",
    "X_val = val_df[FEATURE_COLUMNS].values\n",
    "y_val = val_df[TARGET].values\n",
    "\n",
    "X_test = test_df[FEATURE_COLUMNS].values\n",
    "y_test = test_df[TARGET].values\n",
    "\n",
    "# Store dates for output\n",
    "dates_train = train_df.index\n",
    "dates_val = val_df.index\n",
    "dates_test = test_df.index\n",
    "\n",
    "print(f\"\\nArray shapes:\")\n",
    "print(f\"  X_train: {X_train.shape}, y_train: {y_train.shape}\")\n",
    "print(f\"  X_val:   {X_val.shape}, y_val:   {y_val.shape}\")\n",
    "print(f\"  X_test:  {X_test.shape}, y_test:  {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metric Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "def compute_direction_accuracy(y_true, y_pred):\n    \"\"\"Direction accuracy, excluding zeros.\"\"\"\n    mask = (y_true != 0) & (y_pred != 0)\n    if mask.sum() == 0:\n        return 0.0\n    return (np.sign(y_pred[mask]) == np.sign(y_true[mask])).mean()\n\ndef compute_mae(y_true, y_pred):\n    \"\"\"Mean Absolute Error.\"\"\"\n    return np.abs(y_pred - y_true).mean()\n\ndef compute_sharpe_trade_cost(y_true, y_pred, cost_bps=5.0):\n    \"\"\"Sharpe ratio with position-change cost (5bps per change).\"\"\"\n    positions = np.sign(y_pred)\n    \n    # Strategy returns (position * actual return)\n    strategy_returns = positions * y_true / 100.0  # Convert % to decimal\n    \n    # Position changes\n    position_changes = np.abs(np.diff(positions, prepend=0))\n    trade_costs = position_changes * (cost_bps / 10000.0)  # 5bps = 0.0005\n    \n    # Net returns\n    net_returns = strategy_returns - trade_costs\n    \n    # Annualized Sharpe (252 trading days)\n    if len(net_returns) < 2 or net_returns.std() == 0:\n        return 0.0\n    return (net_returns.mean() / net_returns.std()) * np.sqrt(252)\n\ndef compute_hcda(y_true, y_pred, threshold_percentile=80):\n    \"\"\"High-confidence direction accuracy (top 20% by |prediction|).\"\"\"\n    threshold = np.percentile(np.abs(y_pred), threshold_percentile)\n    hc_mask = np.abs(y_pred) > threshold\n    \n    if hc_mask.sum() == 0:\n        return 0.0, 0.0\n    \n    coverage = hc_mask.sum() / len(y_pred)\n    hc_pred = y_pred[hc_mask]\n    hc_actual = y_true[hc_mask]\n    \n    mask = (hc_actual != 0) & (hc_pred != 0)\n    if mask.sum() == 0:\n        return 0.0, coverage\n    \n    da = (np.sign(hc_pred[mask]) == np.sign(hc_actual[mask])).mean()\n    return da, coverage\n\ndef compute_hcda_bootstrap(y_true, y_pred, bootstrap_std, threshold_percentile=80):\n    \"\"\"\n    HCDA using bootstrap variance-based confidence.\n    High confidence = LOW variance (certain predictions)\n    Top 20% by inverse variance: 1 / (1 + std)\n    \"\"\"\n    confidence = 1.0 / (1.0 + bootstrap_std)  # Higher confidence when std is low\n    threshold = np.percentile(confidence, threshold_percentile)\n    hc_mask = confidence > threshold\n    \n    if hc_mask.sum() == 0:\n        return 0.0, 0.0\n    \n    coverage = hc_mask.sum() / len(y_pred)\n    hc_pred = y_pred[hc_mask]\n    hc_actual = y_true[hc_mask]\n    \n    mask = (hc_actual != 0) & (hc_pred != 0)\n    if mask.sum() == 0:\n        return 0.0, coverage\n    \n    da = (np.sign(hc_pred[mask]) == np.sign(hc_actual[mask])).mean()\n    return da, coverage\n\nprint(\"Metric functions defined\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## XGBoost Optuna HPO (100 trials) - ATTEMPT 8 WEIGHTS"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "def xgb_optuna_objective(trial):\n    \"\"\"XGBoost Optuna objective (Attempt 8: updated weights, wider max_depth).\"\"\"\n    params = {\n        'objective': 'reg:squarederror',\n        'max_depth': trial.suggest_int('max_depth', 2, 5),  # CHANGED: [2,4] -> [2,5]\n        'min_child_weight': trial.suggest_int('min_child_weight', 12, 25),\n        'subsample': trial.suggest_float('subsample', 0.4, 0.85),\n        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.2, 0.7),\n        'reg_lambda': trial.suggest_float('reg_lambda', 1.0, 15.0, log=True),\n        'reg_alpha': trial.suggest_float('reg_alpha', 0.5, 10.0, log=True),\n        'learning_rate': trial.suggest_float('learning_rate', 0.001, 0.05, log=True),\n        'tree_method': 'hist',\n        'eval_metric': 'rmse',\n        'verbosity': 0,\n        'seed': 42 + trial.number,\n    }\n    n_estimators = trial.suggest_int('n_estimators', 100, 800)\n\n    model = xgb.XGBRegressor(**params, n_estimators=n_estimators, early_stopping_rounds=100)\n    model.fit(X_train, y_train, eval_set=[(X_val, y_val)], verbose=False)\n\n    train_pred = model.predict(X_train)\n    val_pred = model.predict(X_val)\n\n    train_da = compute_direction_accuracy(y_train, train_pred)\n    val_da = compute_direction_accuracy(y_val, val_pred)\n    val_mae = compute_mae(y_val, val_pred)\n    val_sharpe = compute_sharpe_trade_cost(y_val, val_pred)\n    val_hc_da, val_hc_coverage = compute_hcda(y_val, val_pred, threshold_percentile=80)\n\n    da_gap = (train_da - val_da) * 100\n    overfit_penalty = max(0.0, (da_gap - 10.0) / 30.0)\n\n    sharpe_norm = np.clip((val_sharpe + 3.0) / 6.0, 0.0, 1.0)\n    da_norm = np.clip((val_da * 100 - 40.0) / 30.0, 0.0, 1.0)\n    mae_norm = np.clip((1.0 - val_mae) / 0.5, 0.0, 1.0)\n    hc_da_norm = np.clip((val_hc_da * 100 - 40.0) / 30.0, 0.0, 1.0)\n\n    # ATTEMPT 8 WEIGHTS: 35/35/10/20 (was 40/30/10/20)\n    objective = (\n        0.35 * sharpe_norm +\n        0.35 * da_norm +\n        0.10 * mae_norm +\n        0.20 * hc_da_norm\n    ) - 0.30 * overfit_penalty\n\n    trial.set_user_attr('val_da', float(val_da))\n    trial.set_user_attr('val_mae', float(val_mae))\n    trial.set_user_attr('val_sharpe', float(val_sharpe))\n    trial.set_user_attr('val_hc_da', float(val_hc_da))\n    trial.set_user_attr('val_hc_coverage', float(val_hc_coverage))\n    trial.set_user_attr('train_da', float(train_da))\n    trial.set_user_attr('da_gap_pp', float(da_gap))\n    trial.set_user_attr('n_estimators_used',\n                         int(model.best_iteration + 1) if hasattr(model, 'best_iteration')\n                         and model.best_iteration is not None else n_estimators)\n    return objective\n\nprint(\"XGBoost Optuna objective defined (Attempt 8: weights 35/35/10/20, max_depth [2,5])\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "print(\"\\n\" + \"=\"*60)\nprint(\"RUNNING XGBOOST OPTUNA HPO (100 trials, 1-hour timeout)\")\nprint(\"=\"*60)\n\nxgb_study = optuna.create_study(direction='maximize', sampler=TPESampler(seed=42))\nxgb_study.optimize(xgb_optuna_objective, n_trials=100, timeout=3600, show_progress_bar=True)\n\nprint(f\"\\nXGBoost HPO complete: {len(xgb_study.trials)} trials\")\nprint(f\"  Best value: {xgb_study.best_value:.4f}\")\nprint(f\"  Best DA: {xgb_study.best_trial.user_attrs['val_da']*100:.2f}%\")\nprint(f\"  Best Sharpe: {xgb_study.best_trial.user_attrs['val_sharpe']:.2f}\")\nprint(f\"  Best HCDA: {xgb_study.best_trial.user_attrs['val_hc_da']*100:.2f}%\")\nprint(f\"\\nBest hyperparameters:\")\nfor k, v in xgb_study.best_params.items():\n    print(f\"  {k}: {v}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## LightGBM Optuna HPO (80 trials)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "def lgbm_optuna_objective(trial):\n    \"\"\"LightGBM Optuna objective (same composite as XGBoost).\"\"\"\n    params = {\n        'objective': 'regression',\n        'metric': 'rmse',\n        'verbosity': -1,\n        'num_leaves': trial.suggest_int('num_leaves', 8, 64),\n        'max_depth': trial.suggest_int('max_depth', -1, 6),\n        'learning_rate': trial.suggest_float('learning_rate', 0.001, 0.05, log=True),\n        'feature_fraction': trial.suggest_float('feature_fraction', 0.2, 0.7),\n        'bagging_fraction': trial.suggest_float('bagging_fraction', 0.4, 0.85),\n        'bagging_freq': trial.suggest_int('bagging_freq', 1, 7),\n        'min_child_samples': trial.suggest_int('min_child_samples', 15, 30),\n        'reg_lambda': trial.suggest_float('reg_lambda', 1.0, 15.0, log=True),\n        'reg_alpha': trial.suggest_float('reg_alpha', 0.5, 10.0, log=True),\n        'seed': 43 + trial.number,\n    }\n    n_estimators = trial.suggest_int('n_estimators', 100, 800)\n\n    model = lgb.LGBMRegressor(**params, n_estimators=n_estimators)\n    model.fit(X_train, y_train, eval_set=[(X_val, y_val)],\n              callbacks=[lgb.early_stopping(100), lgb.log_evaluation(0)])\n\n    train_pred = model.predict(X_train)\n    val_pred = model.predict(X_val)\n\n    train_da = compute_direction_accuracy(y_train, train_pred)\n    val_da = compute_direction_accuracy(y_val, val_pred)\n    val_mae = compute_mae(y_val, val_pred)\n    val_sharpe = compute_sharpe_trade_cost(y_val, val_pred)\n    val_hc_da, _ = compute_hcda(y_val, val_pred)\n\n    da_gap = (train_da - val_da) * 100\n    overfit_penalty = max(0.0, (da_gap - 10.0) / 30.0)\n\n    sharpe_norm = np.clip((val_sharpe + 3.0) / 6.0, 0.0, 1.0)\n    da_norm = np.clip((val_da * 100 - 40.0) / 30.0, 0.0, 1.0)\n    mae_norm = np.clip((1.0 - val_mae) / 0.5, 0.0, 1.0)\n    hc_da_norm = np.clip((val_hc_da * 100 - 40.0) / 30.0, 0.0, 1.0)\n\n    objective = (0.35 * sharpe_norm + 0.35 * da_norm + 0.10 * mae_norm + 0.20 * hc_da_norm\n                 ) - 0.30 * overfit_penalty\n\n    trial.set_user_attr('val_da', float(val_da))\n    trial.set_user_attr('val_sharpe', float(val_sharpe))\n    trial.set_user_attr('val_hc_da', float(val_hc_da))\n    trial.set_user_attr('val_mae', float(val_mae))\n    trial.set_user_attr('train_da', float(train_da))\n    return objective\n\nprint(\"\\n\" + \"=\"*60)\nprint(\"RUNNING LIGHTGBM OPTUNA HPO (80 trials, 40-min timeout)\")\nprint(\"=\"*60)\n\nlgbm_study = optuna.create_study(direction='maximize', sampler=TPESampler(seed=43))\nlgbm_study.optimize(lgbm_optuna_objective, n_trials=80, timeout=2400, show_progress_bar=True)\n\nprint(f\"\\nLightGBM HPO complete: {len(lgbm_study.trials)} trials\")\nprint(f\"  Best value: {lgbm_study.best_value:.4f}\")\nprint(f\"  Best DA: {lgbm_study.best_trial.user_attrs['val_da']*100:.2f}%\")\nprint(f\"  Best Sharpe: {lgbm_study.best_trial.user_attrs['val_sharpe']:.2f}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## CatBoost Optuna HPO (80 trials)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "def catboost_optuna_objective(trial):\n    \"\"\"CatBoost Optuna objective (same composite as XGBoost).\"\"\"\n    params = {\n        'loss_function': 'RMSE',\n        'depth': trial.suggest_int('depth', 2, 6),\n        'iterations': trial.suggest_int('iterations', 100, 800),\n        'learning_rate': trial.suggest_float('learning_rate', 0.001, 0.05, log=True),\n        'l2_leaf_reg': trial.suggest_float('l2_leaf_reg', 1.0, 15.0, log=True),\n        'random_strength': trial.suggest_float('random_strength', 0.5, 5.0),\n        'bagging_temperature': trial.suggest_float('bagging_temperature', 0.0, 2.0),\n        'rsm': trial.suggest_float('rsm', 0.2, 0.7),\n        'min_data_in_leaf': trial.suggest_int('min_data_in_leaf', 15, 30),\n        'random_seed': 44 + trial.number,\n        'verbose': 0,\n    }\n\n    model = cb.CatBoostRegressor(**params)\n    model.fit(X_train, y_train, eval_set=(X_val, y_val),\n              early_stopping_rounds=100, verbose=0)\n\n    train_pred = model.predict(X_train)\n    val_pred = model.predict(X_val)\n\n    train_da = compute_direction_accuracy(y_train, train_pred)\n    val_da = compute_direction_accuracy(y_val, val_pred)\n    val_mae = compute_mae(y_val, val_pred)\n    val_sharpe = compute_sharpe_trade_cost(y_val, val_pred)\n    val_hc_da, _ = compute_hcda(y_val, val_pred)\n\n    da_gap = (train_da - val_da) * 100\n    overfit_penalty = max(0.0, (da_gap - 10.0) / 30.0)\n\n    sharpe_norm = np.clip((val_sharpe + 3.0) / 6.0, 0.0, 1.0)\n    da_norm = np.clip((val_da * 100 - 40.0) / 30.0, 0.0, 1.0)\n    mae_norm = np.clip((1.0 - val_mae) / 0.5, 0.0, 1.0)\n    hc_da_norm = np.clip((val_hc_da * 100 - 40.0) / 30.0, 0.0, 1.0)\n\n    objective = (0.35 * sharpe_norm + 0.35 * da_norm + 0.10 * mae_norm + 0.20 * hc_da_norm\n                 ) - 0.30 * overfit_penalty\n\n    trial.set_user_attr('val_da', float(val_da))\n    trial.set_user_attr('val_sharpe', float(val_sharpe))\n    trial.set_user_attr('val_hc_da', float(val_hc_da))\n    trial.set_user_attr('val_mae', float(val_mae))\n    trial.set_user_attr('train_da', float(train_da))\n    return objective\n\nprint(\"\\n\" + \"=\"*60)\nprint(\"RUNNING CATBOOST OPTUNA HPO (80 trials, 50-min timeout)\")\nprint(\"=\"*60)\n\ncb_study = optuna.create_study(direction='maximize', sampler=TPESampler(seed=44))\ncb_study.optimize(catboost_optuna_objective, n_trials=80, timeout=3000, show_progress_bar=True)\n\nprint(f\"\\nCatBoost HPO complete: {len(cb_study.trials)} trials\")\nprint(f\"  Best value: {cb_study.best_value:.4f}\")\nprint(f\"  Best DA: {cb_study.best_trial.user_attrs['val_da']*100:.2f}%\")\nprint(f\"  Best Sharpe: {cb_study.best_trial.user_attrs['val_sharpe']:.2f}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Train Final Base Models + Stacking"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "print(\"\\n\" + \"=\"*60)\nprint(\"TRAINING FINAL BASE MODELS\")\nprint(\"=\"*60)\n\n# === 1. Final XGBoost ===\nxgb_best = xgb_study.best_params\nxgb_final = xgb.XGBRegressor(\n    objective='reg:squarederror',\n    max_depth=xgb_best['max_depth'],\n    min_child_weight=xgb_best['min_child_weight'],\n    subsample=xgb_best['subsample'],\n    colsample_bytree=xgb_best['colsample_bytree'],\n    reg_lambda=xgb_best['reg_lambda'],\n    reg_alpha=xgb_best['reg_alpha'],\n    learning_rate=xgb_best['learning_rate'],\n    n_estimators=xgb_best['n_estimators'],\n    tree_method='hist', eval_metric='rmse', verbosity=0, seed=42,\n    early_stopping_rounds=100\n)\nxgb_final.fit(X_train, y_train, eval_set=[(X_val, y_val)], verbose=False)\nprint(f\"  XGBoost trained (best iter: {xgb_final.best_iteration})\")\n\n# === 2. Final LightGBM ===\nlgbm_best = lgbm_study.best_params\nlgbm_final = lgb.LGBMRegressor(\n    objective='regression', metric='rmse', verbosity=-1,\n    num_leaves=lgbm_best['num_leaves'],\n    max_depth=lgbm_best['max_depth'],\n    learning_rate=lgbm_best['learning_rate'],\n    feature_fraction=lgbm_best['feature_fraction'],\n    bagging_fraction=lgbm_best['bagging_fraction'],\n    bagging_freq=lgbm_best['bagging_freq'],\n    min_child_samples=lgbm_best['min_child_samples'],\n    reg_lambda=lgbm_best['reg_lambda'],\n    reg_alpha=lgbm_best['reg_alpha'],\n    n_estimators=lgbm_best['n_estimators'],\n    seed=43,\n)\nlgbm_final.fit(X_train, y_train, eval_set=[(X_val, y_val)],\n               callbacks=[lgb.early_stopping(100), lgb.log_evaluation(0)])\nprint(f\"  LightGBM trained (best iter: {lgbm_final.best_iteration_})\")\n\n# === 3. Final CatBoost ===\ncb_best = cb_study.best_params\ncb_final = cb.CatBoostRegressor(\n    loss_function='RMSE',\n    depth=cb_best['depth'],\n    iterations=cb_best['iterations'],\n    learning_rate=cb_best['learning_rate'],\n    l2_leaf_reg=cb_best['l2_leaf_reg'],\n    random_strength=cb_best['random_strength'],\n    bagging_temperature=cb_best['bagging_temperature'],\n    rsm=cb_best['rsm'],\n    min_data_in_leaf=cb_best['min_data_in_leaf'],\n    random_seed=44, verbose=0,\n)\ncb_final.fit(X_train, y_train, eval_set=(X_val, y_val),\n             early_stopping_rounds=100, verbose=0)\nprint(f\"  CatBoost trained (best iter: {cb_final.best_iteration_})\")\n\n# === Generate base model predictions ===\nxgb_train_pred = xgb_final.predict(X_train)\nxgb_val_pred = xgb_final.predict(X_val)\nxgb_test_pred = xgb_final.predict(X_test)\n\nlgbm_train_pred = lgbm_final.predict(X_train)\nlgbm_val_pred = lgbm_final.predict(X_val)\nlgbm_test_pred = lgbm_final.predict(X_test)\n\ncb_train_pred = cb_final.predict(X_train)\ncb_val_pred = cb_final.predict(X_val)\ncb_test_pred = cb_final.predict(X_test)\n\n# === Report individual model val metrics ===\nprint(\"\\nBase model validation metrics:\")\nfor name, vp in [(\"XGBoost\", xgb_val_pred), (\"LightGBM\", lgbm_val_pred), (\"CatBoost\", cb_val_pred)]:\n    da = compute_direction_accuracy(y_val, vp)\n    sh = compute_sharpe_trade_cost(y_val, vp)\n    hc, _ = compute_hcda(y_val, vp)\n    print(f\"  {name:10s}: DA={da*100:5.2f}%, Sharpe={sh:5.2f}, HCDA={hc*100:5.2f}%\")\n\n# === Prediction correlation (diversity check) ===\ncorr_xgb_lgbm = np.corrcoef(xgb_val_pred, lgbm_val_pred)[0, 1]\ncorr_xgb_cb = np.corrcoef(xgb_val_pred, cb_val_pred)[0, 1]\ncorr_lgbm_cb = np.corrcoef(lgbm_val_pred, cb_val_pred)[0, 1]\nprint(f\"\\nPrediction correlations (val):\")\nprint(f\"  XGB-LGBM: {corr_xgb_lgbm:.4f}\")\nprint(f\"  XGB-CB:   {corr_xgb_cb:.4f}\")\nprint(f\"  LGBM-CB:  {corr_lgbm_cb:.4f}\")\n\n# === Stacking: Ridge Meta-Learner ===\nprint(\"\\n\" + \"=\"*60)\nprint(\"STACKING META-LEARNER (Ridge)\")\nprint(\"=\"*60)\n\nstack_val = np.column_stack([xgb_val_pred, lgbm_val_pred, cb_val_pred])\nstack_test = np.column_stack([xgb_test_pred, lgbm_test_pred, cb_test_pred])\nstack_train = np.column_stack([xgb_train_pred, lgbm_train_pred, cb_train_pred])\n\n# Tune Ridge alpha\ndef ridge_objective(trial):\n    alpha = trial.suggest_float('alpha', 0.01, 100.0, log=True)\n    ridge = Ridge(alpha=alpha, fit_intercept=True)\n    ridge.fit(stack_val, y_val)\n    val_pred_r = ridge.predict(stack_val)\n    da = compute_direction_accuracy(y_val, val_pred_r)\n    sharpe = compute_sharpe_trade_cost(y_val, val_pred_r)\n    return 0.5 * da + 0.5 * np.clip((sharpe + 3.0) / 6.0, 0.0, 1.0)\n\nridge_study = optuna.create_study(direction='maximize', sampler=TPESampler(seed=45))\nridge_study.optimize(ridge_objective, n_trials=20, timeout=120)\nbest_ridge_alpha = ridge_study.best_params['alpha']\n\nridge_meta = Ridge(alpha=best_ridge_alpha, fit_intercept=True)\nridge_meta.fit(stack_val, y_val)\n\nprint(f\"  Ridge alpha: {best_ridge_alpha:.4f}\")\nprint(f\"  Ridge coefficients: XGB={ridge_meta.coef_[0]:.4f}, LGBM={ridge_meta.coef_[1]:.4f}, CB={ridge_meta.coef_[2]:.4f}\")\nprint(f\"  Ridge intercept: {ridge_meta.intercept_:.4f}\")\n\n# Ensemble predictions\nensemble_val_pred = ridge_meta.predict(stack_val)\nensemble_test_pred = ridge_meta.predict(stack_test)\nensemble_train_pred = ridge_meta.predict(stack_train)\n\n# === Compare: Stacking vs Single XGBoost ===\nprint(\"\\n\" + \"=\"*60)\nprint(\"STACKING vs SINGLE XGBOOST\")\nprint(\"=\"*60)\n\n# Compute composite for both (on val)\ndef compute_val_composite(y_true, y_pred):\n    da = compute_direction_accuracy(y_true, y_pred)\n    sharpe = compute_sharpe_trade_cost(y_true, y_pred)\n    mae = compute_mae(y_true, y_pred)\n    hcda, _ = compute_hcda(y_true, y_pred)\n    s_n = np.clip((sharpe + 3.0) / 6.0, 0.0, 1.0)\n    d_n = np.clip((da * 100 - 40.0) / 30.0, 0.0, 1.0)\n    m_n = np.clip((1.0 - mae) / 0.5, 0.0, 1.0)\n    h_n = np.clip((hcda * 100 - 40.0) / 30.0, 0.0, 1.0)\n    return 0.35 * s_n + 0.35 * d_n + 0.10 * m_n + 0.20 * h_n\n\nstack_composite = compute_val_composite(y_val, ensemble_val_pred)\nsingle_composite = compute_val_composite(y_val, xgb_val_pred)\n\nstack_da = compute_direction_accuracy(y_val, ensemble_val_pred)\nsingle_da = compute_direction_accuracy(y_val, xgb_val_pred)\nstack_sharpe = compute_sharpe_trade_cost(y_val, ensemble_val_pred)\nsingle_sharpe = compute_sharpe_trade_cost(y_val, xgb_val_pred)\n\nprint(f\"  Stacking composite: {stack_composite:.4f} (DA={stack_da*100:.2f}%, Sharpe={stack_sharpe:.2f})\")\nprint(f\"  Single XGB composite: {single_composite:.4f} (DA={single_da*100:.2f}%, Sharpe={single_sharpe:.2f})\")\n\n# Also test fallback params\nFALLBACK_PARAMS = {\n    'objective': 'reg:squarederror', 'max_depth': 2, 'min_child_weight': 14,\n    'reg_lambda': 4.76, 'reg_alpha': 3.65, 'subsample': 0.478,\n    'colsample_bytree': 0.371, 'learning_rate': 0.025,\n    'tree_method': 'hist', 'eval_metric': 'rmse', 'verbosity': 0, 'seed': 42,\n}\nfb_model = xgb.XGBRegressor(**FALLBACK_PARAMS, n_estimators=300, early_stopping_rounds=100)\nfb_model.fit(X_train, y_train, eval_set=[(X_val, y_val)], verbose=False)\nfb_val_pred = fb_model.predict(X_val)\nfb_composite = compute_val_composite(y_val, fb_val_pred)\nprint(f\"  Fallback composite: {fb_composite:.4f}\")\n\n# Select best configuration\nconfigs = {'stacking': stack_composite, 'single_xgb': single_composite, 'fallback': fb_composite}\nbest_config = max(configs, key=configs.get)\nprint(f\"\\n  SELECTED: {best_config.upper()} (composite={configs[best_config]:.4f})\")\n\nif best_config == 'stacking':\n    pred_train = ensemble_train_pred\n    pred_val = ensemble_val_pred\n    pred_test = ensemble_test_pred\n    selected_config = 'stacking'\n    # For bootstrap and feature importance, use XGBoost params\n    selected_params = xgb_best\n    final_model = xgb_final  # For feature importance\n    use_stacking = True\nelif best_config == 'single_xgb':\n    pred_train = xgb_train_pred\n    pred_val = xgb_val_pred\n    pred_test = xgb_test_pred\n    selected_config = 'optuna_xgb'\n    selected_params = xgb_best\n    final_model = xgb_final\n    use_stacking = False\nelse:\n    pred_train = fb_model.predict(X_train)\n    pred_val = fb_val_pred\n    pred_test = fb_model.predict(X_test)\n    selected_config = 'fallback'\n    selected_params = FALLBACK_PARAMS.copy()\n    selected_params['n_estimators'] = 300\n    final_model = fb_model\n    use_stacking = False\n\npred_full = np.concatenate([pred_train, pred_val, pred_test])\ndates_full = pd.Index(list(dates_train) + list(dates_val) + list(dates_test))\ny_full = np.concatenate([y_train, y_val, y_test])\n\nprint(f\"\\nPredictions ({selected_config}):\")\nprint(f\"  Train: mean={pred_train.mean():.4f}, std={pred_train.std():.4f}\")\nprint(f\"  Val:   mean={pred_val.mean():.4f}, std={pred_val.std():.4f}\")\nprint(f\"  Test:  mean={pred_test.mean():.4f}, std={pred_test.std():.4f}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## OLS Output Scaling + Bootstrap Confidence"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# === OLS OUTPUT SCALING ===\nprint(\"=\"*60)\nprint(\"OLS OUTPUT SCALING\")\nprint(\"=\"*60)\n\nnumerator = np.sum(pred_val * y_val)\ndenominator = np.sum(pred_val ** 2)\nalpha_ols = numerator / denominator if denominator != 0 else 1.0\nalpha_ols = np.clip(alpha_ols, 0.5, 10.0)\nprint(f\"  OLS scaling factor: {alpha_ols:.2f}\")\n\nscaled_pred_train = pred_train * alpha_ols\nscaled_pred_val = pred_val * alpha_ols\nscaled_pred_test = pred_test * alpha_ols\nscaled_pred_full = pred_full * alpha_ols\n\nmae_raw = np.mean(np.abs(pred_test - y_test))\nmae_scaled = np.mean(np.abs(scaled_pred_test - y_test))\nprint(f\"  MAE raw={mae_raw:.4f}%, scaled={mae_scaled:.4f}%\")\nuse_scaled = mae_scaled < mae_raw\nprint(f\"  Using {'SCALED' if use_scaled else 'RAW'} for MAE\")\n\n# === BOOTSTRAP ENSEMBLE CONFIDENCE (XGBoost only) ===\nprint(\"\\n\" + \"=\"*60)\nprint(\"BOOTSTRAP ENSEMBLE CONFIDENCE (5 XGBoost models)\")\nprint(\"=\"*60)\n\nbootstrap_models = []\nbootstrap_seeds = [42, 43, 44, 45, 46]\nfor i, seed in enumerate(bootstrap_seeds):\n    bp = selected_params.copy()\n    model_boot = xgb.XGBRegressor(\n        objective='reg:squarederror',\n        max_depth=bp['max_depth'], min_child_weight=bp['min_child_weight'],\n        subsample=bp['subsample'], colsample_bytree=bp['colsample_bytree'],\n        reg_lambda=bp['reg_lambda'], reg_alpha=bp['reg_alpha'],\n        learning_rate=bp['learning_rate'], n_estimators=bp['n_estimators'],\n        tree_method='hist', eval_metric='rmse', verbosity=0,\n        seed=seed, early_stopping_rounds=100\n    )\n    model_boot.fit(X_train, y_train, eval_set=[(X_val, y_val)], verbose=False)\n    bootstrap_models.append(model_boot)\nprint(f\"  Bootstrap ensemble trained: {len(bootstrap_models)} models\")\n\nensemble_preds_test = np.array([m.predict(X_test) for m in bootstrap_models])\nensemble_preds_val = np.array([m.predict(X_val) for m in bootstrap_models])\nensemble_preds_train = np.array([m.predict(X_train) for m in bootstrap_models])\n\nbootstrap_std_test = np.std(ensemble_preds_test, axis=0)\nbootstrap_std_val = np.std(ensemble_preds_val, axis=0)\nbootstrap_std_train = np.std(ensemble_preds_train, axis=0)\n\nbootstrap_conf_test = 1.0 / (1.0 + bootstrap_std_test)\nbootstrap_conf_val = 1.0 / (1.0 + bootstrap_std_val)\nbootstrap_conf_train = 1.0 / (1.0 + bootstrap_std_train)\n\nprint(f\"  Std range test: [{bootstrap_std_test.min():.4f}, {bootstrap_std_test.max():.4f}]\")\n\nhcda_bootstrap_test, hcda_bootstrap_cov = compute_hcda_bootstrap(y_test, pred_test, bootstrap_std_test)\nhcda_pred_test, hcda_pred_cov = compute_hcda(y_test, pred_test)\n\nprint(f\"\\nHCDA comparison (test):\")\nprint(f\"  Bootstrap: {hcda_bootstrap_test*100:.2f}%\")\nprint(f\"  |pred|:    {hcda_pred_test*100:.2f}%\")\n\nuse_bootstrap_hcda = hcda_bootstrap_test > hcda_pred_test\nprimary_hcda_method = 'bootstrap' if use_bootstrap_hcda else 'pred'\nprimary_hcda_value = hcda_bootstrap_test if use_bootstrap_hcda else hcda_pred_test\nprint(f\"  Selected: {primary_hcda_method} ({primary_hcda_value*100:.2f}%)\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Final Evaluation"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "print(\"\\n\" + \"=\"*60)\nprint(\"FINAL EVALUATION\")\nprint(\"=\"*60)\n\nmetrics_all = {}\nfor split_name, y_true, y_pred_raw, y_pred_scaled in [\n    ('train', y_train, pred_train, scaled_pred_train),\n    ('val', y_val, pred_val, scaled_pred_val),\n    ('test', y_test, pred_test, scaled_pred_test),\n]:\n    da = compute_direction_accuracy(y_true, y_pred_raw)\n    mae_raw_s = compute_mae(y_true, y_pred_raw)\n    mae_scaled_s = compute_mae(y_true, y_pred_scaled)\n    mae = min(mae_raw_s, mae_scaled_s)\n    sharpe = compute_sharpe_trade_cost(y_true, y_pred_raw)\n    hc_da, hc_cov = compute_hcda(y_true, y_pred_raw, threshold_percentile=80)\n    metrics_all[split_name] = {\n        'direction_accuracy': float(da), 'high_confidence_da': float(hc_da),\n        'high_confidence_coverage': float(hc_cov),\n        'mae': float(mae), 'mae_raw': float(mae_raw_s), 'mae_scaled': float(mae_scaled_s),\n        'sharpe_ratio': float(sharpe),\n    }\n\nfor sn in ['train', 'val', 'test']:\n    m = metrics_all[sn]\n    print(f\"\\n{sn.upper()}:\")\n    print(f\"  DA={m['direction_accuracy']*100:.2f}%, HCDA={m['high_confidence_da']*100:.2f}%, \"\n          f\"MAE={m['mae']:.4f}%, Sharpe={m['sharpe_ratio']:.2f}\")\n\ntrain_test_da_gap = (metrics_all['train']['direction_accuracy'] - metrics_all['test']['direction_accuracy']) * 100\ntest_m = metrics_all['test']\ntargets_met = [\n    test_m['direction_accuracy'] > 0.56,\n    primary_hcda_value > 0.60,\n    test_m['mae'] < 0.0075,\n    test_m['sharpe_ratio'] > 0.8,\n]\n\nprint(f\"\\nOVERFITTING: Train-Test DA gap = {train_test_da_gap:.2f}pp\")\nprint(f\"\\nTARGET STATUS:\")\nprint(f\"  DA > 56%:     {'PASS' if targets_met[0] else 'FAIL'} ({test_m['direction_accuracy']*100:.2f}%)\")\nprint(f\"  HCDA > 60%:   {'PASS' if targets_met[1] else 'FAIL'} ({primary_hcda_value*100:.2f}% via {primary_hcda_method})\")\nprint(f\"  MAE < 0.75%:  {'PASS' if targets_met[2] else 'FAIL'} ({test_m['mae']:.4f}%)\")\nprint(f\"  Sharpe > 0.8: {'PASS' if targets_met[3] else 'FAIL'} ({test_m['sharpe_ratio']:.2f})\")\nprint(f\"  Targets passed: {sum(targets_met)}/4\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Diagnostic Analysis"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "print(\"=\"*60)\nprint(\"DIAGNOSTIC ANALYSIS\")\nprint(\"=\"*60)\n\n# 1. Feature importance (XGBoost gain, 30 features)\nfeature_importance = final_model.feature_importances_\nfeature_ranking = pd.DataFrame({\n    'feature': FEATURE_COLUMNS,\n    'importance': feature_importance\n}).sort_values('importance', ascending=False)\n\nprint(\"\\nFEATURE IMPORTANCE (XGBoost, top 15):\")\nfor _, row in feature_ranking.head(15).iterrows():\n    marker = \" *REGIME*\" if row['feature'] in REGIME_FEATURE_COLUMNS else \"\"\n    print(f\"  {row['feature']}: {row['importance']:.4f}{marker}\")\n\n# Regime feature ranks\nprint(f\"\\nRegime feature ranks:\")\nfor rf in REGIME_FEATURE_COLUMNS:\n    rank = (feature_ranking.reset_index(drop=True).reset_index()\n            .loc[feature_ranking['feature'] == rf, 'index'].values[0] + 1)\n    imp = feature_ranking.loc[feature_ranking['feature'] == rf, 'importance'].values[0]\n    print(f\"  {rf}: Rank {rank}/30, Importance {imp:.4f}\")\n\n# 2. Prediction distribution\nprint(f\"\\nPREDICTION DISTRIBUTION (test, raw):\")\nprint(f\"  Mean={pred_test.mean():.4f}, Std={pred_test.std():.4f}\")\nprint(f\"  Min={pred_test.min():.4f}, Max={pred_test.max():.4f}\")\nprint(f\"  Positive={((pred_test > 0).sum() / len(pred_test) * 100):.1f}%\")\n\n# 3. Naive baseline comparison\nnaive_always_up_da = (y_test > 0).sum() / len(y_test)\nprint(f\"\\nNaive always-up DA: {naive_always_up_da*100:.2f}%\")\nprint(f\"Model vs naive: {(test_m['direction_accuracy'] - naive_always_up_da)*100:+.2f}pp\")\n\n# 4. Vs previous attempts\nprint(f\"\\nVs Attempt 7:\")\nprint(f\"  DA:     {test_m['direction_accuracy']*100:.2f}% (Att7: 60.04%, delta: {(test_m['direction_accuracy']-0.6004)*100:+.2f}pp)\")\nprint(f\"  HCDA:   {primary_hcda_value*100:.2f}% (Att7: 64.13%, delta: {(primary_hcda_value-0.6413)*100:+.2f}pp)\")\nprint(f\"  MAE:    {test_m['mae']:.4f}% (Att7: 0.9429%, delta: {(test_m['mae']-0.9429)*100:+.2f}pp)\")\nprint(f\"  Sharpe: {test_m['sharpe_ratio']:.2f} (Att7: 2.46, delta: {test_m['sharpe_ratio']-2.4636:+.2f})\")\n\n# 5. Decile Analysis (|prediction| method)\nprint(f\"\\nDECILE ANALYSIS (test, |prediction|):\")\nn = len(pred_test)\nsorted_idx = np.argsort(-np.abs(pred_test))\ndecile_size = n // 10\nfor d in range(10):\n    start = d * decile_size\n    end = start + decile_size if d < 9 else n\n    idx = sorted_idx[start:end]\n    nonzero = (y_test[idx] != 0) & (pred_test[idx] != 0)\n    da = (np.sign(pred_test[idx[nonzero]]) == np.sign(y_test[idx[nonzero]])).mean() if nonzero.sum() > 0 else 0.0\n    print(f\"  Decile {d+1}: DA={da*100:5.1f}% (N={end-start})\")\n\n# 6. Quarterly breakdown\ntest_df_with_pred = test_df.copy()\ntest_df_with_pred['prediction'] = pred_test\ntest_df_with_pred['quarter'] = pd.to_datetime(test_df_with_pred.index).to_period('Q')\n\nprint(f\"\\nQUARTERLY PERFORMANCE (test):\")\nfor quarter in test_df_with_pred['quarter'].unique():\n    qd = test_df_with_pred[test_df_with_pred['quarter'] == quarter]\n    qda = compute_direction_accuracy(qd[TARGET].values, qd['prediction'].values)\n    qsh = compute_sharpe_trade_cost(qd[TARGET].values, qd['prediction'].values)\n    print(f\"  {quarter}: DA={qda*100:5.1f}%, Sharpe={qsh:5.2f}, N={len(qd)}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "print(\"\\n\" + \"=\"*60)\nprint(\"SAVING RESULTS\")\nprint(\"=\"*60)\n\n# 1. predictions.csv (full dataset, with BOTH raw and scaled)\nsplit_labels = ['train'] * len(dates_train) + ['val'] * len(dates_val) + ['test'] * len(dates_test)\npredictions_df = pd.DataFrame({\n    'date': dates_full,\n    'split': split_labels,\n    'actual': y_full,\n    'prediction_raw': pred_full,\n    'prediction_scaled': scaled_pred_full,\n    'direction_correct': (np.sign(pred_full) == np.sign(y_full)).astype(int),\n    'abs_prediction': np.abs(pred_full),\n})\n\n# Add high_confidence flags (80th percentile for both methods)\nthreshold_80_pred = np.percentile(np.abs(pred_full), 80)\npredictions_df['high_confidence_pred'] = (predictions_df['abs_prediction'] > threshold_80_pred).astype(int)\n\n# Bootstrap confidence for full dataset\nbootstrap_conf_full = np.concatenate([bootstrap_conf_train, bootstrap_conf_val, bootstrap_conf_test])\nthreshold_80_bootstrap = np.percentile(bootstrap_conf_full, 80)\npredictions_df['bootstrap_confidence'] = bootstrap_conf_full\npredictions_df['high_confidence_bootstrap'] = (predictions_df['bootstrap_confidence'] > threshold_80_bootstrap).astype(int)\n\n# Bootstrap std for full dataset\nbootstrap_std_full = np.concatenate([bootstrap_std_train, bootstrap_std_val, bootstrap_std_test])\npredictions_df['bootstrap_std'] = bootstrap_std_full\n\npredictions_df.to_csv('predictions.csv', index=False)\nprint(\"✓ Saved predictions.csv\")\n\n# 2. test_predictions.csv (test set only)\ntest_predictions_df = predictions_df[predictions_df['split'] == 'test'].copy()\ntest_predictions_df.to_csv('test_predictions.csv', index=False)\nprint(\"✓ Saved test_predictions.csv\")\n\n# 3. submodel_output.csv (for pipeline compatibility)\npredictions_df.to_csv('submodel_output.csv', index=False)\nprint(\"✓ Saved submodel_output.csv\")\n\n# 4. model.json (XGBoost model)\nfinal_model.save_model('model.json')\nprint(\"✓ Saved model.json\")\n\n# Find temporal_context_score rank and importance\ntc_rank = int((feature_ranking.reset_index(drop=True).reset_index()\n           .loc[feature_ranking['feature'] == 'temporal_context_score', 'index'].values[0] + 1))\ntc_importance = float(feature_ranking.loc[feature_ranking['feature'] == 'temporal_context_score', 'importance'].values[0])\n\n# Find options_risk_regime_prob rank and importance\noptions_rank = int((feature_ranking.reset_index(drop=True).reset_index()\n           .loc[feature_ranking['feature'] == 'options_risk_regime_prob', 'index'].values[0] + 1))\noptions_importance = float(feature_ranking.loc[feature_ranking['feature'] == 'options_risk_regime_prob', 'importance'].values[0])\n\n# 5. training_result.json (Attempt 8: stacking + regime features)\ntraining_result = {\n    'feature': 'meta_model',\n    'attempt': 8,\n    'timestamp': datetime.now().isoformat(),\n    'architecture': 'GBDT Stacking (XGB+LGBM+CatBoost) + Ridge Meta-Learner + Bootstrap confidence + OLS scaling',\n    'phase': '3_meta_model',\n    \n    'model_config': {\n        'n_features': 30,\n        'n_base_features': 24,\n        'n_regime_features': 6,\n        'regime_features': REGIME_FEATURE_COLUMNS,\n        'train_samples': len(X_train),\n        'val_samples': len(X_val),\n        'test_samples': len(X_test),\n        'samples_per_feature_ratio': round(len(X_train) / 30, 1),\n        'selected_configuration': selected_config,\n        'use_stacking': use_stacking,\n    },\n    \n    'stacking_config': {\n        'base_models': ['XGBoost', 'LightGBM', 'CatBoost'],\n        'meta_learner': 'Ridge',\n        'ridge_alpha': float(best_ridge_alpha),\n        'ridge_coefficients': {\n            'xgb': float(ridge_meta.coef_[0]),\n            'lgbm': float(ridge_meta.coef_[1]),\n            'catboost': float(ridge_meta.coef_[2]),\n        },\n        'ridge_intercept': float(ridge_meta.intercept_),\n        'prediction_correlations': {\n            'xgb_lgbm': float(corr_xgb_lgbm),\n            'xgb_cb': float(corr_xgb_cb),\n            'lgbm_cb': float(corr_lgbm_cb),\n        },\n        'base_model_val_metrics': {\n            'xgb': {\n                'da': float(compute_direction_accuracy(y_val, xgb_val_pred)),\n                'sharpe': float(compute_sharpe_trade_cost(y_val, xgb_val_pred)),\n            },\n            'lgbm': {\n                'da': float(compute_direction_accuracy(y_val, lgbm_val_pred)),\n                'sharpe': float(compute_sharpe_trade_cost(y_val, lgbm_val_pred)),\n            },\n            'catboost': {\n                'da': float(compute_direction_accuracy(y_val, cb_val_pred)),\n                'sharpe': float(compute_sharpe_trade_cost(y_val, cb_val_pred)),\n            },\n        },\n        'stacking_vs_single': {\n            'stacking_composite': float(stack_composite),\n            'single_xgb_composite': float(single_composite),\n            'fallback_composite': float(fb_composite),\n            'selected': best_config,\n        },\n    },\n    \n    'optuna_search': {\n        'xgb_trials': len(xgb_study.trials),\n        'xgb_best_value': float(xgb_study.best_value),\n        'lgbm_trials': len(lgbm_study.trials),\n        'lgbm_best_value': float(lgbm_study.best_value),\n        'cb_trials': len(cb_study.trials),\n        'cb_best_value': float(cb_study.best_value),\n        'ridge_trials': len(ridge_study.trials),\n        'total_trials': len(xgb_study.trials) + len(lgbm_study.trials) + len(cb_study.trials) + len(ridge_study.trials),\n        'xgb_best_params': xgb_study.best_params,\n        'lgbm_best_params': lgbm_study.best_params,\n        'cb_best_params': cb_study.best_params,\n        'objective_weights': '35/35/10/20 (Sharpe/DA/MAE/HCDA)',\n    },\n    \n    'bootstrap_analysis': {\n        'bootstrap_ensemble_size': 5,\n        'bootstrap_seeds': bootstrap_seeds,\n        'bootstrap_std_range_test': [float(bootstrap_std_test.min()), float(bootstrap_std_test.max())],\n        'bootstrap_std_mean_test': float(bootstrap_std_test.mean()),\n        'bootstrap_conf_range_test': [float(bootstrap_conf_test.min()), float(bootstrap_conf_test.max())],\n        'bootstrap_conf_mean_test': float(bootstrap_conf_test.mean()),\n        'hcda_bootstrap': float(hcda_bootstrap_test),\n        'hcda_pred': float(hcda_pred_test),\n        'hcda_improvement': float(hcda_bootstrap_test - hcda_pred_test),\n    },\n    \n    'ols_scaling': {\n        'alpha_ols': float(alpha_ols),\n        'mae_raw': float(mae_raw),\n        'mae_scaled': float(mae_scaled),\n        'mae_improvement': float(mae_raw - mae_scaled),\n    },\n    \n    'primary_hcda_method': primary_hcda_method,\n    'primary_hcda_value': float(primary_hcda_value),\n    'primary_mae': float(min(mae_raw, mae_scaled)),\n    \n    'metrics': metrics_all,\n    \n    'target_evaluation': {\n        'direction_accuracy': {\n            'target': '> 56.0%',\n            'actual': f\"{test_m['direction_accuracy']*100:.2f}%\",\n            'gap': f\"{(test_m['direction_accuracy'] - 0.56)*100:+.2f}pp\",\n            'passed': bool(targets_met[0]),\n        },\n        'high_confidence_da': {\n            'target': '> 60.0%',\n            'actual': f\"{primary_hcda_value*100:.2f}%\",\n            'gap': f\"{(primary_hcda_value - 0.60)*100:+.2f}pp\",\n            'passed': bool(targets_met[1]),\n            'method_used': primary_hcda_method,\n        },\n        'mae': {\n            'target': '< 0.75%',\n            'actual': f\"{test_m['mae']:.4f}%\",\n            'gap': f\"{(0.0075 - test_m['mae']):.4f}%\",\n            'passed': bool(targets_met[2]),\n        },\n        'sharpe_ratio': {\n            'target': '> 0.80',\n            'actual': f\"{test_m['sharpe_ratio']:.2f}\",\n            'gap': f\"{(test_m['sharpe_ratio'] - 0.8):+.2f}\",\n            'passed': bool(targets_met[3]),\n        },\n    },\n    \n    'targets_passed': sum(targets_met),\n    'targets_total': 4,\n    'overall_passed': all(targets_met),\n    \n    'overfitting_analysis': {\n        'train_test_da_gap_pp': float(train_test_da_gap),\n        'target_gap_pp': 10.0,\n        'overfitting_check': 'PASS' if train_test_da_gap < 10 else 'FAIL',\n    },\n    \n    'feature_importance': {\n        'top_10_xgb': feature_ranking.head(10).to_dict('records'),\n        'regime_feature_summary': {\n            rf: {\n                'rank': int((feature_ranking.reset_index(drop=True).reset_index()\n                    .loc[feature_ranking['feature'] == rf, 'index'].values[0] + 1)),\n                'importance': float(feature_ranking.loc[feature_ranking['feature'] == rf, 'importance'].values[0]),\n            }\n            for rf in REGIME_FEATURE_COLUMNS\n        },\n        'options_risk_regime_prob_rank': options_rank,\n        'options_risk_regime_prob_importance': options_importance,\n        'temporal_context_score_rank': tc_rank,\n        'temporal_context_score_importance': tc_importance,\n    },\n    \n    'vs_attempt_7': {\n        'da_delta_pp': float((test_m['direction_accuracy'] - 0.6004) * 100),\n        'hcda_delta_pp': float((primary_hcda_value - 0.6413) * 100),\n        'mae_delta': float(test_m['mae'] - 0.9429),\n        'sharpe_delta': float(test_m['sharpe_ratio'] - 2.4636),\n    },\n    \n    'vs_naive': {\n        'naive_always_up_da': f\"{naive_always_up_da*100:.2f}%\",\n        'model_vs_naive_pp': float((test_m['direction_accuracy'] - naive_always_up_da) * 100),\n    },\n    \n    'prediction_characteristics': {\n        'mean_raw': float(pred_test.mean()),\n        'std_raw': float(pred_test.std()),\n        'min_raw': float(pred_test.min()),\n        'max_raw': float(pred_test.max()),\n        'positive_pct': float((pred_test > 0).sum() / len(pred_test) * 100),\n    },\n}\n\nwith open('training_result.json', 'w') as f:\n    json.dump(training_result, f, indent=2, default=str)\nprint(\"✓ Saved training_result.json\")\n\nprint(f\"\\n{'='*60}\")\nprint(\"TRAINING COMPLETE\")\nprint(f\"{'='*60}\")\nprint(f\"Finished: {datetime.now().isoformat()}\")\nprint(f\"\\nFinal Status:\")\nprint(f\"  Configuration: {selected_config.upper()}\")\nprint(f\"  Stacking: {'YES' if use_stacking else 'NO'}\")\nprint(f\"  HCDA method: {primary_hcda_method.upper()}\")\nprint(f\"  MAE method: {'SCALED' if use_scaled else 'RAW'}\")\nprint(f\"  Features: {len(FEATURE_COLUMNS)} (24 base + 6 regime)\")\nprint(f\"  Targets passed: {sum(targets_met)}/4\")\nif all(targets_met):\n    print(f\"  ALL TARGETS MET\")\nelse:\n    failed = [t for t, m in zip(['DA', 'HCDA', 'MAE', 'Sharpe'], targets_met) if not m]\n    print(f\"  Improvements needed on: {failed}\")"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}