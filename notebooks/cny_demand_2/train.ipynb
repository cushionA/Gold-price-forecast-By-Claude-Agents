{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gold Prediction SubModel Training - CNY Demand Proxy Attempt 2\n",
    "\n",
    "**Self-contained**: Data fetch -> Deterministic momentum z-score -> Optuna window HPO -> Save results\n",
    "\n",
    "**Key changes from Attempt 1:**\n",
    "1. Single output column (was 3)\n",
    "2. No HMM, no hmmlearn (pure deterministic)\n",
    "3. Optimized momentum z-score with finer window grid\n",
    "\n",
    "**Feature**: cny_demand | **Attempt**: 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "from scipy.stats import pearsonr\n",
    "from sklearn.metrics import mutual_info_score\n",
    "import optuna\n",
    "from optuna.samplers import TPESampler\n",
    "import json\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "np.random.seed(42)\n",
    "print(f\"Training started: {datetime.now().isoformat()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Fetching and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_and_preprocess():\n",
    "    \"\"\"\n",
    "    Fetch CNY=X and GC=F, compute returns.\n",
    "    GC=F is for Optuna objective only, not feature input.\n",
    "    \"\"\"\n",
    "    # Fetch CNY=X\n",
    "    print(\"Fetching CNY=X (CNY/USD exchange rate)...\")\n",
    "    cny_data = yf.download('CNY=X', start='2014-06-01', progress=False)\n",
    "    if cny_data.empty:\n",
    "        raise RuntimeError(\"Failed to fetch CNY=X\")\n",
    "    \n",
    "    if isinstance(cny_data.columns, pd.MultiIndex):\n",
    "        cny_close = cny_data['Close']['CNY=X'].copy()\n",
    "    else:\n",
    "        cny_close = cny_data['Close'].copy()\n",
    "    cny_close = cny_close.dropna()\n",
    "    print(f\"CNY=X: {len(cny_close)} rows ({cny_close.index[0]} to {cny_close.index[-1]})\")\n",
    "    \n",
    "    # Validate range\n",
    "    assert cny_close.min() >= 5.5 and cny_close.max() <= 8.0, \\\n",
    "        f\"CNY/USD out of range: [{cny_close.min():.2f}, {cny_close.max():.2f}]\"\n",
    "    \n",
    "    # Fetch GC=F (for Optuna objective only)\n",
    "    print(\"Fetching GC=F (Gold Futures)...\")\n",
    "    gc_data = yf.download('GC=F', start='2014-06-01', progress=False)\n",
    "    if gc_data.empty:\n",
    "        raise RuntimeError(\"Failed to fetch GC=F\")\n",
    "    \n",
    "    if isinstance(gc_data.columns, pd.MultiIndex):\n",
    "        gc_close = gc_data['Close']['GC=F'].copy()\n",
    "    else:\n",
    "        gc_close = gc_data['Close'].copy()\n",
    "    gc_close = gc_close.dropna()\n",
    "    print(f\"GC=F: {len(gc_close)} rows ({gc_close.index[0]} to {gc_close.index[-1]})\")\n",
    "    \n",
    "    # Compute returns\n",
    "    cny_return = cny_close.pct_change()\n",
    "    gold_return = gc_close.pct_change()\n",
    "    gold_return_next = gold_return.shift(-1)  # Next-day gold return\n",
    "    \n",
    "    # Align dates (inner join)\n",
    "    df = pd.DataFrame({\n",
    "        'cny_close': cny_close,\n",
    "        'cny_return': cny_return,\n",
    "        'gold_return_next': gold_return_next\n",
    "    }).dropna()\n",
    "    \n",
    "    # Trim to base_features start date\n",
    "    df.index = pd.to_datetime(df.index)\n",
    "    base_start = pd.Timestamp('2015-01-30')\n",
    "    df_output = df[df.index >= base_start]\n",
    "    \n",
    "    print(f\"\\nAligned dataset: {len(df_output)} rows ({df_output.index[0]} to {df_output.index[-1]})\")\n",
    "    \n",
    "    # Data split 70/15/15\n",
    "    n = len(df_output)\n",
    "    train_end = int(n * 0.70)\n",
    "    val_end = int(n * 0.85)\n",
    "    \n",
    "    print(f\"Split: train={train_end}, val={val_end - train_end}, test={n - val_end}\")\n",
    "    \n",
    "    return df, df_output, train_end, val_end\n",
    "\n",
    "df_full, df_aligned, train_end, val_end = fetch_and_preprocess()\n",
    "print(\"\\nData ready!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Generation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_momentum_z(cny_return, momentum_window, baseline_window):\n",
    "    \"\"\"\n",
    "    Compute z-scored momentum: rolling sum of N-day returns,\n",
    "    z-scored against baseline_window-day rolling statistics.\n",
    "    \n",
    "    Args:\n",
    "        cny_return: pd.Series of daily CNY returns\n",
    "        momentum_window: int, days for cumulative return (3-10)\n",
    "        baseline_window: int, days for z-score baseline (30-120)\n",
    "    \n",
    "    Returns:\n",
    "        pd.Series: z-scored momentum, clipped to [-4, 4]\n",
    "    \"\"\"\n",
    "    momentum = cny_return.rolling(momentum_window).sum()\n",
    "    rolling_mean = momentum.rolling(baseline_window).mean()\n",
    "    rolling_std = momentum.rolling(baseline_window).std()\n",
    "    # Avoid division by zero\n",
    "    rolling_std = rolling_std.replace(0, np.nan)\n",
    "    z = (momentum - rolling_mean) / rolling_std\n",
    "    z = z.clip(-4, 4)\n",
    "    return z\n",
    "\n",
    "# Test with default params\n",
    "test_z = generate_momentum_z(df_aligned['cny_return'], 5, 60)\n",
    "print(f\"Test feature (5d/60d): non-NaN={test_z.notna().sum()}, mean={test_z.mean():.4f}, std={test_z.std():.4f}\")\n",
    "print(f\"Autocorrelation (lag-1): {test_z.autocorr(1):.4f}\")\n",
    "print(\"Feature generation function defined.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optuna Hyperparameter Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    \"\"\"\n",
    "    Maximize abs(Pearson correlation) + 10 * MI on validation set.\n",
    "    \"\"\"\n",
    "    momentum_window = trial.suggest_int('momentum_window', 3, 10)\n",
    "    baseline_window = trial.suggest_int('baseline_window', 30, 120, step=10)\n",
    "    \n",
    "    # Generate feature for full aligned dataset\n",
    "    z = generate_momentum_z(df_aligned['cny_return'], momentum_window, baseline_window)\n",
    "    \n",
    "    # Extract validation period\n",
    "    z_val = z.iloc[train_end:val_end]\n",
    "    target_val = df_aligned['gold_return_next'].iloc[train_end:val_end]\n",
    "    \n",
    "    # Drop NaN\n",
    "    valid = z_val.notna() & target_val.notna()\n",
    "    if valid.sum() < 50:\n",
    "        return 0.0\n",
    "    \n",
    "    z_clean = z_val[valid].values\n",
    "    target_clean = target_val[valid].values\n",
    "    \n",
    "    # Pearson correlation\n",
    "    corr, _ = pearsonr(z_clean, target_clean)\n",
    "    abs_corr = abs(corr)\n",
    "    \n",
    "    # Mutual information (discretized)\n",
    "    try:\n",
    "        z_disc = pd.qcut(z_clean, 20, labels=False, duplicates='drop')\n",
    "        t_disc = pd.qcut(target_clean, 20, labels=False, duplicates='drop')\n",
    "        mi = mutual_info_score(z_disc, t_disc)\n",
    "    except Exception:\n",
    "        mi = 0.0\n",
    "    \n",
    "    score = abs_corr + mi * 10\n",
    "    \n",
    "    # Log trial details\n",
    "    trial.set_user_attr('correlation', float(corr))\n",
    "    trial.set_user_attr('abs_corr', float(abs_corr))\n",
    "    trial.set_user_attr('mi', float(mi))\n",
    "    trial.set_user_attr('score', float(score))\n",
    "    \n",
    "    return score\n",
    "\n",
    "\n",
    "# Run Optuna\n",
    "print(\"Starting Optuna HPO (30 trials, 300s timeout)...\")\n",
    "study = optuna.create_study(\n",
    "    direction='maximize',\n",
    "    sampler=TPESampler(seed=42)\n",
    ")\n",
    "study.optimize(objective, n_trials=30, timeout=300, show_progress_bar=True)\n",
    "\n",
    "# Results\n",
    "best_params = study.best_params\n",
    "best_value = study.best_value\n",
    "n_completed = len([t for t in study.trials if t.state == optuna.trial.TrialState.COMPLETE])\n",
    "\n",
    "print(f\"\\nOptuna complete!\")\n",
    "print(f\"Completed trials: {n_completed}\")\n",
    "print(f\"Best score: {best_value:.6f}\")\n",
    "print(f\"Best parameters:\")\n",
    "for k, v in best_params.items():\n",
    "    print(f\"  {k}: {v}\")\n",
    "print(f\"\\nBest trial details:\")\n",
    "bt = study.best_trial\n",
    "print(f\"  Correlation: {bt.user_attrs['correlation']:.6f}\")\n",
    "print(f\"  Abs correlation: {bt.user_attrs['abs_corr']:.6f}\")\n",
    "print(f\"  MI: {bt.user_attrs['mi']:.6f}\")\n",
    "\n",
    "# Show top 5 trials\n",
    "print(f\"\\nTop 5 trials:\")\n",
    "sorted_trials = sorted(study.trials, key=lambda t: t.value if t.value else 0, reverse=True)\n",
    "for i, t in enumerate(sorted_trials[:5]):\n",
    "    if t.value:\n",
    "        print(f\"  #{t.number}: score={t.value:.6f}, mom={t.params['momentum_window']}, base={t.params['baseline_window']}, corr={t.user_attrs.get('correlation', 'N/A')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Final Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Generating final output with best parameters...\")\n",
    "momentum_window = best_params['momentum_window']\n",
    "baseline_window = best_params['baseline_window']\n",
    "\n",
    "# Generate feature for FULL dataset (including pre-2015 warmup)\n",
    "# Use df_full which starts from 2014-06-01 for proper warmup\n",
    "cny_return_full = df_full['cny_return']\n",
    "z_full = generate_momentum_z(cny_return_full, momentum_window, baseline_window)\n",
    "\n",
    "# Trim to aligned dates (2015-01-30+)\n",
    "z_aligned = z_full.reindex(df_aligned.index)\n",
    "\n",
    "# Create output DataFrame\n",
    "output_df = pd.DataFrame({\n",
    "    'cny_demand_momentum_z': z_aligned.values\n",
    "}, index=df_aligned.index)\n",
    "output_df.index.name = 'Date'\n",
    "\n",
    "print(f\"\\nOutput shape: {output_df.shape}\")\n",
    "print(f\"Output column: {list(output_df.columns)}\")\n",
    "print(f\"\\nOutput summary:\")\n",
    "print(output_df.describe())\n",
    "\n",
    "# Quality checks\n",
    "nan_count = output_df['cny_demand_momentum_z'].isna().sum()\n",
    "nan_pct = nan_count / len(output_df) * 100\n",
    "std_val = output_df['cny_demand_momentum_z'].std()\n",
    "autocorr = output_df['cny_demand_momentum_z'].dropna().autocorr(1)\n",
    "\n",
    "print(f\"\\nQuality checks:\")\n",
    "print(f\"  NaN count: {nan_count} ({nan_pct:.2f}%)\")\n",
    "print(f\"  Std: {std_val:.4f}\")\n",
    "print(f\"  Autocorrelation (lag-1): {autocorr:.4f}\")\n",
    "print(f\"  Min: {output_df['cny_demand_momentum_z'].min():.4f}\")\n",
    "print(f\"  Max: {output_df['cny_demand_momentum_z'].max():.4f}\")\n",
    "\n",
    "if std_val < 1e-6:\n",
    "    print(\"WARNING: Feature is essentially constant!\")\n",
    "if autocorr > 0.99:\n",
    "    print(\"WARNING: Autocorrelation > 0.99 (potential leak)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute correlation and MI on each split\n",
    "splits = {\n",
    "    'train': (0, train_end),\n",
    "    'val': (train_end, val_end),\n",
    "    'test': (val_end, len(df_aligned))\n",
    "}\n",
    "\n",
    "metrics = {}\n",
    "for split_name, (start, end) in splits.items():\n",
    "    z_split = output_df['cny_demand_momentum_z'].iloc[start:end]\n",
    "    target_split = df_aligned['gold_return_next'].iloc[start:end]\n",
    "    \n",
    "    valid = z_split.notna() & target_split.notna()\n",
    "    if valid.sum() > 50:\n",
    "        z_clean = z_split[valid].values\n",
    "        t_clean = target_split[valid].values\n",
    "        \n",
    "        corr, p_value = pearsonr(z_clean, t_clean)\n",
    "        \n",
    "        try:\n",
    "            z_disc = pd.qcut(z_clean, 20, labels=False, duplicates='drop')\n",
    "            t_disc = pd.qcut(t_clean, 20, labels=False, duplicates='drop')\n",
    "            mi = mutual_info_score(z_disc, t_disc)\n",
    "        except:\n",
    "            mi = 0.0\n",
    "        \n",
    "        metrics[split_name] = {\n",
    "            'correlation': float(corr),\n",
    "            'p_value': float(p_value),\n",
    "            'mi': float(mi),\n",
    "            'n_samples': int(valid.sum()),\n",
    "            'autocorrelation': float(z_split.dropna().autocorr(1)) if z_split.notna().sum() > 10 else None\n",
    "        }\n",
    "        \n",
    "        print(f\"\\n{split_name.upper()}:\")\n",
    "        print(f\"  Samples: {valid.sum()}\")\n",
    "        print(f\"  Correlation: {corr:.6f} (p={p_value:.4f})\")\n",
    "        print(f\"  MI: {mi:.6f}\")\n",
    "        print(f\"  Autocorrelation: {metrics[split_name]['autocorrelation']:.4f}\")\n",
    "    else:\n",
    "        metrics[split_name] = {'error': 'insufficient data'}\n",
    "        print(f\"\\n{split_name.upper()}: insufficient data\")\n",
    "\n",
    "print(\"\\nMetrics computed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nSaving results...\")\n",
    "\n",
    "# 1. Save submodel output\n",
    "output_df.to_csv('submodel_output.csv')\n",
    "print(\"  Saved: submodel_output.csv\")\n",
    "\n",
    "# 2. Save training result\n",
    "result = {\n",
    "    'feature': 'cny_demand',\n",
    "    'attempt': 2,\n",
    "    'timestamp': datetime.now().isoformat(),\n",
    "    'architecture': 'Deterministic momentum z-score (single output)',\n",
    "    'key_changes': [\n",
    "        'Single output column (was 3 in attempt 1)',\n",
    "        'No HMM, no hmmlearn (pure deterministic)',\n",
    "        'Optimized momentum and baseline windows via Optuna'\n",
    "    ],\n",
    "    'best_params': best_params,\n",
    "    'optuna_trials_completed': n_completed,\n",
    "    'optuna_best_value': float(best_value),\n",
    "    'metrics': metrics,\n",
    "    'output_shape': list(output_df.shape),\n",
    "    'output_columns': list(output_df.columns),\n",
    "    'quality_checks': {\n",
    "        'nan_count': int(nan_count),\n",
    "        'nan_pct': float(nan_pct),\n",
    "        'std': float(std_val),\n",
    "        'autocorrelation_lag1': float(autocorr),\n",
    "        'min': float(output_df['cny_demand_momentum_z'].min()),\n",
    "        'max': float(output_df['cny_demand_momentum_z'].max())\n",
    "    },\n",
    "    'data_info': {\n",
    "        'train_samples': train_end,\n",
    "        'val_samples': val_end - train_end,\n",
    "        'test_samples': len(df_aligned) - val_end,\n",
    "        'full_samples': len(df_aligned),\n",
    "        'date_range': {\n",
    "            'start': str(df_aligned.index[0]),\n",
    "            'end': str(df_aligned.index[-1])\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "with open('training_result.json', 'w') as f:\n",
    "    json.dump(result, f, indent=2, default=str)\n",
    "print(\"  Saved: training_result.json\")\n",
    "\n",
    "print(f\"\\n=== Training Complete! ===\")\n",
    "print(f\"Finished: {datetime.now().isoformat()}\")\n",
    "print(f\"\\nOutput: submodel_output.csv ({output_df.shape[0]} rows x {output_df.shape[1]} column)\")\n",
    "print(f\"Best params: momentum_window={best_params['momentum_window']}, baseline_window={best_params['baseline_window']}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
