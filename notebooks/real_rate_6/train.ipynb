{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gold Prediction SubModel Training - real_rate Attempt 6\n",
    "\n",
    "**Method**: Deterministic Bond Vol Regime + Rate Momentum Persistence\n",
    "\n",
    "**Self-contained**: Data fetch → Feature computation → Optuna HPO → Save results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Cell 1: Header + Libraries\nimport subprocess\nsubprocess.check_call(['pip', 'install', '-q', 'fredapi'])\n\nimport pandas as pd\nimport numpy as np\nimport json\nimport os\nimport warnings\nfrom datetime import datetime\n\nwarnings.filterwarnings('ignore')\n\n# FRED API\nfrom fredapi import Fred\nfred = Fred(api_key=\"3ffb68facdf6321e180e380c00e909c8\")\n\n# Optuna\nimport optuna\noptuna.logging.set_verbosity(optuna.logging.WARNING)\n\n# sklearn MI\nfrom sklearn.metrics import mutual_info_score\n\nprint(f\"Started: {datetime.now().isoformat()}\")\nprint(\"Libraries loaded successfully\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: Data Fetching\n",
    "print(\"=\" * 60)\n",
    "print(\"DATA FETCHING\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Fetch DFII10 from FRED (with buffer for rolling window warmup)\n",
    "dfii10_raw = fred.get_series('DFII10', observation_start='2014-01-01')\n",
    "dfii10_raw = dfii10_raw.dropna()\n",
    "print(f\"DFII10: {len(dfii10_raw)} observations, {dfii10_raw.index[0]} to {dfii10_raw.index[-1]}\")\n",
    "\n",
    "# Fetch gold prices for date alignment\n",
    "import yfinance as yf\n",
    "gold = yf.download('GC=F', start='2014-01-01', auto_adjust=True, progress=False)\n",
    "gold_dates = gold.index\n",
    "\n",
    "# Align DFII10 to gold trading calendar\n",
    "dfii10 = dfii10_raw.reindex(gold_dates, method='ffill')\n",
    "dfii10_change = dfii10.diff()\n",
    "\n",
    "print(f\"Aligned: {len(dfii10)} trading days\")\n",
    "print(f\"dfii10 range: [{dfii10.min():.4f}, {dfii10.max():.4f}]\")\n",
    "print(f\"dfii10_change range: [{dfii10_change.min():.4f}, {dfii10_change.max():.4f}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: Target variable\n",
    "# Compute gold return (next-day) as target for MI evaluation\n",
    "gold_close = gold['Close'].squeeze()\n",
    "gold_return = gold_close.pct_change() * 100  # percentage\n",
    "gold_return_next = gold_return.shift(-1)  # next-day return\n",
    "\n",
    "# Align all series\n",
    "common_dates = dfii10.dropna().index.intersection(gold_return_next.dropna().index)\n",
    "print(f\"Common dates: {len(common_dates)}, {common_dates[0]} to {common_dates[-1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: Feature computation functions\n",
    "def compute_bond_vol_z(dfii10_change, vol_window, zscore_window):\n",
    "    \"\"\"Bond Volatility Regime: realized vol of DFII10 changes, z-scored.\"\"\"\n",
    "    realized_vol = dfii10_change.rolling(window=vol_window, min_periods=vol_window).std()\n",
    "    # shift(1) to avoid look-ahead: z-score compares to PAST vol only\n",
    "    mean_vol = realized_vol.shift(1).rolling(window=zscore_window, min_periods=zscore_window).mean()\n",
    "    std_vol = realized_vol.shift(1).rolling(window=zscore_window, min_periods=zscore_window).std()\n",
    "    z = (realized_vol - mean_vol) / std_vol\n",
    "    z = z.clip(-4, 4)\n",
    "    return z\n",
    "\n",
    "def compute_momentum_z(dfii10_change, autocorr_window, zscore_window):\n",
    "    \"\"\"Rate Momentum Persistence: lag-1 autocorrelation of DFII10 changes, z-scored.\"\"\"\n",
    "    autocorr = dfii10_change.rolling(window=autocorr_window, min_periods=autocorr_window).apply(\n",
    "        lambda x: pd.Series(x).autocorr(lag=1), raw=False\n",
    "    )\n",
    "    # shift(1) to avoid look-ahead\n",
    "    mean_ac = autocorr.shift(1).rolling(window=zscore_window, min_periods=zscore_window).mean()\n",
    "    std_ac = autocorr.shift(1).rolling(window=zscore_window, min_periods=zscore_window).std()\n",
    "    z = (autocorr - mean_ac) / std_ac\n",
    "    z = z.clip(-4, 4)\n",
    "    return z\n",
    "\n",
    "def compute_mi(feature, target, n_bins=20):\n",
    "    \"\"\"Compute mutual information between feature and target using quantile binning.\"\"\"\n",
    "    mask = feature.notna() & target.notna()\n",
    "    f = feature[mask]\n",
    "    t = target[mask]\n",
    "    if len(f) < 100:\n",
    "        return 0.0\n",
    "    f_binned = pd.qcut(f, q=n_bins, labels=False, duplicates='drop')\n",
    "    t_binned = pd.qcut(t, q=n_bins, labels=False, duplicates='drop')\n",
    "    return mutual_info_score(f_binned, t_binned)\n",
    "\n",
    "print(\"Feature computation functions defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5: Data split\n",
    "print(\"=\" * 60)\n",
    "print(\"DATA SPLIT\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Schema date range\n",
    "SCHEMA_START = '2015-01-30'\n",
    "SCHEMA_END = '2025-02-12'\n",
    "\n",
    "# Filter to schema range for split\n",
    "schema_dates = common_dates[(common_dates >= SCHEMA_START) & (common_dates <= SCHEMA_END)]\n",
    "n = len(schema_dates)\n",
    "n_train = int(n * 0.70)\n",
    "n_val = int(n * 0.15)\n",
    "\n",
    "train_dates = schema_dates[:n_train]\n",
    "val_dates = schema_dates[n_train:n_train+n_val]\n",
    "test_dates = schema_dates[n_train+n_val:]\n",
    "\n",
    "print(f\"Total: {n}, Train: {len(train_dates)} ({train_dates[0]}~{train_dates[-1]})\")\n",
    "print(f\"Val: {len(val_dates)} ({val_dates[0]}~{val_dates[-1]})\")\n",
    "print(f\"Test: {len(test_dates)} ({test_dates[0]}~{test_dates[-1]})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 6: Optuna HPO\n",
    "print(\"=\" * 60)\n",
    "print(\"OPTUNA HYPERPARAMETER OPTIMIZATION\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "def optuna_objective(trial):\n",
    "    vol_window = trial.suggest_categorical('vol_window', [10, 15, 20])\n",
    "    vol_zscore_window = trial.suggest_categorical('vol_zscore_window', [60, 120])\n",
    "    autocorr_window = trial.suggest_categorical('autocorr_window', [5, 10, 15])\n",
    "    autocorr_zscore_window = trial.suggest_categorical('autocorr_zscore_window', [30, 60])\n",
    "    \n",
    "    bond_vol_z = compute_bond_vol_z(dfii10_change, vol_window, vol_zscore_window)\n",
    "    momentum_z = compute_momentum_z(dfii10_change, autocorr_window, autocorr_zscore_window)\n",
    "    \n",
    "    # MI on validation set only\n",
    "    target_val = gold_return_next.loc[val_dates]\n",
    "    mi_vol = compute_mi(bond_vol_z.loc[val_dates], target_val)\n",
    "    mi_mom = compute_mi(momentum_z.loc[val_dates], target_val)\n",
    "    \n",
    "    mi_sum = mi_vol + mi_mom\n",
    "    \n",
    "    # Log for reference\n",
    "    trial.set_user_attr('mi_vol', mi_vol)\n",
    "    trial.set_user_attr('mi_mom', mi_mom)\n",
    "    trial.set_user_attr('autocorr_vol', bond_vol_z.loc[val_dates].autocorr(lag=1))\n",
    "    trial.set_user_attr('autocorr_mom', momentum_z.loc[val_dates].autocorr(lag=1))\n",
    "    \n",
    "    return mi_sum\n",
    "\n",
    "study = optuna.create_study(\n",
    "    direction='maximize',\n",
    "    sampler=optuna.samplers.TPESampler(seed=42)\n",
    ")\n",
    "study.optimize(optuna_objective, n_trials=36, timeout=300)\n",
    "\n",
    "print(f\"\\nBest MI sum: {study.best_value:.6f}\")\n",
    "print(f\"Best params: {study.best_params}\")\n",
    "print(f\"Best MI vol: {study.best_trial.user_attrs['mi_vol']:.6f}\")\n",
    "print(f\"Best MI mom: {study.best_trial.user_attrs['mi_mom']:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 7: Generate final features with best params\n",
    "print(\"=\" * 60)\n",
    "print(\"GENERATING FINAL FEATURES\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "best = study.best_params\n",
    "print(f\"Generating final features with: {best}\")\n",
    "\n",
    "rr_bond_vol_z = compute_bond_vol_z(dfii10_change, best['vol_window'], best['vol_zscore_window'])\n",
    "rr_momentum_z = compute_momentum_z(dfii10_change, best['autocorr_window'], best['autocorr_zscore_window'])\n",
    "\n",
    "# Build output dataframe\n",
    "output = pd.DataFrame({\n",
    "    'rr_bond_vol_z': rr_bond_vol_z,\n",
    "    'rr_momentum_z': rr_momentum_z\n",
    "}, index=dfii10_change.index)\n",
    "\n",
    "# Trim to schema range\n",
    "output = output.loc[SCHEMA_START:SCHEMA_END]\n",
    "\n",
    "# Fill NaN (from rolling window warmup) with 0.0 (z-score neutral)\n",
    "nan_count_before = output.isna().sum().sum()\n",
    "output = output.fillna(0.0)\n",
    "\n",
    "print(f\"Output shape: {output.shape}\")\n",
    "print(f\"NaN filled: {nan_count_before}\")\n",
    "print(f\"Date range: {output.index[0]} to {output.index[-1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 8: Validation checks\n",
    "print(\"=\" * 60)\n",
    "print(\"VALIDATION CHECKS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "all_pass = True\n",
    "for col in ['rr_bond_vol_z', 'rr_momentum_z']:\n",
    "    autocorr_val = output[col].autocorr(lag=1)\n",
    "    std_val = output[col].std()\n",
    "    nan_val = output[col].isna().sum()\n",
    "    \n",
    "    ac_pass = autocorr_val < 0.95\n",
    "    std_pass = std_val > 0.1\n",
    "    nan_pass = nan_val == 0\n",
    "    \n",
    "    print(f\"\\n{col}:\")\n",
    "    print(f\"  autocorr(1) = {autocorr_val:.4f} {'PASS' if ac_pass else 'FAIL'} (< 0.95)\")\n",
    "    print(f\"  std = {std_val:.4f} {'PASS' if std_pass else 'FAIL'} (> 0.1)\")\n",
    "    print(f\"  NaN count = {nan_val} {'PASS' if nan_pass else 'FAIL'} (== 0)\")\n",
    "    print(f\"  mean = {output[col].mean():.4f}\")\n",
    "    print(f\"  min = {output[col].min():.4f}, max = {output[col].max():.4f}\")\n",
    "    \n",
    "    if not (ac_pass and std_pass and nan_pass):\n",
    "        all_pass = False\n",
    "\n",
    "# Cross-correlation\n",
    "cross_corr = output['rr_bond_vol_z'].corr(output['rr_momentum_z'])\n",
    "print(f\"\\nCross-correlation: {cross_corr:.4f}\")\n",
    "print(f\"\\nOverall: {'ALL PASS' if all_pass else 'SOME CHECKS FAILED'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 9: Detailed diagnostics (train/val/test splits)\n",
    "print(\"=\" * 60)\n",
    "print(\"DIAGNOSTICS BY SPLIT\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for split_name, split_dates in [('Train', train_dates), ('Val', val_dates), ('Test', test_dates)]:\n",
    "    split_data = output.loc[output.index.isin(split_dates)]\n",
    "    print(f\"\\n--- {split_name} ({len(split_data)} rows) ---\")\n",
    "    for col in ['rr_bond_vol_z', 'rr_momentum_z']:\n",
    "        s = split_data[col]\n",
    "        print(f\"  {col}: mean={s.mean():.4f}, std={s.std():.4f}, \"\n",
    "              f\"min={s.min():.4f}, max={s.max():.4f}, autocorr={s.autocorr(lag=1):.4f}\")\n",
    "    \n",
    "    # MI with target on this split\n",
    "    target_split = gold_return_next.loc[gold_return_next.index.isin(split_dates)]\n",
    "    for col in ['rr_bond_vol_z', 'rr_momentum_z']:\n",
    "        mi = compute_mi(split_data[col], target_split)\n",
    "        print(f\"  MI({col}, target) = {mi:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 10: Save outputs\n",
    "print(\"=\" * 60)\n",
    "print(\"SAVING OUTPUTS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# 1. Save submodel output CSV\n",
    "output_csv = output.copy()\n",
    "output_csv.index.name = 'date'\n",
    "output_csv.to_csv('submodel_output.csv')\n",
    "print(f\"Saved submodel_output.csv: {output_csv.shape}\")\n",
    "\n",
    "# 2. Save training_result.json\n",
    "result = {\n",
    "    \"feature\": \"real_rate\",\n",
    "    \"attempt\": 6,\n",
    "    \"method\": \"deterministic_bond_vol_momentum_zscore\",\n",
    "    \"timestamp\": datetime.now().isoformat(),\n",
    "    \"best_params\": best,\n",
    "    \"validation_mi_sum\": study.best_value,\n",
    "    \"per_feature_mi\": {\n",
    "        \"rr_bond_vol_z\": study.best_trial.user_attrs['mi_vol'],\n",
    "        \"rr_momentum_z\": study.best_trial.user_attrs['mi_mom']\n",
    "    },\n",
    "    \"autocorrelation\": {\n",
    "        \"rr_bond_vol_z\": float(output['rr_bond_vol_z'].autocorr(lag=1)),\n",
    "        \"rr_momentum_z\": float(output['rr_momentum_z'].autocorr(lag=1))\n",
    "    },\n",
    "    \"cross_correlation\": float(cross_corr),\n",
    "    \"output_shape\": list(output.shape),\n",
    "    \"output_columns\": [\"rr_bond_vol_z\", \"rr_momentum_z\"],\n",
    "    \"output_stats\": {\n",
    "        col: {\n",
    "            \"mean\": float(output[col].mean()),\n",
    "            \"std\": float(output[col].std()),\n",
    "            \"min\": float(output[col].min()),\n",
    "            \"max\": float(output[col].max())\n",
    "        }\n",
    "        for col in ['rr_bond_vol_z', 'rr_momentum_z']\n",
    "    },\n",
    "    \"nan_filled_rows\": int(nan_count_before),\n",
    "    \"n_optuna_trials\": len(study.trials),\n",
    "    \"total_combinations\": 36,\n",
    "    \"all_checks_passed\": all_pass,\n",
    "    \"split_info\": {\n",
    "        \"train_rows\": len(train_dates),\n",
    "        \"val_rows\": len(val_dates),\n",
    "        \"test_rows\": len(test_dates)\n",
    "    }\n",
    "}\n",
    "\n",
    "with open('training_result.json', 'w') as f:\n",
    "    json.dump(result, f, indent=2)\n",
    "print(f\"Saved training_result.json\")\n",
    "\n",
    "print(f\"\\nFinished: {datetime.now().isoformat()}\")\n",
    "print(\"Training complete!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}