{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "# Gold Meta-Model Training - Attempt 17\n",
    "\n",
    "**Architecture:** XGBoost (attempt 7 exact hyperparameters) + Bootstrap DATA SUBSAMPLING ensemble (12 models)\n",
    "\n",
    "**Key Design:**\n",
    "- Attempt 7 (XGBoost, single model): DA 60.04%, HCDA 64.13%, Sharpe 2.46 (BEST DA and Sharpe)\n",
    "- Attempt 16 (LightGBM + bootstrap 5-seed): DA 58.52%, HCDA 68.48% (BEST HCDA)\n",
    "- Attempt 17: XGBoost attempt 7 hyperparameters + bootstrap DATA SUBSAMPLING (genuine diversity)\n",
    "\n",
    "**Why data subsampling (not seed variation):**\n",
    "Attempt 7 tried 5-seed bootstrap but std_mean=0.008 (too uniform, models agreed too closely).\n",
    "Attempt 16's LightGBM + seed bootstrap achieved std_mean=0.025 (sufficient diversity).\n",
    "Data subsampling trains each ensemble member on a different 80% bootstrap sample (with replacement),\n",
    "creating genuine prediction diversity while preserving XGBoost's superior base performance.\n",
    "\n",
    "**NO Optuna HPO** - using exact attempt 7 hyperparameters.\n",
    "**BOTH HCDA methods** computed: bootstrap std-based and |prediction|-based."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "import json\n",
    "import os\n",
    "import glob\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "print(f\"XGBoost version: {xgb.__version__}\")\n",
    "print(f\"Pandas version: {pd.__version__}\")\n",
    "print(f\"NumPy version: {np.__version__}\")\n",
    "print(f\"Started: {datetime.now().isoformat()}\")\n",
    "print(f\"Attempt: 17\")\n",
    "print(f\"Architecture: XGBoost (attempt 7 params) + Bootstrap Data Subsampling Ensemble\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"FETCHING DATA FROM APIs\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "import yfinance as yf\n",
    "\n",
    "try:\n",
    "    from fredapi import Fred\n",
    "except ImportError:\n",
    "    import subprocess\n",
    "    subprocess.run([\"pip\", \"install\", \"fredapi\"], check=True)\n",
    "    from fredapi import Fred\n",
    "\n",
    "FRED_API_KEY = os.environ['FRED_API_KEY']\n",
    "fred = Fred(api_key=FRED_API_KEY)\n",
    "print(\"FRED API initialized\")\n",
    "\n",
    "# Gold Price\n",
    "print(\"\\nFetching gold price (GC=F)...\")\n",
    "gold = yf.download('GC=F', start='2014-01-01', end='2026-02-20', progress=False)\n",
    "if gold.empty:\n",
    "    raise ValueError(\"Gold price data is empty - yf.download('GC=F') returned no data\")\n",
    "gold_df = gold[['Close']].copy()\n",
    "gold_df.columns = ['gold_price']\n",
    "gold_df['gold_return'] = gold_df['gold_price'].pct_change() * 100\n",
    "gold_df['gold_return_next'] = gold_df['gold_return'].shift(-1)\n",
    "gold_df = gold_df.dropna(subset=['gold_return_next'])\n",
    "gold_df.index = pd.to_datetime(gold_df.index).strftime('%Y-%m-%d')\n",
    "print(f\"  Gold: {len(gold_df)} rows\")\n",
    "\n",
    "print(\"\\nFetching base features...\")\n",
    "\n",
    "real_rate = fred.get_series('DFII10', observation_start='2014-01-01')\n",
    "real_rate_df = real_rate.to_frame('real_rate_real_rate')\n",
    "real_rate_df.index = pd.to_datetime(real_rate_df.index).strftime('%Y-%m-%d')\n",
    "\n",
    "dxy = yf.download('DX-Y.NYB', start='2014-01-01', end='2026-02-20', progress=False)\n",
    "if dxy.empty:\n",
    "    raise ValueError(\"DXY data is empty - yf.download('DX-Y.NYB') returned no data\")\n",
    "dxy_df = dxy[['Close']].copy()\n",
    "dxy_df.columns = ['dxy_dxy']\n",
    "dxy_df.index = pd.to_datetime(dxy_df.index).strftime('%Y-%m-%d')\n",
    "\n",
    "vix = fred.get_series('VIXCLS', observation_start='2014-01-01')\n",
    "vix_df = vix.to_frame('vix_vix')\n",
    "vix_df.index = pd.to_datetime(vix_df.index).strftime('%Y-%m-%d')\n",
    "\n",
    "dgs10 = fred.get_series('DGS10', observation_start='2014-01-01')\n",
    "dgs2 = fred.get_series('DGS2', observation_start='2014-01-01')\n",
    "yc_df = pd.DataFrame({'DGS10': dgs10, 'DGS2': dgs2})\n",
    "yc_df['yield_curve_yield_spread'] = yc_df['DGS10'] - yc_df['DGS2']\n",
    "yc_df = yc_df[['yield_curve_yield_spread']]\n",
    "yc_df.index = pd.to_datetime(yc_df.index).strftime('%Y-%m-%d')\n",
    "\n",
    "infl_exp = fred.get_series('T10YIE', observation_start='2014-01-01')\n",
    "infl_exp_df = infl_exp.to_frame('inflation_expectation_inflation_expectation')\n",
    "infl_exp_df.index = pd.to_datetime(infl_exp_df.index).strftime('%Y-%m-%d')\n",
    "\n",
    "base_features = gold_df[['gold_return_next']].copy()\n",
    "for df in [real_rate_df, dxy_df, vix_df, yc_df, infl_exp_df]:\n",
    "    base_features = base_features.join(df, how='left')\n",
    "base_features = base_features.ffill()\n",
    "print(f\"  Base features: {len(base_features)} rows, {len(base_features.columns)} columns\")\n",
    "print(\"\\nData fetching complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nApplying transformations...\")\n",
    "\n",
    "final_df = base_features.copy()\n",
    "\n",
    "final_df['real_rate_change'] = final_df['real_rate_real_rate'].diff()\n",
    "final_df['dxy_change'] = final_df['dxy_dxy'].diff()\n",
    "final_df['vix'] = final_df['vix_vix']\n",
    "final_df['yield_spread_change'] = final_df['yield_curve_yield_spread'].diff()\n",
    "final_df['inflation_exp_change'] = final_df['inflation_expectation_inflation_expectation'].diff()\n",
    "\n",
    "final_df = final_df.drop(columns=['real_rate_real_rate', 'dxy_dxy', 'vix_vix',\n",
    "                                    'yield_curve_yield_spread', 'inflation_expectation_inflation_expectation'])\n",
    "\n",
    "print(f\"  Base transformations applied\")\n",
    "print(f\"  Columns so far: {list(final_df.columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-4",
   "metadata": {},
   "outputs": [],
   "source": [
    "FEATURE_COLUMNS = [\n",
    "    # Base features (5)\n",
    "    'real_rate_change',\n",
    "    'dxy_change',\n",
    "    'vix',\n",
    "    'yield_spread_change',\n",
    "    'inflation_exp_change',\n",
    "    # VIX submodel (3)\n",
    "    'vix_regime_probability',\n",
    "    'vix_mean_reversion_z',\n",
    "    'vix_persistence',\n",
    "    # Technical submodel (3)\n",
    "    'tech_trend_regime_prob',\n",
    "    'tech_mean_reversion_z',\n",
    "    'tech_volatility_regime',\n",
    "    # Cross-asset submodel (3)\n",
    "    'xasset_regime_prob',\n",
    "    'xasset_recession_signal',\n",
    "    'xasset_divergence',\n",
    "    # Yield curve submodel (2)\n",
    "    'yc_spread_velocity_z',\n",
    "    'yc_curvature_z',\n",
    "    # ETF flow submodel (3)\n",
    "    'etf_regime_prob',\n",
    "    'etf_capital_intensity',\n",
    "    'etf_pv_divergence',\n",
    "    # Inflation expectation submodel (3)\n",
    "    'ie_regime_prob',\n",
    "    'ie_anchoring_z',\n",
    "    'ie_gold_sensitivity_z',\n",
    "    # Options market submodel (1)\n",
    "    'options_risk_regime_prob',\n",
    "    # Temporal context submodel (1)\n",
    "    'temporal_context_score',\n",
    "]\n",
    "\n",
    "TARGET = 'gold_return_next'\n",
    "\n",
    "assert len(FEATURE_COLUMNS) == 24, f\"Expected 24 features, got {len(FEATURE_COLUMNS)}\"\n",
    "print(f\"Features defined: {len(FEATURE_COLUMNS)} features\")\n",
    "print(f\"Feature list: {FEATURE_COLUMNS}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# DATASET PATH RESOLUTION (robust: use glob + pd.read_csv probe)\n",
    "# API-created kernels: /kaggle/input/datasets/{owner}/{slug}/\n",
    "# Web-UI-created kernels: /kaggle/input/{slug}/\n",
    "# Use glob to find the file, then probe with pd.read_csv to verify\n",
    "# ============================================================\n",
    "import pandas as _pd_probe\n",
    "DATASET_SLUG = 'gold-prediction-submodels'\n",
    "DATASET_OWNER = 'bigbigzabuton'\n",
    "_PROBE_FILE = 'vix.csv'\n",
    "\n",
    "# Use glob to search all plausible locations with absolute paths\n",
    "_glob_patterns = [\n",
    "    f'/kaggle/input/datasets/{DATASET_OWNER}/{DATASET_SLUG}/{_PROBE_FILE}',\n",
    "    f'/kaggle/input/{DATASET_SLUG}/{_PROBE_FILE}',\n",
    "    f'/kaggle/input/datasets/*/{DATASET_SLUG}/{_PROBE_FILE}',\n",
    "    f'/kaggle/input/*/{_PROBE_FILE}',\n",
    "]\n",
    "\n",
    "DATASET_BASE = None\n",
    "for _pattern in _glob_patterns:\n",
    "    _matches = glob.glob(_pattern)\n",
    "    if _matches:\n",
    "        _candidate_base = os.path.dirname(_matches[0])\n",
    "        # Verify by actually reading the file with pandas\n",
    "        try:\n",
    "            _pd_probe.read_csv(_matches[0], nrows=1)\n",
    "            DATASET_BASE = _candidate_base\n",
    "            print(f\"Dataset found at: {DATASET_BASE} (pattern: {_pattern})\")\n",
    "            break\n",
    "        except Exception as _e:\n",
    "            print(f\"  Found at {_matches[0]} but read failed: {_e}\")\n",
    "\n",
    "if DATASET_BASE is None:\n",
    "    print(\"ERROR: Dataset not found via glob! Searched patterns:\")\n",
    "    for _p in _glob_patterns:\n",
    "        print(f\"  {_p} -> {glob.glob(_p)}\")\n",
    "    print(\"\\nFull /kaggle/input/ listing:\")\n",
    "    try:\n",
    "        import subprocess as _sp\n",
    "        _r = _sp.run(['find', '/kaggle/input', '-name', _PROBE_FILE, '-type', 'f'],\n",
    "                     capture_output=True, text=True, timeout=15)\n",
    "        print(f\"  find result: {_r.stdout.strip() or '(nothing found)'}\")\n",
    "        print(f\"  find stderr: {_r.stderr.strip()}\")\n",
    "    except Exception as _e:\n",
    "        print(f\"  find failed: {_e}\")\n",
    "    raise FileNotFoundError(\n",
    "        f\"Dataset '{DATASET_SLUG}' not found. \"\n",
    "        f\"Tried patterns: {_glob_patterns}. \"\n",
    "        \"Ensure dataset_sources includes 'bigbigzabuton/gold-prediction-submodels' in kernel-metadata.json.\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nLoading submodel outputs from Kaggle Dataset...\")\n",
    "\n",
    "submodel_files = {\n",
    "    'vix': {\n",
    "        'path': f'{DATASET_BASE}/vix.csv',\n",
    "        'columns': ['vix_regime_probability', 'vix_mean_reversion_z', 'vix_persistence'],\n",
    "        'date_col': 'date',\n",
    "        'tz_aware': False,\n",
    "    },\n",
    "    'technical': {\n",
    "        'path': f'{DATASET_BASE}/technical.csv',\n",
    "        'columns': ['tech_trend_regime_prob', 'tech_mean_reversion_z', 'tech_volatility_regime'],\n",
    "        'date_col': 'date',\n",
    "        'tz_aware': True,\n",
    "    },\n",
    "    'cross_asset': {\n",
    "        'path': f'{DATASET_BASE}/cross_asset.csv',\n",
    "        'columns': ['xasset_regime_prob', 'xasset_recession_signal', 'xasset_divergence'],\n",
    "        'date_col': 'Date',\n",
    "        'tz_aware': False,\n",
    "    },\n",
    "    'yield_curve': {\n",
    "        'path': f'{DATASET_BASE}/yield_curve.csv',\n",
    "        'columns': ['yc_spread_velocity_z', 'yc_curvature_z'],\n",
    "        'date_col': 'index',\n",
    "        'tz_aware': False,\n",
    "    },\n",
    "    'etf_flow': {\n",
    "        'path': f'{DATASET_BASE}/etf_flow.csv',\n",
    "        'columns': ['etf_regime_prob', 'etf_capital_intensity', 'etf_pv_divergence'],\n",
    "        'date_col': 'Date',\n",
    "        'tz_aware': False,\n",
    "    },\n",
    "    'inflation_expectation': {\n",
    "        'path': f'{DATASET_BASE}/inflation_expectation.csv',\n",
    "        'columns': ['ie_regime_prob', 'ie_anchoring_z', 'ie_gold_sensitivity_z'],\n",
    "        'date_col': 'Unnamed: 0',\n",
    "        'tz_aware': False,\n",
    "    },\n",
    "    'options_market': {\n",
    "        'path': f'{DATASET_BASE}/options_market.csv',\n",
    "        'columns': ['options_risk_regime_prob'],\n",
    "        'date_col': 'Date',\n",
    "        'tz_aware': True,\n",
    "    },\n",
    "    'temporal_context': {\n",
    "        'path': f'{DATASET_BASE}/temporal_context.csv',\n",
    "        'columns': ['temporal_context_score'],\n",
    "        'date_col': 'date',\n",
    "        'tz_aware': False,\n",
    "    },\n",
    "}\n",
    "\n",
    "submodel_dfs = {}\n",
    "for feature, spec in submodel_files.items():\n",
    "    df = pd.read_csv(spec['path'])\n",
    "    date_col = spec['date_col']\n",
    "    if spec['tz_aware']:\n",
    "        df['Date'] = pd.to_datetime(df[date_col], utc=True).dt.strftime('%Y-%m-%d')\n",
    "    else:\n",
    "        if date_col == 'index':\n",
    "            df['Date'] = pd.to_datetime(df.iloc[:, 0]).dt.strftime('%Y-%m-%d')\n",
    "        elif date_col == 'Unnamed: 0':\n",
    "            df['Date'] = pd.to_datetime(df['Unnamed: 0']).dt.strftime('%Y-%m-%d')\n",
    "        else:\n",
    "            df['Date'] = pd.to_datetime(df[date_col]).dt.strftime('%Y-%m-%d')\n",
    "    df = df[['Date'] + spec['columns']]\n",
    "    df = df.set_index('Date')\n",
    "    submodel_dfs[feature] = df\n",
    "    print(f\"  {feature}: {len(df)} rows\")\n",
    "\n",
    "print(\"\\nMerging submodel outputs...\")\n",
    "for feature, df in submodel_dfs.items():\n",
    "    final_df = final_df.join(df, how='left')\n",
    "print(f\"  Features after merge: {final_df.shape[1]} columns, {len(final_df)} rows\")\n",
    "\n",
    "print(\"\\nApplying NaN imputation...\")\n",
    "nan_before = final_df.isna().sum().sum()\n",
    "print(f\"  NaN before imputation: {nan_before}\")\n",
    "\n",
    "regime_cols = ['vix_regime_probability', 'tech_trend_regime_prob',\n",
    "               'xasset_regime_prob', 'etf_regime_prob', 'ie_regime_prob',\n",
    "               'options_risk_regime_prob', 'temporal_context_score']\n",
    "for col in regime_cols:\n",
    "    if col in final_df.columns:\n",
    "        final_df[col] = final_df[col].fillna(0.5)\n",
    "\n",
    "z_cols = ['vix_mean_reversion_z', 'tech_mean_reversion_z',\n",
    "          'yc_spread_velocity_z', 'yc_curvature_z',\n",
    "          'etf_capital_intensity', 'etf_pv_divergence',\n",
    "          'ie_anchoring_z', 'ie_gold_sensitivity_z']\n",
    "for col in z_cols:\n",
    "    if col in final_df.columns:\n",
    "        final_df[col] = final_df[col].fillna(0.0)\n",
    "\n",
    "div_cols = ['xasset_recession_signal', 'xasset_divergence']\n",
    "for col in div_cols:\n",
    "    if col in final_df.columns:\n",
    "        final_df[col] = final_df[col].fillna(0.0)\n",
    "\n",
    "cont_cols = ['tech_volatility_regime', 'vix_persistence']\n",
    "for col in cont_cols:\n",
    "    if col in final_df.columns:\n",
    "        final_df[col] = final_df[col].fillna(final_df[col].median())\n",
    "\n",
    "final_df = final_df.dropna(subset=['gold_return_next', 'real_rate_change', 'dxy_change',\n",
    "                                     'vix', 'yield_spread_change', 'inflation_exp_change'])\n",
    "\n",
    "nan_after = final_df.isna().sum().sum()\n",
    "print(f\"  NaN after imputation: {nan_after}\")\n",
    "print(f\"  Final dataset: {len(final_df)} rows\")\n",
    "\n",
    "assert all(col in final_df.columns for col in FEATURE_COLUMNS), \"Missing features after merge!\"\n",
    "assert TARGET in final_df.columns, \"Target not found!\"\n",
    "print(f\"\\nAll {len(FEATURE_COLUMNS)} features present\")\n",
    "print(f\"Dataset shape: {final_df.shape}\")\n",
    "print(f\"Date range: {final_df.index.min()} to {final_df.index.max()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-7",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_total = len(final_df)\n",
    "n_train = int(n_total * 0.70)\n",
    "n_val = int(n_total * 0.15)\n",
    "\n",
    "train_df = final_df.iloc[:n_train].copy()\n",
    "val_df = final_df.iloc[n_train:n_train+n_val].copy()\n",
    "test_df = final_df.iloc[n_train+n_val:].copy()\n",
    "\n",
    "print(f\"\\nData split complete:\")\n",
    "print(f\"  Train: {len(train_df)} rows ({len(train_df)/n_total*100:.1f}%) - {train_df.index.min()} to {train_df.index.max()}\")\n",
    "print(f\"  Val:   {len(val_df)} rows ({len(val_df)/n_total*100:.1f}%) - {val_df.index.min()} to {val_df.index.max()}\")\n",
    "print(f\"  Test:  {len(test_df)} rows ({len(test_df)/n_total*100:.1f}%) - {test_df.index.min()} to {test_df.index.max()}\")\n",
    "print(f\"  Total: {n_total} rows\")\n",
    "print(f\"  Samples per feature: {n_train / len(FEATURE_COLUMNS):.1f}:1 (train)\")\n",
    "\n",
    "assert train_df.index.max() < val_df.index.min(), \"Train-val overlap detected!\"\n",
    "assert val_df.index.max() < test_df.index.min(), \"Val-test overlap detected!\"\n",
    "print(f\"\\nNo time-series leakage detected\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "X_train = train_df[FEATURE_COLUMNS].values\n",
    "y_train = train_df[TARGET].values\n",
    "X_val = val_df[FEATURE_COLUMNS].values\n",
    "y_val = val_df[TARGET].values\n",
    "X_test = test_df[FEATURE_COLUMNS].values\n",
    "y_test = test_df[TARGET].values\n",
    "\n",
    "X_train_df = train_df[FEATURE_COLUMNS]\n",
    "X_val_df = val_df[FEATURE_COLUMNS]\n",
    "X_test_df = test_df[FEATURE_COLUMNS]\n",
    "\n",
    "dates_train = train_df.index\n",
    "dates_val = val_df.index\n",
    "dates_test = test_df.index\n",
    "\n",
    "print(f\"\\nArray shapes:\")\n",
    "print(f\"  X_train: {X_train.shape}, y_train: {y_train.shape}\")\n",
    "print(f\"  X_val:   {X_val.shape}, y_val:   {y_val.shape}\")\n",
    "print(f\"  X_test:  {X_test.shape}, y_test:  {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_direction_accuracy(y_true, y_pred):\n",
    "    mask = (y_true != 0) & (y_pred != 0)\n",
    "    if mask.sum() == 0:\n",
    "        return 0.0\n",
    "    return (np.sign(y_pred[mask]) == np.sign(y_true[mask])).mean()\n",
    "\n",
    "def compute_mae(y_true, y_pred):\n",
    "    return np.abs(y_pred - y_true).mean()\n",
    "\n",
    "def compute_sharpe_trade_cost(y_true, y_pred, cost_bps=5.0):\n",
    "    positions = np.sign(y_pred)\n",
    "    strategy_returns = positions * y_true / 100.0\n",
    "    position_changes = np.abs(np.diff(positions, prepend=0))\n",
    "    trade_costs = position_changes * (cost_bps / 10000.0)\n",
    "    net_returns = strategy_returns - trade_costs\n",
    "    if len(net_returns) < 2 or net_returns.std() == 0:\n",
    "        return 0.0\n",
    "    return (net_returns.mean() / net_returns.std()) * np.sqrt(252)\n",
    "\n",
    "def compute_hcda_abs(y_true, y_pred, threshold_percentile=80):\n",
    "    \"\"\"HCDA via |prediction| magnitude (attempt 7 approach)\"\"\"\n",
    "    threshold = np.percentile(np.abs(y_pred), threshold_percentile)\n",
    "    hc_mask = np.abs(y_pred) >= threshold\n",
    "    if hc_mask.sum() == 0:\n",
    "        return 0.0, 0.0\n",
    "    coverage = hc_mask.sum() / len(y_pred)\n",
    "    hc_pred = y_pred[hc_mask]\n",
    "    hc_actual = y_true[hc_mask]\n",
    "    mask = (hc_actual != 0) & (hc_pred != 0)\n",
    "    if mask.sum() == 0:\n",
    "        return 0.0, coverage\n",
    "    da = (np.sign(hc_pred[mask]) == np.sign(hc_actual[mask])).mean()\n",
    "    return float(da), float(coverage)\n",
    "\n",
    "def compute_hcda_bootstrap(y_true, y_pred, bootstrap_std, low_std_pct=20):\n",
    "    \"\"\"HCDA via bootstrap std - low std = high confidence (attempt 16 approach)\"\"\"\n",
    "    # Bottom X% by std = highest confidence\n",
    "    threshold_std = np.percentile(bootstrap_std, low_std_pct)\n",
    "    hc_mask = bootstrap_std <= threshold_std\n",
    "    if hc_mask.sum() == 0:\n",
    "        return 0.0, 0.0\n",
    "    coverage = hc_mask.sum() / len(y_pred)\n",
    "    hc_pred = y_pred[hc_mask]\n",
    "    hc_actual = y_true[hc_mask]\n",
    "    mask = (hc_actual != 0) & (hc_pred != 0)\n",
    "    if mask.sum() == 0:\n",
    "        return 0.0, coverage\n",
    "    da = (np.sign(hc_pred[mask]) == np.sign(hc_actual[mask])).mean()\n",
    "    return float(da), float(coverage)\n",
    "\n",
    "print(\"Metric functions defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# XGBoost Hyperparameters - Attempt 7 Exact Values (NO Optuna)\n",
    "# ============================================================\n",
    "print(\"=\"*60)\n",
    "print(\"XGBOOST HYPERPARAMETERS (ATTEMPT 7 EXACT - NO HPO)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "xgb_params = {\n",
    "    \"objective\": \"reg:squarederror\",\n",
    "    \"max_depth\": 2,\n",
    "    \"min_child_weight\": 25,\n",
    "    \"subsample\": 0.765,\n",
    "    \"colsample_bytree\": 0.450,\n",
    "    \"reg_lambda\": 2.049,\n",
    "    \"reg_alpha\": 1.107,\n",
    "    \"learning_rate\": 0.0215,\n",
    "    \"n_estimators\": 621,\n",
    "    \"tree_method\": \"hist\",\n",
    "    \"device\": \"cuda\",\n",
    "    \"random_state\": 42,\n",
    "    \"verbosity\": 0,\n",
    "}\n",
    "\n",
    "print(\"XGBoost parameters (from attempt 7):\")\n",
    "for k, v in xgb_params.items():\n",
    "    print(f\"  {k}: {v}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Bootstrap Data Subsampling Ensemble Training\n",
    "# Each model trains on a different 80% bootstrap sample\n",
    "# ============================================================\n",
    "print(\"=\"*60)\n",
    "print(\"BOOTSTRAP DATA SUBSAMPLING ENSEMBLE TRAINING\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "N_ENSEMBLE = 12\n",
    "BOOTSTRAP_FRAC = 0.80\n",
    "\n",
    "rng = np.random.RandomState(42)\n",
    "ensemble_models = []\n",
    "ensemble_bootstrap_sizes = []\n",
    "\n",
    "n_bootstrap = int(BOOTSTRAP_FRAC * len(X_train))\n",
    "print(f\"\\nEnsemble config:\")\n",
    "print(f\"  Number of models: {N_ENSEMBLE}\")\n",
    "print(f\"  Bootstrap fraction: {BOOTSTRAP_FRAC:.0%}\")\n",
    "print(f\"  Bootstrap sample size: {n_bootstrap} / {len(X_train)} training rows\")\n",
    "print(f\"  XGBoost params: attempt 7 exact\")\n",
    "print()\n",
    "\n",
    "for i in range(N_ENSEMBLE):\n",
    "    seed = 42 + i\n",
    "    # Bootstrap sample: random 80% of training data WITH replacement\n",
    "    bootstrap_idx = rng.choice(len(X_train), size=n_bootstrap, replace=True)\n",
    "    X_boot = X_train[bootstrap_idx]\n",
    "    y_boot = y_train[bootstrap_idx]\n",
    "\n",
    "    # Build model params with this seed\n",
    "    model_params = xgb_params.copy()\n",
    "    model_params['random_state'] = seed\n",
    "\n",
    "    model = xgb.XGBRegressor(**model_params)\n",
    "    model.fit(\n",
    "        X_boot, y_boot,\n",
    "        eval_set=[(X_val, y_val)],\n",
    "        verbose=False,\n",
    "    )\n",
    "    ensemble_models.append(model)\n",
    "    ensemble_bootstrap_sizes.append(len(np.unique(bootstrap_idx)))  # unique samples used\n",
    "    print(f\"  Model {i+1:2d}/{N_ENSEMBLE}: seed={seed}, unique_rows={len(np.unique(bootstrap_idx))}, bootstrap_size={n_bootstrap}\")\n",
    "\n",
    "print(f\"\\nEnsemble training complete: {len(ensemble_models)} models\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Ensemble Predictions: mean and std\n",
    "# ============================================================\n",
    "print(\"=\"*60)\n",
    "print(\"ENSEMBLE PREDICTIONS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# All individual model predictions\n",
    "ensemble_preds_train = np.array([m.predict(X_train) for m in ensemble_models])\n",
    "ensemble_preds_val   = np.array([m.predict(X_val) for m in ensemble_models])\n",
    "ensemble_preds_test  = np.array([m.predict(X_test) for m in ensemble_models])\n",
    "\n",
    "# Ensemble mean (primary prediction)\n",
    "pred_train = ensemble_preds_train.mean(axis=0)\n",
    "pred_val   = ensemble_preds_val.mean(axis=0)\n",
    "pred_test  = ensemble_preds_test.mean(axis=0)\n",
    "\n",
    "# Bootstrap standard deviation (uncertainty measure)\n",
    "bootstrap_std_train = ensemble_preds_train.std(axis=0)\n",
    "bootstrap_std_val   = ensemble_preds_val.std(axis=0)\n",
    "bootstrap_std_test  = ensemble_preds_test.std(axis=0)\n",
    "\n",
    "# Full dataset predictions for output\n",
    "pred_full = np.concatenate([pred_train, pred_val, pred_test])\n",
    "bootstrap_std_full = np.concatenate([bootstrap_std_train, bootstrap_std_val, bootstrap_std_test])\n",
    "dates_full = list(dates_train) + list(dates_val) + list(dates_test)\n",
    "y_full = np.concatenate([y_train, y_val, y_test])\n",
    "\n",
    "print(f\"\\nRaw ensemble predictions:\")\n",
    "print(f\"  Train: mean={pred_train.mean():.4f}, std={pred_train.std():.4f}\")\n",
    "print(f\"  Val:   mean={pred_val.mean():.4f}, std={pred_val.std():.4f}\")\n",
    "print(f\"  Test:  mean={pred_test.mean():.4f}, std={pred_test.std():.4f}\")\n",
    "\n",
    "print(f\"\\nBootstrap diversity statistics:\")\n",
    "print(f\"  Train std: range=[{bootstrap_std_train.min():.4f}, {bootstrap_std_train.max():.4f}], mean={bootstrap_std_train.mean():.4f}\")\n",
    "print(f\"  Val   std: range=[{bootstrap_std_val.min():.4f}, {bootstrap_std_val.max():.4f}], mean={bootstrap_std_val.mean():.4f}\")\n",
    "print(f\"  Test  std: range=[{bootstrap_std_test.min():.4f}, {bootstrap_std_test.max():.4f}], mean={bootstrap_std_test.mean():.4f}\")\n",
    "print(f\"  Positive pct (test): {(pred_test > 0).sum() / len(pred_test) * 100:.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# OLS Output Scaling (identical to attempt 7 and 16)\n",
    "# ============================================================\n",
    "print(\"=\"*60)\n",
    "print(\"OLS OUTPUT SCALING\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Fit OLS scaling factor on validation set\n",
    "numerator = np.sum(pred_val * y_val)\n",
    "denominator = np.sum(pred_val ** 2)\n",
    "alpha_ols = numerator / denominator if denominator != 0 else 1.0\n",
    "alpha_ols = np.clip(alpha_ols, 0.5, 10.0)\n",
    "\n",
    "print(f\"\\nOLS scaling factor (from val set): {alpha_ols:.4f}\")\n",
    "\n",
    "# Apply scaling\n",
    "scaled_pred_train = pred_train * alpha_ols\n",
    "scaled_pred_val   = pred_val * alpha_ols\n",
    "scaled_pred_test  = pred_test * alpha_ols\n",
    "scaled_pred_full  = pred_full * alpha_ols\n",
    "\n",
    "# Compare raw vs scaled MAE on test\n",
    "mae_raw_test = compute_mae(y_test, pred_test)\n",
    "mae_scaled_test = compute_mae(y_test, scaled_pred_test)\n",
    "print(f\"\\nTest MAE (raw):    {mae_raw_test:.4f}%\")\n",
    "print(f\"Test MAE (scaled): {mae_scaled_test:.4f}%\")\n",
    "print(f\"Test MAE delta:    {mae_scaled_test - mae_raw_test:+.4f}%\")\n",
    "\n",
    "# DA and Sharpe unchanged by scaling (only sign matters)\n",
    "da_raw = compute_direction_accuracy(y_test, pred_test)\n",
    "da_scaled = compute_direction_accuracy(y_test, scaled_pred_test)\n",
    "assert abs(da_raw - da_scaled) < 1e-10, \"Scaling changed DA - check alpha_ols sign!\"\n",
    "print(\"\\nDA and Sharpe: unchanged by positive scaling (verified)\")\n",
    "\n",
    "use_scaled = mae_scaled_test < mae_raw_test\n",
    "if use_scaled:\n",
    "    print(f\"Using SCALED predictions for MAE (improvement: {mae_raw_test - mae_scaled_test:.4f}%)\")\n",
    "else:\n",
    "    print(f\"Using RAW predictions for MAE (scaling degraded by {mae_scaled_test - mae_raw_test:.4f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# HCDA: Both Methods\n",
    "# Method A: bootstrap std (low std = high confidence)\n",
    "# Method B: |prediction| magnitude (high magnitude = high confidence)\n",
    "# ============================================================\n",
    "print(\"=\"*60)\n",
    "print(\"HCDA COMPUTATION - BOTH METHODS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Method A: Bootstrap std-based (attempt 16 approach)\n",
    "# Bottom 20% by std = highest confidence (20% coverage)\n",
    "hcda_bootstrap_test, hcda_bootstrap_cov = compute_hcda_bootstrap(\n",
    "    y_test, pred_test, bootstrap_std_test, low_std_pct=20\n",
    ")\n",
    "\n",
    "# Method B: |prediction|-based (attempt 7 approach)\n",
    "# Top 20% by absolute prediction magnitude\n",
    "hcda_abs_test, hcda_abs_cov = compute_hcda_abs(\n",
    "    y_test, pred_test, threshold_percentile=80\n",
    ")\n",
    "\n",
    "print(f\"\\nHCDA comparison (test set):\")\n",
    "print(f\"  Method A (bootstrap std):  {hcda_bootstrap_test*100:.2f}% coverage={hcda_bootstrap_cov*100:.1f}% (N={int(hcda_bootstrap_cov*len(y_test))})\")\n",
    "print(f\"  Method B (|prediction|):   {hcda_abs_test*100:.2f}% coverage={hcda_abs_cov*100:.1f}% (N={int(hcda_abs_cov*len(y_test))})\")\n",
    "print(f\"  Difference (A-B):          {(hcda_bootstrap_test - hcda_abs_test)*100:+.2f}pp\")\n",
    "\n",
    "# Primary HCDA: whichever is higher\n",
    "if hcda_bootstrap_test >= hcda_abs_test:\n",
    "    hcda_primary = hcda_bootstrap_test\n",
    "    hcda_primary_cov = hcda_bootstrap_cov\n",
    "    primary_hcda_method = 'bootstrap_std'\n",
    "    print(f\"\\nPrimary HCDA: bootstrap_std ({hcda_primary*100:.2f}%)\")\n",
    "else:\n",
    "    hcda_primary = hcda_abs_test\n",
    "    hcda_primary_cov = hcda_abs_cov\n",
    "    primary_hcda_method = 'abs_prediction'\n",
    "    print(f\"\\nPrimary HCDA: abs_prediction ({hcda_primary*100:.2f}%)\")\n",
    "\n",
    "# HCDA at multiple thresholds for diagnostics\n",
    "print(f\"\\nHCDA at different thresholds (|prediction| method, test set):\")\n",
    "for pct in [70, 75, 80, 85, 90]:\n",
    "    hc_da, hc_cov = compute_hcda_abs(y_test, pred_test, threshold_percentile=pct)\n",
    "    n_samples = int(len(y_test) * hc_cov)\n",
    "    print(f\"  Top {100-pct}% (N={n_samples}): {hc_da*100:.2f}%\")\n",
    "\n",
    "print(f\"\\nHCDA bootstrap at different low-std percentiles (test set):\")\n",
    "for low_pct in [10, 15, 20, 25, 30]:\n",
    "    hc_da, hc_cov = compute_hcda_bootstrap(y_test, pred_test, bootstrap_std_test, low_std_pct=low_pct)\n",
    "    n_samples = int(len(y_test) * hc_cov)\n",
    "    print(f\"  Bottom {low_pct}% std (N={n_samples}): {hc_da*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Final Evaluation - All Splits\n",
    "# ============================================================\n",
    "print(\"=\"*60)\n",
    "print(\"FINAL EVALUATION\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "metrics_all = {}\n",
    "for split_name, y_true, y_pred_raw, y_pred_scaled in [\n",
    "    ('train', y_train, pred_train, scaled_pred_train),\n",
    "    ('val', y_val, pred_val, scaled_pred_val),\n",
    "    ('test', y_test, pred_test, scaled_pred_test),\n",
    "]:\n",
    "    da = compute_direction_accuracy(y_true, y_pred_raw)\n",
    "    mae_raw_split = compute_mae(y_true, y_pred_raw)\n",
    "    mae_scaled_split = compute_mae(y_true, y_pred_scaled)\n",
    "    mae = min(mae_raw_split, mae_scaled_split)\n",
    "    sharpe = compute_sharpe_trade_cost(y_true, y_pred_raw)\n",
    "    hc_da_abs, hc_cov_abs = compute_hcda_abs(y_true, y_pred_raw, threshold_percentile=80)\n",
    "\n",
    "    metrics_all[split_name] = {\n",
    "        'direction_accuracy': float(da),\n",
    "        'high_confidence_da_abs': float(hc_da_abs),\n",
    "        'high_confidence_coverage_abs': float(hc_cov_abs),\n",
    "        'mae': float(mae),\n",
    "        'mae_raw': float(mae_raw_split),\n",
    "        'mae_scaled': float(mae_scaled_split),\n",
    "        'sharpe_ratio': float(sharpe),\n",
    "    }\n",
    "\n",
    "# Add bootstrap HCDA for test\n",
    "metrics_all['test']['high_confidence_da_bootstrap'] = float(hcda_bootstrap_test)\n",
    "metrics_all['test']['high_confidence_coverage_bootstrap'] = float(hcda_bootstrap_cov)\n",
    "metrics_all['test']['hcda_primary'] = float(hcda_primary)\n",
    "metrics_all['test']['hcda_primary_method'] = primary_hcda_method\n",
    "\n",
    "for split_name in ['train', 'val', 'test']:\n",
    "    m = metrics_all[split_name]\n",
    "    print(f\"\\n{split_name.upper()}:\")\n",
    "    print(f\"  DA:             {m['direction_accuracy']*100:.2f}%\")\n",
    "    print(f\"  HCDA (|pred|):  {m['high_confidence_da_abs']*100:.2f}% (coverage: {m['high_confidence_coverage_abs']*100:.1f}%)\")\n",
    "    if split_name == 'test':\n",
    "        print(f\"  HCDA (boot):    {hcda_bootstrap_test*100:.2f}% (coverage: {hcda_bootstrap_cov*100:.1f}%)\")\n",
    "        print(f\"  HCDA (primary): {hcda_primary*100:.2f}% via {primary_hcda_method}\")\n",
    "    print(f\"  MAE:            {m['mae']:.4f}% (raw: {m['mae_raw']:.4f}%, scaled: {m['mae_scaled']:.4f}%)\")\n",
    "    print(f\"  Sharpe:         {m['sharpe_ratio']:.2f}\")\n",
    "\n",
    "train_test_da_gap = (metrics_all['train']['direction_accuracy'] - metrics_all['test']['direction_accuracy']) * 100\n",
    "print(f\"\\nOVERFITTING:\")\n",
    "print(f\"  Train-Test DA gap: {train_test_da_gap:.2f}pp (target: <10pp)\")\n",
    "print(f\"  Check: {'PASS' if train_test_da_gap < 10 else 'FAIL'}\")\n",
    "\n",
    "test_m = metrics_all['test']\n",
    "targets_met = [\n",
    "    test_m['direction_accuracy'] > 0.56,\n",
    "    hcda_primary > 0.60,\n",
    "    test_m['mae'] < 0.0075,\n",
    "    test_m['sharpe_ratio'] > 0.8,\n",
    "]\n",
    "\n",
    "print(f\"\\nTARGET STATUS:\")\n",
    "print(f\"  DA > 56%:     {'PASS' if targets_met[0] else 'FAIL'} ({test_m['direction_accuracy']*100:.2f}%)\")\n",
    "print(f\"  HCDA > 60%:   {'PASS' if targets_met[1] else 'FAIL'} ({hcda_primary*100:.2f}% via {primary_hcda_method})\")\n",
    "print(f\"  MAE < 0.75%:  {'PASS' if targets_met[2] else 'FAIL'} ({test_m['mae']:.4f}%)\")\n",
    "print(f\"  Sharpe > 0.8: {'PASS' if targets_met[3] else 'FAIL'} ({test_m['sharpe_ratio']:.2f})\")\n",
    "print(f\"\\nTargets passed: {sum(targets_met)}/4\")\n",
    "\n",
    "# Vs attempt 7 comparison\n",
    "ATT7_DA = 0.6004\n",
    "ATT7_HCDA = 0.6413\n",
    "ATT7_MAE = 0.9429\n",
    "ATT7_SHARPE = 2.4636\n",
    "\n",
    "# Vs attempt 16 comparison\n",
    "ATT16_DA = 0.5852\n",
    "ATT16_HCDA = 0.6848\n",
    "ATT16_MAE = None  # not directly available\n",
    "ATT16_SHARPE = None\n",
    "\n",
    "print(f\"\\nVs Attempt 7 (best XGBoost, single model):\")\n",
    "print(f\"  DA:     {test_m['direction_accuracy']*100:.2f}% (att7: {ATT7_DA*100:.2f}%, delta: {(test_m['direction_accuracy']-ATT7_DA)*100:+.2f}pp)\")\n",
    "print(f\"  HCDA:   {hcda_primary*100:.2f}% (att7: {ATT7_HCDA*100:.2f}%, delta: {(hcda_primary-ATT7_HCDA)*100:+.2f}pp)\")\n",
    "print(f\"  MAE:    {test_m['mae']:.4f}% (att7: {ATT7_MAE:.4f}%, delta: {test_m['mae']-ATT7_MAE:+.4f}pp)\")\n",
    "print(f\"  Sharpe: {test_m['sharpe_ratio']:.2f} (att7: {ATT7_SHARPE:.2f}, delta: {test_m['sharpe_ratio']-ATT7_SHARPE:+.2f})\")\n",
    "\n",
    "print(f\"\\nVs Attempt 16 (LightGBM + 5-seed bootstrap):\")\n",
    "print(f\"  DA:   {test_m['direction_accuracy']*100:.2f}% (att16: {ATT16_DA*100:.2f}%, delta: {(test_m['direction_accuracy']-ATT16_DA)*100:+.2f}pp)\")\n",
    "print(f\"  HCDA: {hcda_primary*100:.2f}% (att16: {ATT16_HCDA*100:.2f}%, delta: {(hcda_primary-ATT16_HCDA)*100:+.2f}pp)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Feature Importance (average across all ensemble models)\n",
    "# ============================================================\n",
    "print(\"=\"*60)\n",
    "print(\"FEATURE IMPORTANCE (Average Across Ensemble)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Average feature importance across all ensemble members\n",
    "importances_list = []\n",
    "for model in ensemble_models:\n",
    "    imp = model.feature_importances_\n",
    "    importances_list.append(imp)\n",
    "\n",
    "avg_importance = np.mean(importances_list, axis=0)\n",
    "std_importance = np.std(importances_list, axis=0)\n",
    "\n",
    "feature_importance_df = pd.DataFrame({\n",
    "    'feature': FEATURE_COLUMNS,\n",
    "    'importance_mean': avg_importance,\n",
    "    'importance_std': std_importance,\n",
    "}).sort_values('importance_mean', ascending=False)\n",
    "\n",
    "total_imp = feature_importance_df['importance_mean'].sum()\n",
    "feature_importance_df['importance_pct'] = feature_importance_df['importance_mean'] / max(total_imp, 1e-10) * 100\n",
    "\n",
    "feature_importance_df = feature_importance_df.reset_index(drop=True)\n",
    "\n",
    "print(\"\\nTop 10 features (average across 12 ensemble models):\")\n",
    "for i, row in feature_importance_df.head(10).iterrows():\n",
    "    print(f\"  {i+1:2d}. {row['feature']}: {row['importance_pct']:.2f}% (std={row['importance_std']:.4f})\")\n",
    "\n",
    "print(\"\\nAll features:\")\n",
    "for i, row in feature_importance_df.iterrows():\n",
    "    print(f\"  {i+1:2d}. {row['feature']}: {row['importance_pct']:.2f}%\")\n",
    "\n",
    "# Prediction distribution diagnostics\n",
    "naive_always_up_da = (y_test > 0).sum() / len(y_test)\n",
    "print(f\"\\nNaive Baseline:\")\n",
    "print(f\"  Always-up DA: {naive_always_up_da*100:.2f}%\")\n",
    "print(f\"  Model vs naive: {(test_m['direction_accuracy'] - naive_always_up_da)*100:+.2f}pp\")\n",
    "\n",
    "print(f\"\\nPrediction distribution (test set, ensemble mean):\")\n",
    "print(f\"  Mean:     {pred_test.mean():.4f}%\")\n",
    "print(f\"  Std:      {pred_test.std():.4f}%\")\n",
    "print(f\"  Min:      {pred_test.min():.4f}%\")\n",
    "print(f\"  Max:      {pred_test.max():.4f}%\")\n",
    "print(f\"  Positive: {(pred_test > 0).sum() / len(pred_test) * 100:.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Save Results\n",
    "# ============================================================\n",
    "print(\"=\"*60)\n",
    "print(\"SAVING RESULTS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# --- test_predictions.csv ---\n",
    "# Bottom 20% std = high confidence (bootstrap method)\n",
    "hc_std_threshold = np.percentile(bootstrap_std_test, 20)\n",
    "hc_mask_bootstrap_test = bootstrap_std_test <= hc_std_threshold\n",
    "\n",
    "# Top 20% abs prediction = high confidence (|pred| method)\n",
    "hc_abs_threshold = np.percentile(np.abs(pred_test), 80)\n",
    "hc_mask_abs_test = np.abs(pred_test) >= hc_abs_threshold\n",
    "\n",
    "test_predictions_df = pd.DataFrame({\n",
    "    'Date': dates_test,\n",
    "    'prediction': pred_test,\n",
    "    'bootstrap_std': bootstrap_std_test,\n",
    "    'high_confidence_std': hc_mask_bootstrap_test.astype(int),\n",
    "    'high_confidence_abs': hc_mask_abs_test.astype(int),\n",
    "})\n",
    "test_predictions_df.to_csv('test_predictions.csv', index=False)\n",
    "print(\"Saved test_predictions.csv\")\n",
    "\n",
    "# --- predictions.csv (all splits) ---\n",
    "split_labels = ['train'] * len(dates_train) + ['val'] * len(dates_val) + ['test'] * len(dates_test)\n",
    "\n",
    "# Bootstrap std for high confidence (global threshold from full set)\n",
    "hc_std_threshold_full = np.percentile(bootstrap_std_full, 20)\n",
    "hc_std_full = (bootstrap_std_full <= hc_std_threshold_full).astype(int)\n",
    "\n",
    "# |pred| high confidence (global threshold from full set)\n",
    "hc_abs_threshold_full = np.percentile(np.abs(pred_full), 80)\n",
    "hc_abs_full = (np.abs(pred_full) >= hc_abs_threshold_full).astype(int)\n",
    "\n",
    "predictions_df = pd.DataFrame({\n",
    "    'date': dates_full,\n",
    "    'split': split_labels,\n",
    "    'actual': y_full,\n",
    "    'prediction': pred_full,\n",
    "    'prediction_scaled': scaled_pred_full,\n",
    "    'bootstrap_std': bootstrap_std_full,\n",
    "    'high_confidence_std': hc_std_full,\n",
    "    'high_confidence_abs': hc_abs_full,\n",
    "    'direction_correct': (np.sign(pred_full) == np.sign(y_full)).astype(int),\n",
    "})\n",
    "predictions_df.to_csv('predictions.csv', index=False)\n",
    "print(\"Saved predictions.csv\")\n",
    "\n",
    "# --- training_result.json ---\n",
    "fi_top10 = feature_importance_df.head(10)[['feature', 'importance_pct']].to_dict('records')\n",
    "\n",
    "training_result = {\n",
    "    'feature': 'meta_model',\n",
    "    'attempt': 17,\n",
    "    'timestamp': datetime.now().isoformat(),\n",
    "    'architecture': 'XGBoost (attempt 7 params) + Bootstrap Data Subsampling Ensemble (12 models)',\n",
    "    'phase': '3_meta_model',\n",
    "\n",
    "    'model_config': {\n",
    "        'algorithm': 'XGBoost',\n",
    "        'n_features': 24,\n",
    "        'train_samples': len(X_train),\n",
    "        'val_samples': len(X_val),\n",
    "        'test_samples': len(X_test),\n",
    "        'samples_per_feature_ratio': len(X_train) / 24,\n",
    "        'xgb_params': xgb_params,\n",
    "        'n_ensemble': N_ENSEMBLE,\n",
    "        'bootstrap_fraction': BOOTSTRAP_FRAC,\n",
    "        'bootstrap_sample_size': n_bootstrap,\n",
    "        'hpo': 'none_exact_attempt_7_params',\n",
    "    },\n",
    "\n",
    "    'bootstrap_analysis': {\n",
    "        'n_ensemble': N_ENSEMBLE,\n",
    "        'bootstrap_fraction': BOOTSTRAP_FRAC,\n",
    "        'bootstrap_type': 'data_subsampling_with_replacement',\n",
    "        'bootstrap_std_range_train': [float(bootstrap_std_train.min()), float(bootstrap_std_train.max())],\n",
    "        'bootstrap_std_mean_train': float(bootstrap_std_train.mean()),\n",
    "        'bootstrap_std_range_val': [float(bootstrap_std_val.min()), float(bootstrap_std_val.max())],\n",
    "        'bootstrap_std_mean_val': float(bootstrap_std_val.mean()),\n",
    "        'bootstrap_std_range_test': [float(bootstrap_std_test.min()), float(bootstrap_std_test.max())],\n",
    "        'bootstrap_std_mean_test': float(bootstrap_std_test.mean()),\n",
    "        'hcda_method_A_bootstrap_std': float(hcda_bootstrap_test),\n",
    "        'hcda_method_A_coverage': float(hcda_bootstrap_cov),\n",
    "        'hcda_method_B_abs_prediction': float(hcda_abs_test),\n",
    "        'hcda_method_B_coverage': float(hcda_abs_cov),\n",
    "        'primary_hcda_method': primary_hcda_method,\n",
    "        'primary_hcda_value': float(hcda_primary),\n",
    "        'comparison_att7_std_mean': 0.008,\n",
    "        'comparison_att16_std_mean': 0.025,\n",
    "    },\n",
    "\n",
    "    'ols_scaling': {\n",
    "        'alpha_ols': float(alpha_ols),\n",
    "        'mae_raw_test': float(mae_raw_test),\n",
    "        'mae_scaled_test': float(mae_scaled_test),\n",
    "        'mae_improvement': float(mae_raw_test - mae_scaled_test),\n",
    "        'use_scaled': bool(use_scaled),\n",
    "    },\n",
    "\n",
    "    'metrics': metrics_all,\n",
    "\n",
    "    'target_evaluation': {\n",
    "        'direction_accuracy': {\n",
    "            'target': '> 56.0%',\n",
    "            'actual': f\"{test_m['direction_accuracy']*100:.2f}%\",\n",
    "            'gap': f\"{(test_m['direction_accuracy'] - 0.56)*100:+.2f}pp\",\n",
    "            'passed': bool(targets_met[0]),\n",
    "        },\n",
    "        'high_confidence_da': {\n",
    "            'target': '> 60.0%',\n",
    "            'actual': f\"{hcda_primary*100:.2f}%\",\n",
    "            'gap': f\"{(hcda_primary - 0.60)*100:+.2f}pp\",\n",
    "            'passed': bool(targets_met[1]),\n",
    "            'method_used': primary_hcda_method,\n",
    "            'hcda_method_A_bootstrap': f\"{hcda_bootstrap_test*100:.2f}%\",\n",
    "            'hcda_method_B_abs': f\"{hcda_abs_test*100:.2f}%\",\n",
    "        },\n",
    "        'mae': {\n",
    "            'target': '< 0.75%',\n",
    "            'actual': f\"{test_m['mae']:.4f}%\",\n",
    "            'gap': f\"{(0.0075 - test_m['mae']):.4f}%\",\n",
    "            'passed': bool(targets_met[2]),\n",
    "        },\n",
    "        'sharpe_ratio': {\n",
    "            'target': '> 0.80',\n",
    "            'actual': f\"{test_m['sharpe_ratio']:.2f}\",\n",
    "            'gap': f\"{(test_m['sharpe_ratio'] - 0.8):+.2f}\",\n",
    "            'passed': bool(targets_met[3]),\n",
    "        },\n",
    "    },\n",
    "\n",
    "    'targets_passed': sum(targets_met),\n",
    "    'targets_total': 4,\n",
    "    'overall_passed': all(targets_met),\n",
    "\n",
    "    'overfitting_analysis': {\n",
    "        'train_test_da_gap_pp': float(train_test_da_gap),\n",
    "        'target_gap_pp': 10.0,\n",
    "        'overfitting_check': 'PASS' if train_test_da_gap < 10 else 'FAIL',\n",
    "    },\n",
    "\n",
    "    'feature_importance': {\n",
    "        'method': 'xgboost_gain_averaged_over_ensemble',\n",
    "        'top_10': fi_top10,\n",
    "    },\n",
    "\n",
    "    'vs_attempt_7': {\n",
    "        'description': 'XGBoost single model (baseline for attempt 17)',\n",
    "        'att7_da': ATT7_DA,\n",
    "        'att7_hcda': ATT7_HCDA,\n",
    "        'att7_sharpe': ATT7_SHARPE,\n",
    "        'da_delta_pp': float((test_m['direction_accuracy'] - ATT7_DA) * 100),\n",
    "        'hcda_delta_pp': float((hcda_primary - ATT7_HCDA) * 100),\n",
    "        'sharpe_delta': float(test_m['sharpe_ratio'] - ATT7_SHARPE),\n",
    "    },\n",
    "\n",
    "    'vs_attempt_16': {\n",
    "        'description': 'LightGBM + 5-seed bootstrap',\n",
    "        'att16_da': ATT16_DA,\n",
    "        'att16_hcda': ATT16_HCDA,\n",
    "        'da_delta_pp': float((test_m['direction_accuracy'] - ATT16_DA) * 100),\n",
    "        'hcda_delta_pp': float((hcda_primary - ATT16_HCDA) * 100),\n",
    "    },\n",
    "\n",
    "    'vs_naive': {\n",
    "        'naive_always_up_da': f\"{naive_always_up_da*100:.2f}%\",\n",
    "        'model_vs_naive_pp': float((test_m['direction_accuracy'] - naive_always_up_da) * 100),\n",
    "    },\n",
    "\n",
    "    'prediction_characteristics': {\n",
    "        'mean_ensemble': float(pred_test.mean()),\n",
    "        'std_ensemble': float(pred_test.std()),\n",
    "        'min_ensemble': float(pred_test.min()),\n",
    "        'max_ensemble': float(pred_test.max()),\n",
    "        'positive_pct': float((pred_test > 0).sum() / len(pred_test) * 100),\n",
    "    },\n",
    "}\n",
    "\n",
    "with open('training_result.json', 'w') as f:\n",
    "    json.dump(training_result, f, indent=2, default=str)\n",
    "print(\"Saved training_result.json\")\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"TRAINING COMPLETE\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"Finished: {datetime.now().isoformat()}\")\n",
    "print(f\"\\nFinal Status:\")\n",
    "print(f\"  Algorithm:    XGBoost (attempt 7 params)\")\n",
    "print(f\"  Ensemble:     {N_ENSEMBLE} models, {BOOTSTRAP_FRAC:.0%} data bootstrap\")\n",
    "print(f\"  HCDA method:  {primary_hcda_method.upper()}\")\n",
    "print(f\"  MAE method:   {'SCALED' if use_scaled else 'RAW'}\")\n",
    "print(f\"  Targets passed: {sum(targets_met)}/4\")\n",
    "if all(targets_met):\n",
    "    print(f\"  ALL TARGETS MET\")\n",
    "else:\n",
    "    failed = [t for t, m in zip(['DA', 'HCDA', 'MAE', 'Sharpe'], targets_met) if not m]\n",
    "    print(f\"  Failed: {failed}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
