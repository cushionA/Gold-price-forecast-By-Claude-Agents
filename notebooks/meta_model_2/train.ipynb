{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Gold Meta-Model Training - Attempt 2\n",
        "\n",
        "**Architecture**: XGBoost Regression (reg:squarederror)\n",
        "\n",
        "**Key Improvements from Attempt 1**:\n",
        "- Aggressive regularization (max_depth 2-4, high L1/L2, low subsample)\n",
        "- Direct overfitting penalty in Optuna objective (penalize train-val DA gap > 10pp)\n",
        "- Position-change cost only (not daily cost)\n",
        "- NO directional-weighted MAE\n",
        "- NO price-level or CNY features\n",
        "- 80 Optuna trials (increased from 50)\n",
        "\n",
        "**Self-contained**: Data load → Preprocessing → HPO → Training → Evaluation → Save"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================\n",
        "# 1. IMPORTS\n",
        "# ============================================================\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import xgboost as xgb\n",
        "import optuna\n",
        "import json\n",
        "import os\n",
        "from datetime import datetime\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Reproducibility\n",
        "np.random.seed(42)\n",
        "\n",
        "print(f\"Training started: {datetime.now().isoformat()}\")\n",
        "print(f\"XGBoost version: {xgb.__version__}\")\n",
        "print(f\"Optuna version: {optuna.__version__}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================",
        "# 2. DATA LOADING",
        "# ============================================================",
        "print(\"\\n=== Loading Data ===\")",
        "",
        "# Load the 3 pre-split CSVs (verified by datachecker)",
        "train_df = pd.read_csv('../input/gold-prediction-complete/meta_model_attempt_2_train.csv', index_col=0, parse_dates=True)",
        "val_df = pd.read_csv('../input/gold-prediction-complete/meta_model_attempt_2_val.csv', index_col=0, parse_dates=True)",
        "test_df = pd.read_csv('../input/gold-prediction-complete/meta_model_attempt_2_test.csv', index_col=0, parse_dates=True)",
        "",
        "print(f\"Train: {train_df.shape}\")",
        "print(f\"Val:   {val_df.shape}\")",
        "print(f\"Test:  {test_df.shape}\")",
        "print(f\"\\nTrain date range: {train_df.index[0]} to {train_df.index[-1]}\")",
        "print(f\"Val date range:   {val_df.index[0]} to {val_df.index[-1]}\")",
        "print(f\"Test date range:  {test_df.index[0]} to {test_df.index[-1]}\")",
        "",
        "# Separate features and target",
        "TARGET_COL = 'target_next_day_return'",
        "",
        "X_train = train_df.drop(columns=[TARGET_COL])",
        "y_train = train_df[TARGET_COL]",
        "",
        "X_val = val_df.drop(columns=[TARGET_COL])",
        "y_val = val_df[TARGET_COL]",
        "",
        "X_test = test_df.drop(columns=[TARGET_COL])",
        "y_test = test_df[TARGET_COL]",
        "",
        "print(f\"\\nFeature count: {X_train.shape[1]}\")",
        "print(f\"Features: {list(X_train.columns)}\")",
        "",
        "# Verify feature count",
        "assert X_train.shape[1] == 22, f\"Expected 22 features, got {X_train.shape[1]}\"",
        "assert X_val.shape[1] == 22, f\"Expected 22 features in val, got {X_val.shape[1]}\"",
        "assert X_test.shape[1] == 22, f\"Expected 22 features in test, got {X_test.shape[1]}\"",
        "",
        "print(\"\\n✓ Data loaded successfully\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================\n",
        "# 3. EVALUATION METRICS\n",
        "# ============================================================\n",
        "\n",
        "def direction_accuracy(y_true, y_pred):\n",
        "    \"\"\"Direction accuracy (excludes zero predictions and actuals)\"\"\"\n",
        "    y_true = np.array(y_true)\n",
        "    y_pred = np.array(y_pred)\n",
        "    \n",
        "    # Exclude zeros to avoid np.sign(0) = 0 problem\n",
        "    mask = (y_true != 0) & (y_pred != 0)\n",
        "    if mask.sum() == 0:\n",
        "        return 0.0\n",
        "    \n",
        "    correct = (np.sign(y_true[mask]) == np.sign(y_pred[mask])).sum()\n",
        "    return correct / mask.sum()\n",
        "\n",
        "def high_confidence_direction_accuracy(y_true, y_pred, threshold_percentile=75):\n",
        "    \"\"\"Direction accuracy for high-confidence predictions (top 25%)\"\"\"\n",
        "    y_true = np.array(y_true)\n",
        "    y_pred = np.array(y_pred)\n",
        "    \n",
        "    # Filter high-confidence predictions\n",
        "    threshold = np.percentile(np.abs(y_pred), threshold_percentile)\n",
        "    mask = (np.abs(y_pred) >= threshold) & (y_true != 0) & (y_pred != 0)\n",
        "    \n",
        "    if mask.sum() == 0:\n",
        "        return 0.0\n",
        "    \n",
        "    correct = (np.sign(y_true[mask]) == np.sign(y_pred[mask])).sum()\n",
        "    return correct / mask.sum()\n",
        "\n",
        "def sharpe_ratio(y_true, y_pred):\n",
        "    \"\"\"\n",
        "    Sharpe ratio with position-change cost (5bps per trade).\n",
        "    Matches CLAUDE.md specification.\n",
        "    \"\"\"\n",
        "    y_true = np.array(y_true)\n",
        "    y_pred = np.array(y_pred)\n",
        "    \n",
        "    # Trading positions based on prediction sign\n",
        "    positions = np.sign(y_pred)\n",
        "    \n",
        "    # Count position changes (prepend 0 for first position)\n",
        "    trades = np.abs(np.diff(positions, prepend=0))\n",
        "    \n",
        "    # Strategy returns = position * actual return - transaction cost\n",
        "    strategy_returns = positions * y_true - trades * 0.0005  # 5bps per trade\n",
        "    \n",
        "    if len(strategy_returns) == 0 or np.std(strategy_returns) == 0:\n",
        "        return 0.0\n",
        "    \n",
        "    # Annualized Sharpe (252 trading days)\n",
        "    sharpe = np.mean(strategy_returns) / np.std(strategy_returns) * np.sqrt(252)\n",
        "    return sharpe\n",
        "\n",
        "def compute_all_metrics(y_true, y_pred, split_name=''):\n",
        "    \"\"\"Compute all evaluation metrics\"\"\"\n",
        "    mae = mean_absolute_error(y_true, y_pred)\n",
        "    da = direction_accuracy(y_true, y_pred)\n",
        "    hcda = high_confidence_direction_accuracy(y_true, y_pred)\n",
        "    sharpe = sharpe_ratio(y_true, y_pred)\n",
        "    \n",
        "    metrics = {\n",
        "        'mae': mae,\n",
        "        'direction_accuracy': da,\n",
        "        'high_confidence_da': hcda,\n",
        "        'sharpe_ratio': sharpe\n",
        "    }\n",
        "    \n",
        "    if split_name:\n",
        "        print(f\"\\n{split_name} Metrics:\")\n",
        "        print(f\"  MAE: {mae:.4f}%\")\n",
        "        print(f\"  Direction Accuracy: {da*100:.2f}%\")\n",
        "        print(f\"  High-Confidence DA: {hcda*100:.2f}%\")\n",
        "        print(f\"  Sharpe Ratio: {sharpe:.3f}\")\n",
        "    \n",
        "    return metrics\n",
        "\n",
        "print(\"✓ Evaluation functions defined\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================\n",
        "# 4. OPTUNA HYPERPARAMETER OPTIMIZATION\n",
        "# ============================================================\n",
        "\n",
        "def optuna_objective(trial):\n",
        "    \"\"\"\n",
        "    Optuna objective with weighted composite metric and overfitting penalty.\n",
        "    \n",
        "    Composite = 0.50*Sharpe + 0.30*DA + 0.10*(1-MAE) + 0.10*HCDA - overfitting_penalty\n",
        "    \n",
        "    Overfitting penalty: penalize train-val DA gap > 10pp\n",
        "    \"\"\"\n",
        "    # Aggressive regularization ranges\n",
        "    params = {\n",
        "        'objective': 'reg:squarederror',\n",
        "        'eval_metric': 'mae',\n",
        "        'max_depth': trial.suggest_int('max_depth', 2, 4),\n",
        "        'min_child_weight': trial.suggest_int('min_child_weight', 10, 30),\n",
        "        'reg_lambda': trial.suggest_float('reg_lambda', 3.0, 20.0),\n",
        "        'reg_alpha': trial.suggest_float('reg_alpha', 1.0, 10.0),\n",
        "        'subsample': trial.suggest_float('subsample', 0.4, 0.7),\n",
        "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.3, 0.6),\n",
        "        'learning_rate': trial.suggest_float('learning_rate', 0.001, 0.05, log=True),\n",
        "        'n_estimators': trial.suggest_int('n_estimators', 100, 500),\n",
        "        'random_state': 42,\n",
        "        'n_jobs': -1,\n",
        "        'verbosity': 0\n",
        "    }\n",
        "    \n",
        "    # Train model\n",
        "    model = xgb.XGBRegressor(**params)\n",
        "    model.fit(\n",
        "        X_train, y_train,\n",
        "        eval_set=[(X_val, y_val)],\n",
        "        verbose=False\n",
        "    )\n",
        "    \n",
        "    # Predictions\n",
        "    train_pred = model.predict(X_train)\n",
        "    val_pred = model.predict(X_val)\n",
        "    \n",
        "    # Validation metrics\n",
        "    val_mae = mean_absolute_error(y_val, val_pred)\n",
        "    val_da = direction_accuracy(y_val, val_pred)\n",
        "    val_hcda = high_confidence_direction_accuracy(y_val, val_pred)\n",
        "    val_sharpe = sharpe_ratio(y_val, val_pred)\n",
        "    \n",
        "    # Train metrics (for overfitting detection)\n",
        "    train_da = direction_accuracy(y_train, train_pred)\n",
        "    \n",
        "    # Normalize metrics to [0, 1] range for composite\n",
        "    sharpe_normalized = np.clip((val_sharpe + 1.0) / 3.0, 0, 1)  # assume Sharpe in [-1, 2]\n",
        "    da_normalized = val_da  # already in [0, 1]\n",
        "    mae_normalized = np.clip(val_mae / 2.0, 0, 1)  # assume MAE in [0, 2]\n",
        "    hcda_normalized = val_hcda  # already in [0, 1]\n",
        "    \n",
        "    # Overfitting penalty: penalize train-val DA gap > 10pp\n",
        "    da_gap_pp = (train_da - val_da) * 100\n",
        "    overfitting_penalty = max(0, (da_gap_pp - 10) * 0.05)\n",
        "    \n",
        "    # Weighted composite (weights from design doc)\n",
        "    composite = (\n",
        "        0.50 * sharpe_normalized +\n",
        "        0.30 * da_normalized +\n",
        "        0.10 * (1 - mae_normalized) +\n",
        "        0.10 * hcda_normalized -\n",
        "        overfitting_penalty\n",
        "    )\n",
        "    \n",
        "    # Log metrics for monitoring\n",
        "    trial.set_user_attr('val_mae', val_mae)\n",
        "    trial.set_user_attr('val_da', val_da)\n",
        "    trial.set_user_attr('val_hcda', val_hcda)\n",
        "    trial.set_user_attr('val_sharpe', val_sharpe)\n",
        "    trial.set_user_attr('train_da', train_da)\n",
        "    trial.set_user_attr('da_gap_pp', da_gap_pp)\n",
        "    trial.set_user_attr('overfitting_penalty', overfitting_penalty)\n",
        "    trial.set_user_attr('composite', composite)\n",
        "    \n",
        "    return composite\n",
        "\n",
        "print(\"✓ Optuna objective function defined\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================\n",
        "# 5. RUN HYPERPARAMETER SEARCH\n",
        "# ============================================================\n",
        "print(\"\\n=== Starting Hyperparameter Optimization ===\")\n",
        "print(\"Configuration:\")\n",
        "print(\"  Trials: 80\")\n",
        "print(\"  Objective: Weighted composite (50% Sharpe, 30% DA, 10% MAE, 10% HCDA) - overfitting penalty\")\n",
        "print(\"  Pruner: MedianPruner\")\n",
        "print(\"  Regularization: AGGRESSIVE (max_depth 2-4, high L1/L2, low subsample)\")\n",
        "\n",
        "# Create Optuna study\n",
        "study = optuna.create_study(\n",
        "    direction='maximize',\n",
        "    pruner=optuna.pruners.MedianPruner(n_warmup_steps=5),\n",
        "    sampler=optuna.samplers.TPESampler(seed=42)\n",
        ")\n",
        "\n",
        "# Run optimization\n",
        "study.optimize(optuna_objective, n_trials=80, show_progress_bar=True)\n",
        "\n",
        "print(\"\\n=== Optimization Complete ===\")\n",
        "print(f\"Best composite score: {study.best_value:.4f}\")\n",
        "print(f\"\\nBest hyperparameters:\")\n",
        "for key, value in study.best_params.items():\n",
        "    print(f\"  {key}: {value}\")\n",
        "\n",
        "print(f\"\\nBest trial metrics:\")\n",
        "best_trial = study.best_trial\n",
        "print(f\"  Val MAE: {best_trial.user_attrs['val_mae']:.4f}%\")\n",
        "print(f\"  Val DA: {best_trial.user_attrs['val_da']*100:.2f}%\")\n",
        "print(f\"  Val HCDA: {best_trial.user_attrs['val_hcda']*100:.2f}%\")\n",
        "print(f\"  Val Sharpe: {best_trial.user_attrs['val_sharpe']:.3f}\")\n",
        "print(f\"  Train DA: {best_trial.user_attrs['train_da']*100:.2f}%\")\n",
        "print(f\"  DA Gap: {best_trial.user_attrs['da_gap_pp']:.2f}pp\")\n",
        "print(f\"  Overfitting Penalty: {best_trial.user_attrs['overfitting_penalty']:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================\n",
        "# 6. TRAIN FINAL MODEL WITH BEST HYPERPARAMETERS\n",
        "# ============================================================\n",
        "print(\"\\n=== Training Final Model ===\")\n",
        "\n",
        "best_params = study.best_params.copy()\n",
        "best_params.update({\n",
        "    'objective': 'reg:squarederror',\n",
        "    'eval_metric': 'mae',\n",
        "    'random_state': 42,\n",
        "    'n_jobs': -1,\n",
        "    'verbosity': 0\n",
        "})\n",
        "\n",
        "final_model = xgb.XGBRegressor(**best_params)\n",
        "final_model.fit(\n",
        "    X_train, y_train,\n",
        "    eval_set=[(X_train, y_train), (X_val, y_val)],\n",
        "    verbose=True\n",
        ")\n",
        "\n",
        "print(\"\\n✓ Final model trained\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================\n",
        "# 7. EVALUATE ON ALL SPLITS\n",
        "# ============================================================\n",
        "print(\"\\n=== Final Evaluation ===\")\n",
        "\n",
        "# Generate predictions\n",
        "train_pred = final_model.predict(X_train)\n",
        "val_pred = final_model.predict(X_val)\n",
        "test_pred = final_model.predict(X_test)\n",
        "\n",
        "# Compute metrics for all splits\n",
        "train_metrics = compute_all_metrics(y_train, train_pred, 'TRAIN')\n",
        "val_metrics = compute_all_metrics(y_val, val_pred, 'VAL')\n",
        "test_metrics = compute_all_metrics(y_test, test_pred, 'TEST')\n",
        "\n",
        "# Overfitting analysis\n",
        "print(\"\\n=== Overfitting Analysis ===\")\n",
        "print(f\"Train-Val DA Gap: {(train_metrics['direction_accuracy'] - val_metrics['direction_accuracy'])*100:.2f}pp\")\n",
        "print(f\"Train-Val Sharpe Gap: {train_metrics['sharpe_ratio'] - val_metrics['sharpe_ratio']:.3f}\")\n",
        "print(f\"Train-Val MAE Gap: {train_metrics['mae'] - val_metrics['mae']:.4f}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================\n",
        "# 8. FEATURE IMPORTANCE\n",
        "# ============================================================\n",
        "print(\"\\n=== Feature Importance (Top 15) ===\")\n",
        "\n",
        "feature_importance = pd.DataFrame({\n",
        "    'feature': X_train.columns,\n",
        "    'importance': final_model.feature_importances_\n",
        "}).sort_values('importance', ascending=False)\n",
        "\n",
        "print(feature_importance.head(15).to_string(index=False))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================\n",
        "# 9. SAVE RESULTS\n",
        "# ============================================================\n",
        "print(\"\\n=== Saving Results ===\")\n",
        "\n",
        "# Save model\n",
        "final_model.save_model('model.json')\n",
        "print(\"✓ Model saved to model.json\")\n",
        "\n",
        "# Save predictions\n",
        "predictions_df = pd.DataFrame({\n",
        "    'date': test_df.index,\n",
        "    'actual': y_test.values,\n",
        "    'predicted': test_pred\n",
        "})\n",
        "predictions_df.to_csv('predictions.csv', index=False)\n",
        "print(\"✓ Predictions saved to predictions.csv\")\n",
        "\n",
        "# Save feature importance\n",
        "feature_importance.to_csv('feature_importance.csv', index=False)\n",
        "print(\"✓ Feature importance saved to feature_importance.csv\")\n",
        "\n",
        "# Save training results\n",
        "training_result = {\n",
        "    'feature': 'meta_model',\n",
        "    'attempt': 2,\n",
        "    'timestamp': datetime.now().isoformat(),\n",
        "    'architecture': 'XGBoost Regression (reg:squarederror)',\n",
        "    'best_params': best_params,\n",
        "    'optuna_config': {\n",
        "        'n_trials': 80,\n",
        "        'best_composite_score': study.best_value,\n",
        "        'direction': 'maximize',\n",
        "        'objective': 'Weighted composite (50% Sharpe, 30% DA, 10% MAE, 10% HCDA) - overfitting penalty'\n",
        "    },\n",
        "    'metrics': {\n",
        "        'train': train_metrics,\n",
        "        'val': val_metrics,\n",
        "        'test': test_metrics\n",
        "    },\n",
        "    'overfitting_analysis': {\n",
        "        'train_val_da_gap_pp': (train_metrics['direction_accuracy'] - val_metrics['direction_accuracy']) * 100,\n",
        "        'train_val_sharpe_gap': train_metrics['sharpe_ratio'] - val_metrics['sharpe_ratio'],\n",
        "        'train_val_mae_gap': train_metrics['mae'] - val_metrics['mae']\n",
        "    },\n",
        "    'data_info': {\n",
        "        'train_samples': len(X_train),\n",
        "        'val_samples': len(X_val),\n",
        "        'test_samples': len(X_test),\n",
        "        'n_features': X_train.shape[1],\n",
        "        'feature_names': list(X_train.columns)\n",
        "    }\n",
        "}\n",
        "\n",
        "with open('training_result.json', 'w') as f:\n",
        "    json.dump(training_result, f, indent=2, default=str)\n",
        "print(\"✓ Training results saved to training_result.json\")\n",
        "\n",
        "print(\"\\n=== Training Complete ===\")\n",
        "print(f\"Finished: {datetime.now().isoformat()}\")\n",
        "print(f\"\\nFinal Test Metrics:\")\n",
        "print(f\"  Direction Accuracy: {test_metrics['direction_accuracy']*100:.2f}%\")\n",
        "print(f\"  High-Confidence DA: {test_metrics['high_confidence_da']*100:.2f}%\")\n",
        "print(f\"  MAE: {test_metrics['mae']:.4f}%\")\n",
        "print(f\"  Sharpe Ratio: {test_metrics['sharpe_ratio']:.3f}\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}