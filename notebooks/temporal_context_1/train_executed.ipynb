{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gold Prediction SubModel Training - Temporal Context Transformer\n",
    "## Attempt 1\n",
    "\n",
    "**Generated by**: builder_model agent  \n",
    "**Architecture**: Asymmetric Transformer Autoencoder with Masked Reconstruction  \n",
    "**Input**: 14 features (5 base + 9 submodel outputs)  \n",
    "**Output**: 1 column (temporal_context_score, 0-1)  \n",
    "**Target params**: ~6,200 (3K-10K range)  \n",
    "**Window size**: 5-20 days (Optuna search)  \n",
    "\n",
    "Self-contained: Data fetch → Preprocessing → Training → Evaluation → Save results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 1: Imports and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-17T16:38:03.804566Z",
     "iopub.status.busy": "2026-02-17T16:38:03.804390Z",
     "iopub.status.idle": "2026-02-17T16:38:06.902662Z",
     "shell.execute_reply": "2026-02-17T16:38:06.901815Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Gold SubModel Training: temporal_context attempt 1 ===\n",
      "Started: 2026-02-18T01:38:06.899896\n",
      "Device: cuda\n",
      "PyTorch version: 2.7.1+cu118\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tatuk\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "from datetime import datetime\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import optuna\n",
    "from optuna.pruners import MedianPruner\n",
    "from optuna.samplers import TPESampler\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set random seeds\n",
    "SEED = 42\n",
    "torch.manual_seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(SEED)\n",
    "\n",
    "# Device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "print(f\"=== Gold SubModel Training: temporal_context attempt 1 ===\")\n",
    "print(f\"Started: {datetime.now().isoformat()}\")\n",
    "print(f\"Device: {device}\")\n",
    "print(f\"PyTorch version: {torch.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 2: Data Fetching (API-based, self-contained)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-17T16:38:06.935849Z",
     "iopub.status.busy": "2026-02-17T16:38:06.935213Z",
     "iopub.status.idle": "2026-02-17T16:38:11.934277Z",
     "shell.execute_reply": "2026-02-17T16:38:11.933557Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "DATA FETCHING\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[1/5] Fetching base features from FRED and Yahoo...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Real rate: 2901 rows\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   DXY: 2897 rows\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   VIX: 2903 rows\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Yield spread: 2901 rows\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Inflation expectation: 2902 rows\n",
      "   Base features merged: 2902 rows, 5 columns\n",
      "\n",
      "[2/5] Transforming base features (diff)...\n",
      "   Base features transformed: ['real_rate_change', 'dxy_change', 'vix', 'yield_spread_change', 'inflation_exp_change']\n",
      "\n",
      "[3/5] Loading submodel outputs from Kaggle Dataset...\n",
      "   VIX: 2858 rows\n",
      "   Technical: 2860 rows\n",
      "   Cross-asset: 2774 rows\n",
      "   ETF flow: 2839 rows\n",
      "   Options: 2798 rows\n",
      "\n",
      "[4/5] Merging all features...\n",
      "   Final merged: 2716 rows, 14 columns\n",
      "   Date range: 2015-01-30 00:00:00 to 2026-02-12 00:00:00\n",
      "\n",
      "[5/5] Splitting data (70/15/15)...\n",
      "   Train: 1901 rows (2015-01-30 00:00:00 to 2022-10-04 00:00:00)\n",
      "   Val:   407 rows (2022-10-05 00:00:00 to 2024-06-18 00:00:00)\n",
      "   Test:  408 rows (2024-06-20 00:00:00 to 2026-02-12 00:00:00)\n",
      "\n",
      "Standardizing features...\n",
      "   [OK] Features standardized using train set statistics\n",
      "\n",
      "================================================================================\n",
      "DATA FETCHING COMPLETE\n",
      "================================================================================\n",
      "\n",
      "Data ready: train=1901, val=407, test=408, full=2716\n"
     ]
    }
   ],
   "source": [
    "def fetch_data():\n",
    "    \"\"\"\n",
    "    Fetch and prepare data for temporal context transformer.\n",
    "    Returns: (train_df, val_df, test_df, full_df, scaler)\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"DATA FETCHING\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # ===== 1. Import data APIs =====\n",
    "    import yfinance as yf\n",
    "    try:\n",
    "        from fredapi import Fred\n",
    "    except ImportError:\n",
    "        import subprocess\n",
    "        print(\"Installing fredapi...\")\n",
    "        subprocess.run([\"pip\", \"install\", \"fredapi\"], check=True)\n",
    "        from fredapi import Fred\n",
    "    \n",
    "    # Get FRED API key from environment variable\n",
    "    FRED_API_KEY = \"3ffb68facdf6321e180e380c00e909c8\"\n",
    "    fred = Fred(api_key=FRED_API_KEY)\n",
    "    \n",
    "    # ===== 2. Fetch base features (FRED + Yahoo) =====\n",
    "    print(\"\\n[1/5] Fetching base features from FRED and Yahoo...\")\n",
    "    \n",
    "    # Real interest rate (10Y TIPS)\n",
    "    real_rate = fred.get_series('DFII10', observation_start='2015-01-01')\n",
    "    real_rate_df = pd.DataFrame({'real_rate_real_rate': real_rate})\n",
    "    print(f\"   Real rate: {len(real_rate_df)} rows\")\n",
    "    \n",
    "    # DXY (Dollar Index) - using FRED for stability\n",
    "    dxy = fred.get_series('DTWEXBGS', observation_start='2015-01-01')\n",
    "    dxy_df = pd.DataFrame({'dxy_dxy': dxy})\n",
    "    print(f\"   DXY: {len(dxy_df)} rows\")\n",
    "    \n",
    "    # VIX\n",
    "    vix = fred.get_series('VIXCLS', observation_start='2015-01-01')\n",
    "    vix_df = pd.DataFrame({'vix_vix': vix})\n",
    "    print(f\"   VIX: {len(vix_df)} rows\")\n",
    "    \n",
    "    # Yield spread (10Y - 2Y)\n",
    "    dgs10 = fred.get_series('DGS10', observation_start='2015-01-01')\n",
    "    dgs2 = fred.get_series('DGS2', observation_start='2015-01-01')\n",
    "    yield_spread = dgs10 - dgs2\n",
    "    yield_spread_df = pd.DataFrame({'yield_curve_yield_spread': yield_spread})\n",
    "    print(f\"   Yield spread: {len(yield_spread_df)} rows\")\n",
    "    \n",
    "    # Inflation expectation (10Y Breakeven)\n",
    "    inflation_exp = fred.get_series('T10YIE', observation_start='2015-01-01')\n",
    "    inflation_exp_df = pd.DataFrame({'inflation_expectation_inflation_expectation': inflation_exp})\n",
    "    print(f\"   Inflation expectation: {len(inflation_exp_df)} rows\")\n",
    "    \n",
    "    # Merge base features\n",
    "    base_df = real_rate_df.join(dxy_df, how='outer')\n",
    "    base_df = base_df.join(vix_df, how='outer')\n",
    "    base_df = base_df.join(yield_spread_df, how='outer')\n",
    "    base_df = base_df.join(inflation_exp_df, how='outer')\n",
    "    base_df = base_df.sort_index()\n",
    "    \n",
    "    # Forward fill and backward fill (max 5 days)\n",
    "    base_df = base_df.ffill(limit=5)\n",
    "    base_df = base_df.bfill(limit=5)\n",
    "    base_df = base_df.dropna()\n",
    "    \n",
    "    print(f\"   Base features merged: {len(base_df)} rows, {base_df.shape[1]} columns\")\n",
    "    \n",
    "    # ===== 3. Transform base features =====\n",
    "    print(\"\\n[2/5] Transforming base features (diff)...\")\n",
    "    \n",
    "    base_features = pd.DataFrame(index=base_df.index)\n",
    "    base_features['real_rate_change'] = base_df['real_rate_real_rate'].diff()\n",
    "    base_features['dxy_change'] = base_df['dxy_dxy'].diff()\n",
    "    base_features['vix'] = base_df['vix_vix']  # No transformation (already stationary)\n",
    "    base_features['yield_spread_change'] = base_df['yield_curve_yield_spread'].diff()\n",
    "    base_features['inflation_exp_change'] = base_df['inflation_expectation_inflation_expectation'].diff()\n",
    "    \n",
    "    print(f\"   Base features transformed: {list(base_features.columns)}\")\n",
    "    \n",
    "    # ===== 4. Load submodel outputs from Kaggle Dataset =====\n",
    "    print(\"\\n[3/5] Loading submodel outputs from Kaggle Dataset...\")\n",
    "    \n",
    "    # Note: In Kaggle environment, the dataset is mounted at /kaggle/input/\n",
    "    # For local testing, adjust the path\n",
    "    if os.path.exists(\"/kaggle/input/gold-prediction-submodels/\"):\n",
    "        submodel_path = \"/kaggle/input/gold-prediction-submodels/\"\n",
    "    else:\n",
    "        submodel_path = \"../../data/submodel_outputs/\"\n",
    "    \n",
    "    # VIX submodel (2 columns)\n",
    "    vix_sub = pd.read_csv(submodel_path + \"vix.csv\")\n",
    "    vix_sub['date'] = pd.to_datetime(vix_sub['date'])\n",
    "    vix_sub = vix_sub.set_index('date').sort_index()\n",
    "    vix_features = vix_sub[['vix_regime_probability', 'vix_mean_reversion_z']].copy()\n",
    "    print(f\"   VIX: {len(vix_features)} rows\")\n",
    "    \n",
    "    # Technical submodel (3 columns) - handle timezone\n",
    "    tech_sub = pd.read_csv(submodel_path + \"technical.csv\")\n",
    "    tech_sub['date'] = tech_sub['date'].str[:10]  # Extract YYYY-MM-DD\n",
    "    tech_sub['date'] = pd.to_datetime(tech_sub['date'])\n",
    "    tech_sub = tech_sub.set_index('date').sort_index()\n",
    "    tech_features = tech_sub[['tech_trend_regime_prob', 'tech_mean_reversion_z', 'tech_volatility_regime']].copy()\n",
    "    print(f\"   Technical: {len(tech_features)} rows\")\n",
    "    \n",
    "    # Cross-asset submodel (2 columns)\n",
    "    xasset_sub = pd.read_csv(submodel_path + \"cross_asset.csv\")\n",
    "    xasset_sub['Date'] = pd.to_datetime(xasset_sub['Date'])\n",
    "    xasset_sub = xasset_sub.set_index('Date').sort_index()\n",
    "    xasset_features = xasset_sub[['xasset_regime_prob', 'xasset_divergence']].copy()\n",
    "    print(f\"   Cross-asset: {len(xasset_features)} rows\")\n",
    "    \n",
    "    # ETF flow submodel (1 column)\n",
    "    etf_sub = pd.read_csv(submodel_path + \"etf_flow.csv\")\n",
    "    etf_sub['Date'] = pd.to_datetime(etf_sub['Date'])\n",
    "    etf_sub = etf_sub.set_index('Date').sort_index()\n",
    "    etf_features = etf_sub[['etf_regime_prob']].copy()\n",
    "    print(f\"   ETF flow: {len(etf_features)} rows\")\n",
    "    \n",
    "    # Options market submodel (1 column) - handle timezone\n",
    "    options_sub = pd.read_csv(submodel_path + \"options_market.csv\")\n",
    "    options_sub['Date'] = options_sub['Date'].str[:10]  # Extract YYYY-MM-DD\n",
    "    options_sub['Date'] = pd.to_datetime(options_sub['Date'])\n",
    "    options_sub = options_sub.set_index('Date').sort_index()\n",
    "    options_features = options_sub[['options_risk_regime_prob']].copy()\n",
    "    print(f\"   Options: {len(options_features)} rows\")\n",
    "    \n",
    "    # ===== 5. Merge all features =====\n",
    "    print(\"\\n[4/5] Merging all features...\")\n",
    "    \n",
    "    merged_df = base_features.copy()\n",
    "    merged_df = merged_df.join(vix_features, how='inner')\n",
    "    merged_df = merged_df.join(tech_features, how='inner')\n",
    "    merged_df = merged_df.join(xasset_features, how='inner')\n",
    "    merged_df = merged_df.join(etf_features, how='inner')\n",
    "    merged_df = merged_df.join(options_features, how='inner')\n",
    "    \n",
    "    # Handle NaN values\n",
    "    merged_df = merged_df.ffill(limit=5)\n",
    "    merged_df = merged_df.bfill()\n",
    "    merged_df = merged_df.dropna()\n",
    "    \n",
    "    # Remove infinite values\n",
    "    inf_mask = np.isinf(merged_df.values).any(axis=1)\n",
    "    if inf_mask.any():\n",
    "        merged_df = merged_df[~inf_mask]\n",
    "    \n",
    "    print(f\"   Final merged: {len(merged_df)} rows, {merged_df.shape[1]} columns\")\n",
    "    print(f\"   Date range: {merged_df.index.min()} to {merged_df.index.max()}\")\n",
    "    \n",
    "    # Verify we have exactly 14 columns\n",
    "    assert merged_df.shape[1] == 14, f\"Expected 14 columns, got {merged_df.shape[1]}\"\n",
    "    \n",
    "    # ===== 6. Time-series split (70/15/15) =====\n",
    "    print(\"\\n[5/5] Splitting data (70/15/15)...\")\n",
    "    \n",
    "    n = len(merged_df)\n",
    "    train_end = int(n * 0.70)\n",
    "    val_end = int(n * 0.85)\n",
    "    \n",
    "    train_df = merged_df.iloc[:train_end].copy()\n",
    "    val_df = merged_df.iloc[train_end:val_end].copy()\n",
    "    test_df = merged_df.iloc[val_end:].copy()\n",
    "    \n",
    "    print(f\"   Train: {len(train_df)} rows ({train_df.index.min()} to {train_df.index.max()})\")\n",
    "    print(f\"   Val:   {len(val_df)} rows ({val_df.index.min()} to {val_df.index.max()})\")\n",
    "    print(f\"   Test:  {len(test_df)} rows ({test_df.index.min()} to {test_df.index.max()})\")\n",
    "    \n",
    "    # ===== 7. Standardization =====\n",
    "    print(\"\\nStandardizing features...\")\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    train_scaled = scaler.fit_transform(train_df)\n",
    "    val_scaled = scaler.transform(val_df)\n",
    "    test_scaled = scaler.transform(test_df)\n",
    "    full_scaled = scaler.transform(merged_df)\n",
    "    \n",
    "    # Convert back to DataFrame\n",
    "    train_df = pd.DataFrame(train_scaled, index=train_df.index, columns=train_df.columns)\n",
    "    val_df = pd.DataFrame(val_scaled, index=val_df.index, columns=val_df.columns)\n",
    "    test_df = pd.DataFrame(test_scaled, index=test_df.index, columns=test_df.columns)\n",
    "    full_df = pd.DataFrame(full_scaled, index=merged_df.index, columns=merged_df.columns)\n",
    "    \n",
    "    print(\"   [OK] Features standardized using train set statistics\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"DATA FETCHING COMPLETE\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    return train_df, val_df, test_df, full_df, scaler\n",
    "\n",
    "# Fetch data\n",
    "train_data, val_data, test_data, full_data, scaler = fetch_data()\n",
    "print(f\"\\nData ready: train={len(train_data)}, val={len(val_data)}, test={len(test_data)}, full={len(full_data)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 3: Windowing Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-17T16:38:11.936485Z",
     "iopub.status.busy": "2026-02-17T16:38:11.936252Z",
     "iopub.status.idle": "2026-02-17T16:38:11.940462Z",
     "shell.execute_reply": "2026-02-17T16:38:11.939942Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Windowing function defined.\n"
     ]
    }
   ],
   "source": [
    "def create_windows(data, window_size):\n",
    "    \"\"\"\n",
    "    Create sliding windows from time-series data.\n",
    "    \n",
    "    Args:\n",
    "        data: DataFrame (N, 14) with date index\n",
    "        window_size: int, number of time steps per window\n",
    "    \n",
    "    Returns:\n",
    "        windows: tensor (N-W+1, W, 14)\n",
    "        dates: list of dates for each window (end date)\n",
    "    \"\"\"\n",
    "    values = data.values\n",
    "    n_samples = len(values)\n",
    "    \n",
    "    if n_samples < window_size:\n",
    "        raise ValueError(f\"Not enough samples ({n_samples}) for window size {window_size}\")\n",
    "    \n",
    "    windows = []\n",
    "    dates = []\n",
    "    \n",
    "    for i in range(window_size - 1, n_samples):\n",
    "        window = values[i - window_size + 1:i + 1]\n",
    "        windows.append(window)\n",
    "        dates.append(data.index[i])\n",
    "    \n",
    "    windows = np.array(windows)\n",
    "    windows_tensor = torch.FloatTensor(windows)\n",
    "    \n",
    "    return windows_tensor, dates\n",
    "\n",
    "print(\"Windowing function defined.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 4: PyTorch Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-17T16:38:11.942792Z",
     "iopub.status.busy": "2026-02-17T16:38:11.942526Z",
     "iopub.status.idle": "2026-02-17T16:38:11.946520Z",
     "shell.execute_reply": "2026-02-17T16:38:11.945643Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WindowDataset class defined.\n"
     ]
    }
   ],
   "source": [
    "class WindowDataset(Dataset):\n",
    "    \"\"\"\n",
    "    PyTorch Dataset for windowed time-series data.\n",
    "    \"\"\"\n",
    "    def __init__(self, windows):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            windows: tensor (N, W, 14)\n",
    "        \"\"\"\n",
    "        self.windows = windows\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.windows)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.windows[idx]\n",
    "\n",
    "print(\"WindowDataset class defined.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 5: Model Definition - Temporal Context Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-17T16:38:11.948398Z",
     "iopub.status.busy": "2026-02-17T16:38:11.948138Z",
     "iopub.status.idle": "2026-02-17T16:38:11.978274Z",
     "shell.execute_reply": "2026-02-17T16:38:11.977558Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model defined. Test model parameters: 6,135\n",
      "Expected range: 3,000-10,000 params\n"
     ]
    }
   ],
   "source": [
    "class TemporalContextTransformer(nn.Module):\n",
    "    \"\"\"\n",
    "    Asymmetric Transformer Autoencoder for temporal context extraction.\n",
    "    \n",
    "    Architecture:\n",
    "      Input (batch, seq, 14)\n",
    "        -> Input Projection (14 -> d_model)\n",
    "        -> Learned Positional Encoding\n",
    "        -> TransformerEncoder (L layers, H heads)\n",
    "        -> Mean Pool over time\n",
    "        -> Bottleneck Linear (d_model -> 1)\n",
    "        -> Sigmoid -> context_score (0-1)\n",
    "      \n",
    "      Reconstruction branch (training only):\n",
    "        -> Bottleneck (1) -> Expand (d_model)\n",
    "        -> Repeat to seq_len\n",
    "        -> Output Projection (d_model -> 14)\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, input_dim=14, d_model=24, n_heads=2, n_layers=1,\n",
    "                 ffn_ratio=2, dropout=0.2, max_seq_len=20):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Input projection\n",
    "        self.input_proj = nn.Linear(input_dim, d_model)\n",
    "        \n",
    "        # Learned positional encoding\n",
    "        self.pos_encoding = nn.Embedding(max_seq_len, d_model)\n",
    "        \n",
    "        # Transformer Encoder\n",
    "        encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=d_model,\n",
    "            nhead=n_heads,\n",
    "            dim_feedforward=d_model * ffn_ratio,\n",
    "            dropout=dropout,\n",
    "            activation='gelu',\n",
    "            batch_first=True,\n",
    "            norm_first=True  # Pre-Norm for stability\n",
    "        )\n",
    "        self.encoder = nn.TransformerEncoder(encoder_layer, num_layers=n_layers)\n",
    "        \n",
    "        # Bottleneck\n",
    "        self.bottleneck = nn.Sequential(\n",
    "            nn.Linear(d_model, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "        # Lightweight Decoder (reconstruction branch)\n",
    "        self.decoder_expand = nn.Linear(1, d_model)\n",
    "        self.decoder_output = nn.Linear(d_model, input_dim)\n",
    "        \n",
    "        # Dropout for input\n",
    "        self.input_dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def encode(self, x):\n",
    "        \"\"\"\n",
    "        x: (batch, seq_len, input_dim)\n",
    "        Returns: context_score (batch, 1), pooled (batch, d_model)\n",
    "        \"\"\"\n",
    "        batch_size, seq_len, _ = x.shape\n",
    "        \n",
    "        # Input projection\n",
    "        h = self.input_proj(x)  # (batch, seq, d_model)\n",
    "        \n",
    "        # Add positional encoding\n",
    "        positions = torch.arange(seq_len, device=x.device)\n",
    "        h = h + self.pos_encoding(positions).unsqueeze(0)\n",
    "        \n",
    "        # Apply input dropout\n",
    "        h = self.input_dropout(h)\n",
    "        \n",
    "        # Transformer encoder\n",
    "        encoded = self.encoder(h)  # (batch, seq, d_model)\n",
    "        \n",
    "        # Mean pool over time\n",
    "        pooled = encoded.mean(dim=1)  # (batch, d_model)\n",
    "        \n",
    "        # Bottleneck -> context score\n",
    "        context_score = self.bottleneck(pooled)  # (batch, 1)\n",
    "        \n",
    "        return context_score, pooled\n",
    "    \n",
    "    def decode(self, context_score, seq_len):\n",
    "        \"\"\"\n",
    "        Reconstruct from bottleneck for masked reconstruction loss.\n",
    "        context_score: (batch, 1)\n",
    "        Returns: (batch, seq_len, input_dim)\n",
    "        \"\"\"\n",
    "        # Expand bottleneck\n",
    "        expanded = self.decoder_expand(context_score)  # (batch, d_model)\n",
    "        \n",
    "        # Repeat to sequence length\n",
    "        expanded = expanded.unsqueeze(1).repeat(1, seq_len, 1)  # (batch, seq, d_model)\n",
    "        \n",
    "        # Output projection\n",
    "        reconstructed = self.decoder_output(expanded)  # (batch, seq, input_dim)\n",
    "        \n",
    "        return reconstructed\n",
    "    \n",
    "    def forward(self, x, mask_ratio=0.2):\n",
    "        \"\"\"\n",
    "        Forward pass with masked reconstruction.\n",
    "        x: (batch, seq_len, input_dim)\n",
    "        Returns: context_score, reconstructed, mask\n",
    "        \"\"\"\n",
    "        batch_size, seq_len, input_dim = x.shape\n",
    "        \n",
    "        # Create random mask (mask time steps, not features)\n",
    "        mask = torch.rand(batch_size, seq_len, device=x.device) < mask_ratio\n",
    "        # Ensure at least 1 step is masked and 1 is unmasked\n",
    "        mask[:, 0] = False  # Keep first step\n",
    "        if seq_len > 2:\n",
    "            mask[:, -1] = True   # Always mask last step\n",
    "        \n",
    "        # Apply mask (zero out masked positions)\n",
    "        x_masked = x.clone()\n",
    "        x_masked[mask] = 0.0\n",
    "        \n",
    "        # Encode\n",
    "        context_score, pooled = self.encode(x_masked)\n",
    "        \n",
    "        # Decode (reconstruct)\n",
    "        reconstructed = self.decode(context_score, seq_len)\n",
    "        \n",
    "        return context_score, reconstructed, mask\n",
    "    \n",
    "    def extract(self, x):\n",
    "        \"\"\"\n",
    "        Extract context score for inference (no masking).\n",
    "        x: (batch, seq_len, input_dim)\n",
    "        Returns: context_score (batch, 1)\n",
    "        \"\"\"\n",
    "        context_score, _ = self.encode(x)\n",
    "        return context_score\n",
    "\n",
    "# Test model instantiation\n",
    "test_model = TemporalContextTransformer()\n",
    "n_params = sum(p.numel() for p in test_model.parameters())\n",
    "print(f\"\\nModel defined. Test model parameters: {n_params:,}\")\n",
    "print(f\"Expected range: 3,000-10,000 params\")\n",
    "del test_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 6: Loss Function and Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-17T16:38:11.980227Z",
     "iopub.status.busy": "2026-02-17T16:38:11.979966Z",
     "iopub.status.idle": "2026-02-17T16:38:11.987937Z",
     "shell.execute_reply": "2026-02-17T16:38:11.987177Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training functions defined.\n"
     ]
    }
   ],
   "source": [
    "def masked_reconstruction_loss(original, reconstructed, mask):\n",
    "    \"\"\"\n",
    "    MSE loss computed ONLY on masked time steps.\n",
    "    \n",
    "    original: (batch, seq_len, 14)\n",
    "    reconstructed: (batch, seq_len, 14)\n",
    "    mask: (batch, seq_len) -- True where masked\n",
    "    \"\"\"\n",
    "    # Expand mask to feature dimension\n",
    "    mask_expanded = mask.unsqueeze(-1).expand_as(original)  # (batch, seq, 14)\n",
    "    \n",
    "    # Compute MSE only on masked positions\n",
    "    diff = (original - reconstructed) ** 2\n",
    "    masked_diff = diff[mask_expanded]\n",
    "    \n",
    "    if masked_diff.numel() == 0:\n",
    "        return torch.tensor(0.0, requires_grad=True, device=original.device)\n",
    "    \n",
    "    return masked_diff.mean()\n",
    "\n",
    "\n",
    "def train_model(model, train_loader, val_loader, config):\n",
    "    \"\"\"\n",
    "    Train the model with early stopping.\n",
    "    \n",
    "    Returns: model, metrics_dict\n",
    "    \"\"\"\n",
    "    model = model.to(device)\n",
    "    \n",
    "    optimizer = optim.AdamW(\n",
    "        model.parameters(),\n",
    "        lr=config['learning_rate'],\n",
    "        weight_decay=config.get('weight_decay', 0.01),\n",
    "        betas=(0.9, 0.999),\n",
    "        eps=1e-8\n",
    "    )\n",
    "    \n",
    "    scheduler = optim.lr_scheduler.CosineAnnealingWarmRestarts(\n",
    "        optimizer, T_0=20, T_mult=2\n",
    "    )\n",
    "    \n",
    "    best_val_loss = float('inf')\n",
    "    best_train_loss = float('inf')\n",
    "    patience_counter = 0\n",
    "    best_state = None\n",
    "    \n",
    "    max_epochs = config.get('max_epochs', 200)\n",
    "    patience = config.get('patience', 10)\n",
    "    mask_ratio = config.get('mask_ratio', 0.2)\n",
    "    \n",
    "    for epoch in range(max_epochs):\n",
    "        # Train\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        for batch in train_loader:\n",
    "            batch = batch.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            context_score, reconstructed, mask = model(batch, mask_ratio=mask_ratio)\n",
    "            loss = masked_reconstruction_loss(batch, reconstructed, mask)\n",
    "            \n",
    "            loss.backward()\n",
    "            # Gradient clipping\n",
    "            nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_loss += loss.item()\n",
    "        \n",
    "        train_loss /= len(train_loader)\n",
    "        \n",
    "        # Validate\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for batch in val_loader:\n",
    "                batch = batch.to(device)\n",
    "                context_score, reconstructed, mask = model(batch, mask_ratio=mask_ratio)\n",
    "                loss = masked_reconstruction_loss(batch, reconstructed, mask)\n",
    "                val_loss += loss.item()\n",
    "        \n",
    "        val_loss /= len(val_loader)\n",
    "        \n",
    "        # Step scheduler\n",
    "        scheduler.step()\n",
    "        \n",
    "        # Early stopping\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            best_train_loss = train_loss\n",
    "            patience_counter = 0\n",
    "            best_state = {k: v.clone().cpu() for k, v in model.state_dict().items()}\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            if patience_counter >= patience:\n",
    "                print(f\"   Early stopping at epoch {epoch+1}\")\n",
    "                break\n",
    "        \n",
    "        if (epoch + 1) % 20 == 0:\n",
    "            print(f\"   Epoch {epoch+1}/{max_epochs}: train_loss={train_loss:.6f}, val_loss={val_loss:.6f}\")\n",
    "    \n",
    "    # Restore best weights\n",
    "    if best_state:\n",
    "        model.load_state_dict(best_state)\n",
    "    \n",
    "    overfit_ratio = best_val_loss / (best_train_loss + 1e-10)\n",
    "    \n",
    "    metrics = {\n",
    "        'train_loss': best_train_loss,\n",
    "        'val_loss': best_val_loss,\n",
    "        'overfit_ratio': overfit_ratio,\n",
    "        'epochs_trained': epoch + 1\n",
    "    }\n",
    "    \n",
    "    return model, metrics\n",
    "\n",
    "print(\"Training functions defined.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 7: Optuna HPO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-17T16:38:11.989827Z",
     "iopub.status.busy": "2026-02-17T16:38:11.989566Z",
     "iopub.status.idle": "2026-02-17T16:38:11.997997Z",
     "shell.execute_reply": "2026-02-17T16:38:11.997240Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HPO function defined.\n"
     ]
    }
   ],
   "source": [
    "def run_hpo(train_data, val_data, n_trials=30, timeout=1800):\n",
    "    \"\"\"\n",
    "    Run hyperparameter optimization using Optuna.\n",
    "    \n",
    "    Returns: best_params, best_value, n_completed_trials\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"HYPERPARAMETER OPTIMIZATION (OPTUNA)\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    def objective(trial):\n",
    "        # Sample hyperparameters\n",
    "        window_size = trial.suggest_categorical('window_size', [5, 10, 15, 20])\n",
    "\n",
    "        # Flatten parameter space: (d_model, n_heads) combinations\n",
    "        model_config = trial.suggest_categorical('model_config', [\n",
    "            (16, 2),\n",
    "            (24, 2),\n",
    "            (24, 4),\n",
    "            (32, 2),\n",
    "            (32, 4)\n",
    "        ])\n",
    "        d_model, n_heads = model_config\n",
    "\n",
    "        n_layers = trial.suggest_int('n_layers', 1, 2)\n",
    "        ffn_ratio = trial.suggest_categorical('ffn_ratio', [2, 3])\n",
    "        dropout = trial.suggest_float('dropout', 0.1, 0.3)\n",
    "        mask_ratio = trial.suggest_float('mask_ratio', 0.15, 0.30)\n",
    "        learning_rate = trial.suggest_float('learning_rate', 1e-4, 3e-3, log=True)\n",
    "        weight_decay = trial.suggest_float('weight_decay', 0.01, 0.1, log=True)\n",
    "        patience = trial.suggest_categorical('patience', [7, 10, 15])\n",
    "        \n",
    "        config = {\n",
    "            'window_size': window_size,\n",
    "            'd_model': d_model,\n",
    "            'n_heads': n_heads,\n",
    "            'n_layers': n_layers,\n",
    "            'ffn_ratio': ffn_ratio,\n",
    "            'dropout': dropout,\n",
    "            'mask_ratio': mask_ratio,\n",
    "            'learning_rate': learning_rate,\n",
    "            'weight_decay': weight_decay,\n",
    "            'patience': patience,\n",
    "            'max_epochs': 200,\n",
    "            'batch_size': 64\n",
    "        }\n",
    "        \n",
    "        # Create windows\n",
    "        try:\n",
    "            train_windows, _ = create_windows(train_data, window_size)\n",
    "            val_windows, _ = create_windows(val_data, window_size)\n",
    "        except ValueError as e:\n",
    "            print(f\"   Trial failed: {e}\")\n",
    "            return float('inf')\n",
    "        \n",
    "        # Create dataloaders\n",
    "        train_dataset = WindowDataset(train_windows)\n",
    "        val_dataset = WindowDataset(val_windows)\n",
    "        \n",
    "        train_loader = DataLoader(train_dataset, batch_size=config['batch_size'], shuffle=False)\n",
    "        val_loader = DataLoader(val_dataset, batch_size=config['batch_size'], shuffle=False)\n",
    "        \n",
    "        # Build model\n",
    "        model = TemporalContextTransformer(\n",
    "            input_dim=14,\n",
    "            d_model=d_model,\n",
    "            n_heads=n_heads,\n",
    "            n_layers=n_layers,\n",
    "            ffn_ratio=ffn_ratio,\n",
    "            dropout=dropout,\n",
    "            max_seq_len=20\n",
    "        )\n",
    "        \n",
    "        # Train\n",
    "        model, metrics = train_model(model, train_loader, val_loader, config)\n",
    "        \n",
    "        val_loss = metrics['val_loss']\n",
    "        overfit_ratio = metrics['overfit_ratio']\n",
    "        \n",
    "        # Pruning\n",
    "        trial.report(val_loss, step=metrics['epochs_trained'])\n",
    "        if trial.should_prune():\n",
    "            raise optuna.TrialPruned()\n",
    "        \n",
    "        # Penalize overfitting\n",
    "        penalty = max(0, overfit_ratio - 1.5) * 0.1\n",
    "        \n",
    "        return val_loss + penalty\n",
    "    \n",
    "    # Run optimization\n",
    "    study = optuna.create_study(\n",
    "        direction='minimize',\n",
    "        sampler=TPESampler(seed=SEED),\n",
    "        pruner=MedianPruner(n_startup_trials=5, n_warmup_steps=10)\n",
    "    )\n",
    "    \n",
    "    study.optimize(objective, n_trials=n_trials, timeout=timeout, show_progress_bar=True)\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"OPTUNA RESULTS\")\n",
    "    print(\"=\"*80)\n",
    "    print(f\"Number of completed trials: {len(study.trials)}\")\n",
    "    print(f\"Best trial value: {study.best_value:.6f}\")\n",
    "    print(f\"Best parameters:\")\n",
    "    for key, value in study.best_params.items():\n",
    "        print(f\"   {key}: {value}\")\n",
    "    \n",
    "    return study.best_params, study.best_value, len(study.trials)\n",
    "\n",
    "print(\"HPO function defined.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 8: Run HPO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-17T16:38:11.999941Z",
     "iopub.status.busy": "2026-02-17T16:38:11.999667Z",
     "iopub.status.idle": "2026-02-17T16:41:50.824997Z",
     "shell.execute_reply": "2026-02-17T16:41:50.824452Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2026-02-18 01:38:12,001]\u001b[0m A new study created in memory with name: no-name-be31da77-f234-4df0-9332-e81c9dd8ab71\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "HYPERPARAMETER OPTIMIZATION (OPTUNA)\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/30 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Epoch 20/200: train_loss=1.018332, val_loss=0.942577\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                      "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/30 [00:12<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Best trial: 0. Best value: 0.869323:   0%|          | 0/30 [00:12<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Best trial: 0. Best value: 0.869323:   3%|▎         | 1/30 [00:12<05:57, 12.33s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Best trial: 0. Best value: 0.869323:   3%|▎         | 1/30 [00:12<05:57, 12.33s/it, 12.32/1800 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Early stopping at epoch 27\n",
      "\u001b[32m[I 2026-02-18 01:38:24,327]\u001b[0m Trial 0 finished with value: 0.8693226405552456 and parameters: {'window_size': 10, 'model_config': (32, 2), 'n_layers': 2, 'ffn_ratio': 3, 'dropout': 0.26648852816008434, 'mask_ratio': 0.1818508666017414, 'learning_rate': 0.00018559980846490597, 'weight_decay': 0.015254729458052608, 'patience': 10}. Best is trial 0 with value: 0.8693226405552456.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                                       "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Best trial: 0. Best value: 0.869323:   3%|▎         | 1/30 [00:17<05:57, 12.33s/it, 12.32/1800 seconds]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Best trial: 1. Best value: 0.848066:   3%|▎         | 1/30 [00:17<05:57, 12.33s/it, 12.32/1800 seconds]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Best trial: 1. Best value: 0.848066:   7%|▋         | 2/30 [00:17<03:40,  7.88s/it, 12.32/1800 seconds]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Best trial: 1. Best value: 0.848066:   7%|▋         | 2/30 [00:17<03:40,  7.88s/it, 17.10/1800 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Early stopping at epoch 14\n",
      "\u001b[32m[I 2026-02-18 01:38:29,102]\u001b[0m Trial 1 finished with value: 0.8480663469859532 and parameters: {'window_size': 10, 'model_config': (24, 4), 'n_layers': 2, 'ffn_ratio': 3, 'dropout': 0.1341048247374583, 'mask_ratio': 0.1597577389477919, 'learning_rate': 0.00252126790477792, 'weight_decay': 0.0923915031962725, 'patience': 7}. Best is trial 1 with value: 0.8480663469859532.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Epoch 20/200: train_loss=0.910082, val_loss=0.915929\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                                       "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Best trial: 1. Best value: 0.848066:   7%|▋         | 2/30 [00:26<03:40,  7.88s/it, 17.10/1800 seconds]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Best trial: 2. Best value: 0.810552:   7%|▋         | 2/30 [00:26<03:40,  7.88s/it, 17.10/1800 seconds]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Best trial: 2. Best value: 0.810552:  10%|█         | 3/30 [00:26<03:55,  8.73s/it, 17.10/1800 seconds]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Best trial: 2. Best value: 0.810552:  10%|█         | 3/30 [00:26<03:55,  8.73s/it, 26.83/1800 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Early stopping at epoch 29\n",
      "\u001b[32m[I 2026-02-18 01:38:38,830]\u001b[0m Trial 2 finished with value: 0.8105517285210746 and parameters: {'window_size': 5, 'model_config': (24, 2), 'n_layers': 2, 'ffn_ratio': 2, 'dropout': 0.2939169255529117, 'mask_ratio': 0.26626992350416717, 'learning_rate': 0.002442046084491142, 'weight_decay': 0.07849235338159358, 'patience': 10}. Best is trial 2 with value: 0.8105517285210746.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Epoch 20/200: train_loss=0.982965, val_loss=0.886789\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                                       "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Best trial: 2. Best value: 0.810552:  10%|█         | 3/30 [00:34<03:55,  8.73s/it, 26.83/1800 seconds]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Best trial: 2. Best value: 0.810552:  10%|█         | 3/30 [00:34<03:55,  8.73s/it, 26.83/1800 seconds]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Best trial: 2. Best value: 0.810552:  13%|█▎        | 4/30 [00:34<03:36,  8.31s/it, 26.83/1800 seconds]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Best trial: 2. Best value: 0.810552:  13%|█▎        | 4/30 [00:34<03:36,  8.31s/it, 34.50/1800 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Early stopping at epoch 32\n",
      "\u001b[32m[I 2026-02-18 01:38:46,502]\u001b[0m Trial 3 finished with value: 0.8557278939655849 and parameters: {'window_size': 20, 'model_config': (24, 2), 'n_layers': 1, 'ffn_ratio': 2, 'dropout': 0.29737738732010344, 'mask_ratio': 0.2658367153944986, 'learning_rate': 0.00019657448966046135, 'weight_decay': 0.010127963257331486, 'patience': 7}. Best is trial 2 with value: 0.8105517285210746.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Epoch 20/200: train_loss=1.033801, val_loss=0.945230\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Epoch 40/200: train_loss=1.001741, val_loss=0.881472\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Epoch 60/200: train_loss=1.013461, val_loss=0.935711\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                                       "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Best trial: 2. Best value: 0.810552:  13%|█▎        | 4/30 [00:53<03:36,  8.31s/it, 34.50/1800 seconds]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Best trial: 2. Best value: 0.810552:  13%|█▎        | 4/30 [00:53<03:36,  8.31s/it, 34.50/1800 seconds]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Best trial: 2. Best value: 0.810552:  17%|█▋        | 5/30 [00:53<05:03, 12.13s/it, 34.50/1800 seconds]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Best trial: 2. Best value: 0.810552:  17%|█▋        | 5/30 [00:53<05:03, 12.13s/it, 53.41/1800 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Early stopping at epoch 79\n",
      "\u001b[32m[I 2026-02-18 01:39:05,410]\u001b[0m Trial 4 finished with value: 0.8399424382618496 and parameters: {'window_size': 5, 'model_config': (16, 2), 'n_layers': 1, 'ffn_ratio': 2, 'dropout': 0.2774425485152653, 'mask_ratio': 0.22083223877429237, 'learning_rate': 0.00015019490572374368, 'weight_decay': 0.05167075260023277, 'patience': 15}. Best is trial 2 with value: 0.8105517285210746.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Epoch 20/200: train_loss=1.033319, val_loss=0.965665\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                                       "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Best trial: 2. Best value: 0.810552:  17%|█▋        | 5/30 [01:05<05:03, 12.13s/it, 53.41/1800 seconds]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Best trial: 2. Best value: 0.810552:  17%|█▋        | 5/30 [01:05<05:03, 12.13s/it, 53.41/1800 seconds]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Best trial: 2. Best value: 0.810552:  20%|██        | 6/30 [01:05<04:53, 12.25s/it, 53.41/1800 seconds]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Best trial: 2. Best value: 0.810552:  20%|██        | 6/30 [01:05<04:53, 12.25s/it, 65.88/1800 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Early stopping at epoch 37\n",
      "\u001b[32m[I 2026-02-18 01:39:17,882]\u001b[0m Trial 5 finished with value: 0.8793254154069083 and parameters: {'window_size': 10, 'model_config': (24, 4), 'n_layers': 2, 'ffn_ratio': 3, 'dropout': 0.2511102277086097, 'mask_ratio': 0.18431972482374337, 'learning_rate': 0.0001299297674052037, 'weight_decay': 0.01948729021356848, 'patience': 10}. Best is trial 2 with value: 0.8105517285210746.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Epoch 20/200: train_loss=1.009601, val_loss=0.896938\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                                       "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Best trial: 2. Best value: 0.810552:  20%|██        | 6/30 [01:12<04:53, 12.25s/it, 65.88/1800 seconds]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Best trial: 2. Best value: 0.810552:  20%|██        | 6/30 [01:12<04:53, 12.25s/it, 65.88/1800 seconds]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Best trial: 2. Best value: 0.810552:  23%|██▎       | 7/30 [01:12<04:00, 10.47s/it, 65.88/1800 seconds]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Best trial: 2. Best value: 0.810552:  23%|██▎       | 7/30 [01:12<04:00, 10.47s/it, 72.68/1800 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Early stopping at epoch 28\n",
      "\u001b[32m[I 2026-02-18 01:39:24,684]\u001b[0m Trial 6 finished with value: 0.8928050994873047 and parameters: {'window_size': 10, 'model_config': (32, 2), 'n_layers': 1, 'ffn_ratio': 3, 'dropout': 0.2636029531844986, 'mask_ratio': 0.2791095874884515, 'learning_rate': 0.00010239273411172726, 'weight_decay': 0.03241509528627273, 'patience': 7}. Best is trial 2 with value: 0.8105517285210746.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Epoch 20/200: train_loss=0.941188, val_loss=0.911668\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                                       "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Best trial: 2. Best value: 0.810552:  23%|██▎       | 7/30 [01:19<04:00, 10.47s/it, 72.68/1800 seconds]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Best trial: 2. Best value: 0.810552:  23%|██▎       | 7/30 [01:19<04:00, 10.47s/it, 72.68/1800 seconds]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Best trial: 2. Best value: 0.810552:  27%|██▋       | 8/30 [01:19<03:23,  9.24s/it, 72.68/1800 seconds]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Best trial: 2. Best value: 0.810552:  27%|██▋       | 8/30 [01:19<03:23,  9.24s/it, 79.31/1800 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Early stopping at epoch 26\n",
      "\u001b[32m[I 2026-02-18 01:39:31,310]\u001b[0m Trial 7 finished with value: 0.8349365336554391 and parameters: {'window_size': 10, 'model_config': (24, 4), 'n_layers': 1, 'ffn_ratio': 2, 'dropout': 0.10737738947090657, 'mask_ratio': 0.2414346500969845, 'learning_rate': 0.0005527361503993266, 'weight_decay': 0.011258453832483528, 'patience': 10}. Best is trial 2 with value: 0.8105517285210746.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Epoch 20/200: train_loss=0.971242, val_loss=0.942300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                                       "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Best trial: 2. Best value: 0.810552:  27%|██▋       | 8/30 [01:28<03:23,  9.24s/it, 79.31/1800 seconds]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Best trial: 2. Best value: 0.810552:  27%|██▋       | 8/30 [01:28<03:23,  9.24s/it, 79.31/1800 seconds]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Best trial: 2. Best value: 0.810552:  30%|███       | 9/30 [01:28<03:10,  9.09s/it, 79.31/1800 seconds]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Best trial: 2. Best value: 0.810552:  30%|███       | 9/30 [01:28<03:10,  9.09s/it, 88.07/1800 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Early stopping at epoch 25\n",
      "\u001b[32m[I 2026-02-18 01:39:40,077]\u001b[0m Trial 8 finished with value: 0.8683063983917236 and parameters: {'window_size': 15, 'model_config': (24, 2), 'n_layers': 2, 'ffn_ratio': 2, 'dropout': 0.11805795401088166, 'mask_ratio': 0.2752953743383857, 'learning_rate': 0.00029773579612263796, 'weight_decay': 0.015364502781676042, 'patience': 15}. Best is trial 2 with value: 0.8105517285210746.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Epoch 20/200: train_loss=0.927969, val_loss=0.855931\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                                       "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Best trial: 2. Best value: 0.810552:  30%|███       | 9/30 [01:33<03:10,  9.09s/it, 88.07/1800 seconds]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Best trial: 2. Best value: 0.810552:  30%|███       | 9/30 [01:33<03:10,  9.09s/it, 88.07/1800 seconds]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Best trial: 2. Best value: 0.810552:  33%|███▎      | 10/30 [01:33<02:37,  7.89s/it, 88.07/1800 seconds]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Best trial: 2. Best value: 0.810552:  33%|███▎      | 10/30 [01:33<02:37,  7.89s/it, 93.28/1800 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Early stopping at epoch 23\n",
      "\u001b[32m[I 2026-02-18 01:39:45,280]\u001b[0m Trial 9 finished with value: 0.8169306984969548 and parameters: {'window_size': 20, 'model_config': (32, 2), 'n_layers': 1, 'ffn_ratio': 3, 'dropout': 0.27546787067619616, 'mask_ratio': 0.18869124415727334, 'learning_rate': 0.0009437923703573488, 'weight_decay': 0.06564810589958753, 'patience': 7}. Best is trial 2 with value: 0.8105517285210746.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                                        "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Best trial: 2. Best value: 0.810552:  33%|███▎      | 10/30 [01:37<02:37,  7.89s/it, 93.28/1800 seconds]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Best trial: 2. Best value: 0.810552:  33%|███▎      | 10/30 [01:37<02:37,  7.89s/it, 93.28/1800 seconds]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Best trial: 2. Best value: 0.810552:  37%|███▋      | 11/30 [01:37<02:11,  6.91s/it, 93.28/1800 seconds]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Best trial: 2. Best value: 0.810552:  37%|███▋      | 11/30 [01:37<02:11,  6.91s/it, 97.96/1800 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Early stopping at epoch 15\n",
      "\u001b[32m[I 2026-02-18 01:39:49,963]\u001b[0m Trial 10 finished with value: 0.8414711356163025 and parameters: {'window_size': 5, 'model_config': (32, 4), 'n_layers': 2, 'ffn_ratio': 2, 'dropout': 0.20050624353495927, 'mask_ratio': 0.23653947569997247, 'learning_rate': 0.0027374027426971623, 'weight_decay': 0.041396749389544275, 'patience': 10}. Best is trial 2 with value: 0.8105517285210746.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                                        "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Best trial: 2. Best value: 0.810552:  37%|███▋      | 11/30 [01:40<02:11,  6.91s/it, 97.96/1800 seconds]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Best trial: 2. Best value: 0.810552:  37%|███▋      | 11/30 [01:40<02:11,  6.91s/it, 97.96/1800 seconds]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Best trial: 2. Best value: 0.810552:  40%|████      | 12/30 [01:40<01:38,  5.49s/it, 97.96/1800 seconds]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Best trial: 2. Best value: 0.810552:  40%|████      | 12/30 [01:40<01:38,  5.49s/it, 100.19/1800 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Early stopping at epoch 10\n",
      "\u001b[32m[I 2026-02-18 01:39:52,191]\u001b[0m Trial 11 finished with value: 0.8830616133553642 and parameters: {'window_size': 20, 'model_config': (24, 2), 'n_layers': 1, 'ffn_ratio': 3, 'dropout': 0.22074762071794393, 'mask_ratio': 0.29886582656785377, 'learning_rate': 0.0011911493102132206, 'weight_decay': 0.09241145820526017, 'patience': 7}. Best is trial 2 with value: 0.8105517285210746.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                                         "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Best trial: 2. Best value: 0.810552:  40%|████      | 12/30 [01:44<01:38,  5.49s/it, 100.19/1800 seconds]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Best trial: 2. Best value: 0.810552:  40%|████      | 12/30 [01:44<01:38,  5.49s/it, 100.19/1800 seconds]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Best trial: 2. Best value: 0.810552:  43%|████▎     | 13/30 [01:44<01:25,  5.05s/it, 100.19/1800 seconds]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Best trial: 2. Best value: 0.810552:  43%|████▎     | 13/30 [01:44<01:25,  5.05s/it, 104.23/1800 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Early stopping at epoch 19\n",
      "\u001b[32m[I 2026-02-18 01:39:56,234]\u001b[0m Trial 12 finished with value: 0.864848792552948 and parameters: {'window_size': 5, 'model_config': (32, 2), 'n_layers': 1, 'ffn_ratio': 2, 'dropout': 0.16134245105421344, 'mask_ratio': 0.20662414280782768, 'learning_rate': 0.0012423428966730084, 'weight_decay': 0.06207651806442917, 'patience': 10}. Best is trial 2 with value: 0.8105517285210746.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                                         "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Best trial: 2. Best value: 0.810552:  43%|████▎     | 13/30 [01:46<01:25,  5.05s/it, 104.23/1800 seconds]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Best trial: 2. Best value: 0.810552:  43%|████▎     | 13/30 [01:46<01:25,  5.05s/it, 104.23/1800 seconds]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Best trial: 2. Best value: 0.810552:  47%|████▋     | 14/30 [01:46<01:08,  4.26s/it, 104.23/1800 seconds]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Best trial: 2. Best value: 0.810552:  47%|████▋     | 14/30 [01:46<01:08,  4.26s/it, 106.66/1800 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Early stopping at epoch 8\n",
      "\u001b[32m[I 2026-02-18 01:39:58,663]\u001b[0m Trial 13 finished with value: 0.8936977301325116 and parameters: {'window_size': 20, 'model_config': (16, 2), 'n_layers': 2, 'ffn_ratio': 3, 'dropout': 0.23189595634382337, 'mask_ratio': 0.19188389978867815, 'learning_rate': 0.0011468920051395848, 'weight_decay': 0.06450285213659933, 'patience': 7}. Best is trial 2 with value: 0.8105517285210746.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Epoch 20/200: train_loss=0.986567, val_loss=0.956859\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                                         "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Best trial: 2. Best value: 0.810552:  47%|████▋     | 14/30 [01:54<01:08,  4.26s/it, 106.66/1800 seconds]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Best trial: 2. Best value: 0.810552:  47%|████▋     | 14/30 [01:54<01:08,  4.26s/it, 106.66/1800 seconds]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Best trial: 2. Best value: 0.810552:  50%|█████     | 15/30 [01:54<01:20,  5.40s/it, 106.66/1800 seconds]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Best trial: 2. Best value: 0.810552:  50%|█████     | 15/30 [01:54<01:20,  5.40s/it, 114.70/1800 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Early stopping at epoch 37\n",
      "\u001b[32m[I 2026-02-18 01:40:06,705]\u001b[0m Trial 14 finished with value: 0.8556677103042603 and parameters: {'window_size': 15, 'model_config': (32, 4), 'n_layers': 1, 'ffn_ratio': 3, 'dropout': 0.29979661750343023, 'mask_ratio': 0.15543565321798464, 'learning_rate': 0.0006689802001564378, 'weight_decay': 0.07468959677032493, 'patience': 15}. Best is trial 2 with value: 0.8105517285210746.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                                         "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Best trial: 2. Best value: 0.810552:  50%|█████     | 15/30 [01:58<01:20,  5.40s/it, 114.70/1800 seconds]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Best trial: 2. Best value: 0.810552:  50%|█████     | 15/30 [01:58<01:20,  5.40s/it, 114.70/1800 seconds]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Best trial: 2. Best value: 0.810552:  53%|█████▎    | 16/30 [01:58<01:10,  5.00s/it, 114.70/1800 seconds]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Best trial: 2. Best value: 0.810552:  53%|█████▎    | 16/30 [01:58<01:10,  5.00s/it, 118.78/1800 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Early stopping at epoch 13\n",
      "\u001b[32m[I 2026-02-18 01:40:10,782]\u001b[0m Trial 15 finished with value: 0.8250233956745693 and parameters: {'window_size': 20, 'model_config': (32, 2), 'n_layers': 2, 'ffn_ratio': 2, 'dropout': 0.17030433162664235, 'mask_ratio': 0.2504433992591721, 'learning_rate': 0.0018821242414979503, 'weight_decay': 0.04109567876595779, 'patience': 10}. Best is trial 2 with value: 0.8105517285210746.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                                         "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Best trial: 2. Best value: 0.810552:  53%|█████▎    | 16/30 [02:02<01:10,  5.00s/it, 118.78/1800 seconds]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Best trial: 2. Best value: 0.810552:  53%|█████▎    | 16/30 [02:02<01:10,  5.00s/it, 118.78/1800 seconds]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Best trial: 2. Best value: 0.810552:  57%|█████▋    | 17/30 [02:02<01:01,  4.72s/it, 118.78/1800 seconds]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Best trial: 2. Best value: 0.810552:  57%|█████▋    | 17/30 [02:02<01:01,  4.72s/it, 122.85/1800 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Early stopping at epoch 18\n",
      "\u001b[32m[I 2026-02-18 01:40:14,850]\u001b[0m Trial 16 finished with value: 0.8503855381693158 and parameters: {'window_size': 5, 'model_config': (24, 2), 'n_layers': 1, 'ffn_ratio': 2, 'dropout': 0.23976017097175045, 'mask_ratio': 0.22194274508017123, 'learning_rate': 0.0008431966570898267, 'weight_decay': 0.024477620362977685, 'patience': 7}. Best is trial 2 with value: 0.8105517285210746.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Epoch 20/200: train_loss=1.023567, val_loss=0.919587\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Epoch 40/200: train_loss=0.941055, val_loss=0.909008\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                                         "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Best trial: 2. Best value: 0.810552:  57%|█████▋    | 17/30 [02:17<01:01,  4.72s/it, 122.85/1800 seconds]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Best trial: 2. Best value: 0.810552:  57%|█████▋    | 17/30 [02:17<01:01,  4.72s/it, 122.85/1800 seconds]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Best trial: 2. Best value: 0.810552:  60%|██████    | 18/30 [02:17<01:31,  7.59s/it, 122.85/1800 seconds]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Best trial: 2. Best value: 0.810552:  60%|██████    | 18/30 [02:17<01:31,  7.59s/it, 137.11/1800 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Early stopping at epoch 47\n",
      "\u001b[32m[I 2026-02-18 01:40:29,108]\u001b[0m Trial 17 finished with value: 0.8448534096990313 and parameters: {'window_size': 5, 'model_config': (24, 2), 'n_layers': 2, 'ffn_ratio': 3, 'dropout': 0.2785851959737444, 'mask_ratio': 0.20660162270208032, 'learning_rate': 0.00038713573695610897, 'weight_decay': 0.049764384033919445, 'patience': 10}. Best is trial 2 with value: 0.8105517285210746.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Epoch 20/200: train_loss=0.940269, val_loss=0.882034\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                                         "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Best trial: 2. Best value: 0.810552:  60%|██████    | 18/30 [02:24<01:31,  7.59s/it, 137.11/1800 seconds]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Best trial: 2. Best value: 0.810552:  60%|██████    | 18/30 [02:24<01:31,  7.59s/it, 137.11/1800 seconds]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Best trial: 2. Best value: 0.810552:  63%|██████▎   | 19/30 [02:24<01:21,  7.42s/it, 137.11/1800 seconds]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Best trial: 2. Best value: 0.810552:  63%|██████▎   | 19/30 [02:24<01:21,  7.42s/it, 144.15/1800 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Early stopping at epoch 23\n",
      "\u001b[32m[I 2026-02-18 01:40:36,154]\u001b[0m Trial 18 pruned. \u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Epoch 20/200: train_loss=0.913822, val_loss=0.894806\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Epoch 40/200: train_loss=0.889360, val_loss=0.874123\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                                         "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Best trial: 2. Best value: 0.810552:  63%|██████▎   | 19/30 [02:35<01:21,  7.42s/it, 144.15/1800 seconds]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Best trial: 2. Best value: 0.810552:  63%|██████▎   | 19/30 [02:35<01:21,  7.42s/it, 144.15/1800 seconds]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Best trial: 2. Best value: 0.810552:  67%|██████▋   | 20/30 [02:35<01:24,  8.50s/it, 144.15/1800 seconds]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Best trial: 2. Best value: 0.810552:  67%|██████▋   | 20/30 [02:35<01:24,  8.50s/it, 155.15/1800 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Early stopping at epoch 50\n",
      "\u001b[32m[I 2026-02-18 01:40:47,151]\u001b[0m Trial 19 finished with value: 0.8430841990879604 and parameters: {'window_size': 15, 'model_config': (16, 2), 'n_layers': 1, 'ffn_ratio': 3, 'dropout': 0.18204408451786194, 'mask_ratio': 0.2555041037399341, 'learning_rate': 0.0017348165810743695, 'weight_decay': 0.09965433220579406, 'patience': 15}. Best is trial 2 with value: 0.8105517285210746.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Epoch 20/200: train_loss=0.954296, val_loss=0.888178\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                                         "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Best trial: 2. Best value: 0.810552:  67%|██████▋   | 20/30 [02:41<01:24,  8.50s/it, 155.15/1800 seconds]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Best trial: 2. Best value: 0.810552:  67%|██████▋   | 20/30 [02:41<01:24,  8.50s/it, 155.15/1800 seconds]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Best trial: 2. Best value: 0.810552:  70%|███████   | 21/30 [02:41<01:10,  7.83s/it, 155.15/1800 seconds]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Best trial: 2. Best value: 0.810552:  70%|███████   | 21/30 [02:41<01:10,  7.83s/it, 161.43/1800 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Early stopping at epoch 29\n",
      "\u001b[32m[I 2026-02-18 01:40:53,427]\u001b[0m Trial 20 pruned. \u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Epoch 20/200: train_loss=0.912612, val_loss=0.924098\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                                         "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Best trial: 2. Best value: 0.810552:  70%|███████   | 21/30 [02:48<01:10,  7.83s/it, 161.43/1800 seconds]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Best trial: 2. Best value: 0.810552:  70%|███████   | 21/30 [02:48<01:10,  7.83s/it, 161.43/1800 seconds]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Best trial: 2. Best value: 0.810552:  73%|███████▎  | 22/30 [02:48<01:01,  7.75s/it, 161.43/1800 seconds]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Best trial: 2. Best value: 0.810552:  73%|███████▎  | 22/30 [02:48<01:01,  7.75s/it, 168.99/1800 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Early stopping at epoch 25\n",
      "\u001b[32m[I 2026-02-18 01:41:00,989]\u001b[0m Trial 21 finished with value: 0.8553511244910104 and parameters: {'window_size': 20, 'model_config': (32, 2), 'n_layers': 2, 'ffn_ratio': 2, 'dropout': 0.1698534837998375, 'mask_ratio': 0.24488914699075237, 'learning_rate': 0.001984197401273609, 'weight_decay': 0.04263266581745791, 'patience': 10}. Best is trial 2 with value: 0.8105517285210746.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Epoch 20/200: train_loss=0.964416, val_loss=0.921506\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                                         "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Best trial: 2. Best value: 0.810552:  73%|███████▎  | 22/30 [02:56<01:01,  7.75s/it, 168.99/1800 seconds]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Best trial: 2. Best value: 0.810552:  73%|███████▎  | 22/30 [02:56<01:01,  7.75s/it, 168.99/1800 seconds]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Best trial: 2. Best value: 0.810552:  77%|███████▋  | 23/30 [02:56<00:54,  7.78s/it, 168.99/1800 seconds]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Best trial: 2. Best value: 0.810552:  77%|███████▋  | 23/30 [02:56<00:54,  7.78s/it, 176.84/1800 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Early stopping at epoch 26\n",
      "\u001b[32m[I 2026-02-18 01:41:08,846]\u001b[0m Trial 22 pruned. \u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Epoch 20/200: train_loss=0.908030, val_loss=0.819794\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                                         "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Best trial: 2. Best value: 0.810552:  77%|███████▋  | 23/30 [03:05<00:54,  7.78s/it, 176.84/1800 seconds]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Best trial: 2. Best value: 0.810552:  77%|███████▋  | 23/30 [03:06<00:54,  7.78s/it, 176.84/1800 seconds]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Best trial: 2. Best value: 0.810552:  80%|████████  | 24/30 [03:06<00:49,  8.19s/it, 176.84/1800 seconds]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Best trial: 2. Best value: 0.810552:  80%|████████  | 24/30 [03:06<00:49,  8.19s/it, 186.00/1800 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Early stopping at epoch 30\n",
      "\u001b[32m[I 2026-02-18 01:41:18,001]\u001b[0m Trial 23 finished with value: 0.8197942205837795 and parameters: {'window_size': 20, 'model_config': (32, 2), 'n_layers': 2, 'ffn_ratio': 2, 'dropout': 0.18207939734266204, 'mask_ratio': 0.2842059987893025, 'learning_rate': 0.0029606536994747465, 'weight_decay': 0.037567145465111515, 'patience': 10}. Best is trial 2 with value: 0.8105517285210746.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Epoch 20/200: train_loss=0.894058, val_loss=0.874317\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                                         "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Best trial: 2. Best value: 0.810552:  80%|████████  | 24/30 [03:14<00:49,  8.19s/it, 186.00/1800 seconds]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Best trial: 2. Best value: 0.810552:  80%|████████  | 24/30 [03:14<00:49,  8.19s/it, 186.00/1800 seconds]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Best trial: 2. Best value: 0.810552:  83%|████████▎ | 25/30 [03:14<00:41,  8.28s/it, 186.00/1800 seconds]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Best trial: 2. Best value: 0.810552:  83%|████████▎ | 25/30 [03:14<00:41,  8.28s/it, 194.49/1800 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Early stopping at epoch 28\n",
      "\u001b[32m[I 2026-02-18 01:41:26,491]\u001b[0m Trial 24 finished with value: 0.8465127604348319 and parameters: {'window_size': 5, 'model_config': (32, 2), 'n_layers': 2, 'ffn_ratio': 2, 'dropout': 0.18695911311145635, 'mask_ratio': 0.28585076195675124, 'learning_rate': 0.0028370429601712035, 'weight_decay': 0.07234533455482471, 'patience': 10}. Best is trial 2 with value: 0.8105517285210746.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                                         "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Best trial: 2. Best value: 0.810552:  83%|████████▎ | 25/30 [03:18<00:41,  8.28s/it, 194.49/1800 seconds]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Best trial: 2. Best value: 0.810552:  83%|████████▎ | 25/30 [03:18<00:41,  8.28s/it, 194.49/1800 seconds]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Best trial: 2. Best value: 0.810552:  87%|████████▋ | 26/30 [03:18<00:27,  6.97s/it, 194.49/1800 seconds]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Best trial: 2. Best value: 0.810552:  87%|████████▋ | 26/30 [03:18<00:27,  6.97s/it, 198.40/1800 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Early stopping at epoch 13\n",
      "\u001b[32m[I 2026-02-18 01:41:30,399]\u001b[0m Trial 25 pruned. \u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                                         "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Best trial: 2. Best value: 0.810552:  87%|████████▋ | 26/30 [03:22<00:27,  6.97s/it, 198.40/1800 seconds]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Best trial: 2. Best value: 0.810552:  87%|████████▋ | 26/30 [03:22<00:27,  6.97s/it, 198.40/1800 seconds]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Best trial: 2. Best value: 0.810552:  90%|█████████ | 27/30 [03:22<00:18,  6.18s/it, 198.40/1800 seconds]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Best trial: 2. Best value: 0.810552:  90%|█████████ | 27/30 [03:22<00:18,  6.18s/it, 202.72/1800 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Early stopping at epoch 14\n",
      "\u001b[32m[I 2026-02-18 01:41:34,724]\u001b[0m Trial 26 pruned. \u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Epoch 20/200: train_loss=0.958592, val_loss=0.879660\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                                         "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Best trial: 2. Best value: 0.810552:  90%|█████████ | 27/30 [03:29<00:18,  6.18s/it, 202.72/1800 seconds]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Best trial: 2. Best value: 0.810552:  90%|█████████ | 27/30 [03:29<00:18,  6.18s/it, 202.72/1800 seconds]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Best trial: 2. Best value: 0.810552:  93%|█████████▎| 28/30 [03:29<00:12,  6.33s/it, 202.72/1800 seconds]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Best trial: 2. Best value: 0.810552:  93%|█████████▎| 28/30 [03:29<00:12,  6.33s/it, 209.42/1800 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Early stopping at epoch 22\n",
      "\u001b[32m[I 2026-02-18 01:41:41,420]\u001b[0m Trial 27 finished with value: 0.8511484265327454 and parameters: {'window_size': 5, 'model_config': (32, 2), 'n_layers': 2, 'ffn_ratio': 2, 'dropout': 0.26020429305198206, 'mask_ratio': 0.28616317727284757, 'learning_rate': 0.0009545217958209343, 'weight_decay': 0.04775598084163709, 'patience': 10}. Best is trial 2 with value: 0.8105517285210746.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Epoch 20/200: train_loss=0.920677, val_loss=0.870079\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                                         "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Best trial: 2. Best value: 0.810552:  93%|█████████▎| 28/30 [03:35<00:12,  6.33s/it, 209.42/1800 seconds]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Best trial: 2. Best value: 0.810552:  93%|█████████▎| 28/30 [03:35<00:12,  6.33s/it, 209.42/1800 seconds]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Best trial: 2. Best value: 0.810552:  97%|█████████▋| 29/30 [03:35<00:06,  6.26s/it, 209.42/1800 seconds]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Best trial: 2. Best value: 0.810552:  97%|█████████▋| 29/30 [03:35<00:06,  6.26s/it, 215.50/1800 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Early stopping at epoch 28\n",
      "\u001b[32m[I 2026-02-18 01:41:47,499]\u001b[0m Trial 28 finished with value: 0.8360454951013837 and parameters: {'window_size': 15, 'model_config': (24, 2), 'n_layers': 1, 'ffn_ratio': 3, 'dropout': 0.22631669605920351, 'mask_ratio': 0.20606517736038132, 'learning_rate': 0.001483986220706737, 'weight_decay': 0.0830431722412956, 'patience': 15}. Best is trial 2 with value: 0.8105517285210746.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                                         "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Best trial: 2. Best value: 0.810552:  97%|█████████▋| 29/30 [03:38<00:06,  6.26s/it, 215.50/1800 seconds]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Best trial: 2. Best value: 0.810552:  97%|█████████▋| 29/30 [03:38<00:06,  6.26s/it, 215.50/1800 seconds]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Best trial: 2. Best value: 0.810552: 100%|██████████| 30/30 [03:38<00:00,  5.37s/it, 215.50/1800 seconds]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Best trial: 2. Best value: 0.810552: 100%|██████████| 30/30 [03:38<00:00,  5.37s/it, 218.81/1800 seconds]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Best trial: 2. Best value: 0.810552: 100%|██████████| 30/30 [03:38<00:00,  7.29s/it, 218.81/1800 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Early stopping at epoch 11\n",
      "\u001b[32m[I 2026-02-18 01:41:50,812]\u001b[0m Trial 29 finished with value: 0.8453250314508166 and parameters: {'window_size': 20, 'model_config': (32, 2), 'n_layers': 2, 'ffn_ratio': 3, 'dropout': 0.2835231688481889, 'mask_ratio': 0.19272995236447615, 'learning_rate': 0.00216409733116546, 'weight_decay': 0.06366781759826982, 'patience': 7}. Best is trial 2 with value: 0.8105517285210746.\u001b[0m\n",
      "\n",
      "================================================================================\n",
      "OPTUNA RESULTS\n",
      "================================================================================\n",
      "Number of completed trials: 30\n",
      "Best trial value: 0.810552\n",
      "Best parameters:\n",
      "   window_size: 5\n",
      "   model_config: (24, 2)\n",
      "   n_layers: 2\n",
      "   ffn_ratio: 2\n",
      "   dropout: 0.2939169255529117\n",
      "   mask_ratio: 0.26626992350416717\n",
      "   learning_rate: 0.002442046084491142\n",
      "   weight_decay: 0.07849235338159358\n",
      "   patience: 10\n",
      "\n",
      "[OK] HPO complete. Best validation loss: 0.810552\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Run hyperparameter optimization\n",
    "best_params, best_value, n_completed = run_hpo(\n",
    "    train_data, val_data,\n",
    "    n_trials=30,\n",
    "    timeout=1800  # 30 minutes\n",
    ")\n",
    "\n",
    "print(f\"\\n[OK] HPO complete. Best validation loss: {best_value:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 9: Final Training with Best Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-17T16:41:50.827264Z",
     "iopub.status.busy": "2026-02-17T16:41:50.826890Z",
     "iopub.status.idle": "2026-02-17T16:42:00.535188Z",
     "shell.execute_reply": "2026-02-17T16:42:00.534393Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "FINAL TRAINING WITH BEST PARAMETERS\n",
      "================================================================================\n",
      "\n",
      "Final model parameters: 11,007\n",
      "Target range: 3,000-10,000\n",
      "Status: ⚠ WARNING\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Epoch 20/200: train_loss=0.891611, val_loss=0.883879\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Early stopping at epoch 27\n",
      "\n",
      "================================================================================\n",
      "FINAL TRAINING METRICS\n",
      "================================================================================\n",
      "train_loss: 0.8963682187928094\n",
      "val_loss: 0.8526514172554016\n",
      "overfit_ratio: 0.9512289696176348\n",
      "epochs_trained: 27\n",
      "\n",
      "[OK] Final training complete.\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"FINAL TRAINING WITH BEST PARAMETERS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Extract best hyperparameters\n",
    "window_size = best_params['window_size']\n",
    "d_model, n_heads = best_params['model_config']\n",
    "n_layers = best_params['n_layers']\n",
    "ffn_ratio = best_params['ffn_ratio']\n",
    "dropout = best_params['dropout']\n",
    "mask_ratio = best_params['mask_ratio']\n",
    "learning_rate = best_params['learning_rate']\n",
    "weight_decay = best_params['weight_decay']\n",
    "patience = best_params['patience']\n",
    "\n",
    "# Create windows for train+val combined (for final training)\n",
    "train_val_data = pd.concat([train_data, val_data])\n",
    "train_val_windows, train_val_dates = create_windows(train_val_data, window_size)\n",
    "\n",
    "# Create windows for validation (to monitor training)\n",
    "val_windows, val_dates = create_windows(val_data, window_size)\n",
    "\n",
    "# Create dataloaders\n",
    "train_val_dataset = WindowDataset(train_val_windows)\n",
    "val_dataset = WindowDataset(val_windows)\n",
    "\n",
    "train_val_loader = DataLoader(train_val_dataset, batch_size=64, shuffle=False)\n",
    "val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "# Build final model\n",
    "final_model = TemporalContextTransformer(\n",
    "    input_dim=14,\n",
    "    d_model=d_model,\n",
    "    n_heads=n_heads,\n",
    "    n_layers=n_layers,\n",
    "    ffn_ratio=ffn_ratio,\n",
    "    dropout=dropout,\n",
    "    max_seq_len=20\n",
    ")\n",
    "\n",
    "# Count parameters\n",
    "n_params = sum(p.numel() for p in final_model.parameters())\n",
    "print(f\"\\nFinal model parameters: {n_params:,}\")\n",
    "print(f\"Target range: 3,000-10,000\")\n",
    "print(f\"Status: {'✓ OK' if 3000 <= n_params <= 10000 else '⚠ WARNING'}\")\n",
    "\n",
    "# Train final model\n",
    "final_config = {\n",
    "    'learning_rate': learning_rate,\n",
    "    'weight_decay': weight_decay,\n",
    "    'patience': patience,\n",
    "    'mask_ratio': mask_ratio,\n",
    "    'max_epochs': 200,\n",
    "    'batch_size': 64\n",
    "}\n",
    "\n",
    "final_model, final_metrics = train_model(final_model, train_val_loader, val_loader, final_config)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"FINAL TRAINING METRICS\")\n",
    "print(\"=\"*80)\n",
    "for key, value in final_metrics.items():\n",
    "    print(f\"{key}: {value}\")\n",
    "\n",
    "# Move model to CPU for inference\n",
    "final_model = final_model.cpu()\n",
    "final_model.eval()\n",
    "\n",
    "print(\"\\n[OK] Final training complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 10: Generate Submodel Output for Full Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-17T16:42:00.536985Z",
     "iopub.status.busy": "2026-02-17T16:42:00.536758Z",
     "iopub.status.idle": "2026-02-17T16:42:00.606372Z",
     "shell.execute_reply": "2026-02-17T16:42:00.605705Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "GENERATING SUBMODEL OUTPUT\n",
      "================================================================================\n",
      "Full windows: torch.Size([2712, 5, 14])\n",
      "Date range: 2015-02-05 00:00:00 to 2026-02-12 00:00:00\n",
      "\n",
      "Output shape: (2712, 2)\n",
      "Output columns: ['date', 'temporal_context_score']\n",
      "\n",
      "Output statistics:\n",
      "count    2712.000000\n",
      "mean        0.196092\n",
      "std         0.302998\n",
      "min         0.000920\n",
      "25%         0.005154\n",
      "50%         0.023000\n",
      "75%         0.289475\n",
      "max         1.000000\n",
      "Name: temporal_context_score, dtype: float64\n",
      "\n",
      "Quality checks:\n",
      "   NaN values: 0 ✓ OK\n",
      "   Inf values: 0 ✓ OK\n",
      "   Constant output: ✓ OK\n",
      "   Range [0,1]: ✓ OK\n",
      "\n",
      "[OK] Submodel output generated.\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"GENERATING SUBMODEL OUTPUT\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Create windows for full dataset\n",
    "full_windows, full_dates = create_windows(full_data, window_size)\n",
    "\n",
    "print(f\"Full windows: {full_windows.shape}\")\n",
    "print(f\"Date range: {full_dates[0]} to {full_dates[-1]}\")\n",
    "\n",
    "# Extract context scores\n",
    "final_model.eval()\n",
    "with torch.no_grad():\n",
    "    context_scores = []\n",
    "    batch_size = 256\n",
    "    \n",
    "    for i in range(0, len(full_windows), batch_size):\n",
    "        batch = full_windows[i:i+batch_size]\n",
    "        scores = final_model.extract(batch)\n",
    "        context_scores.append(scores.cpu().numpy())\n",
    "    \n",
    "    context_scores = np.concatenate(context_scores, axis=0).flatten()\n",
    "\n",
    "# Create output DataFrame\n",
    "output = pd.DataFrame({\n",
    "    'date': full_dates,\n",
    "    'temporal_context_score': context_scores\n",
    "})\n",
    "\n",
    "print(f\"\\nOutput shape: {output.shape}\")\n",
    "print(f\"Output columns: {list(output.columns)}\")\n",
    "print(f\"\\nOutput statistics:\")\n",
    "print(output['temporal_context_score'].describe())\n",
    "\n",
    "# Check for issues\n",
    "n_nan = output['temporal_context_score'].isna().sum()\n",
    "n_inf = np.isinf(output['temporal_context_score']).sum()\n",
    "is_constant = output['temporal_context_score'].std() < 1e-10\n",
    "\n",
    "print(f\"\\nQuality checks:\")\n",
    "print(f\"   NaN values: {n_nan} {'✓ OK' if n_nan == 0 else '✗ FAIL'}\")\n",
    "print(f\"   Inf values: {n_inf} {'✓ OK' if n_inf == 0 else '✗ FAIL'}\")\n",
    "print(f\"   Constant output: {'✗ FAIL' if is_constant else '✓ OK'}\")\n",
    "print(f\"   Range [0,1]: {'✓ OK' if output['temporal_context_score'].min() >= 0 and output['temporal_context_score'].max() <= 1 else '✗ FAIL'}\")\n",
    "\n",
    "print(\"\\n[OK] Submodel output generated.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 11: Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-17T16:42:00.608191Z",
     "iopub.status.busy": "2026-02-17T16:42:00.607950Z",
     "iopub.status.idle": "2026-02-17T16:42:00.638125Z",
     "shell.execute_reply": "2026-02-17T16:42:00.637317Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "SAVING RESULTS\n",
      "================================================================================\n",
      "[OK] Saved: submodel_output.csv\n",
      "[OK] Saved: model.pt\n",
      "[OK] Saved: training_result.json\n",
      "\n",
      "================================================================================\n",
      "TRAINING COMPLETE\n",
      "================================================================================\n",
      "Finished: 2026-02-18T01:42:00.635531\n",
      "\n",
      "Outputs:\n",
      "  1. submodel_output.csv (2712 rows)\n",
      "  2. model.pt (11,007 parameters)\n",
      "  3. training_result.json\n",
      "\n",
      "Ready for evaluator.\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"SAVING RESULTS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Save submodel output CSV\n",
    "output.to_csv(\"submodel_output.csv\", index=False)\n",
    "print(\"[OK] Saved: submodel_output.csv\")\n",
    "\n",
    "# Save model\n",
    "torch.save({\n",
    "    'model_state': final_model.state_dict(),\n",
    "    'config': {\n",
    "        'd_model': d_model,\n",
    "        'n_heads': n_heads,\n",
    "        'n_layers': n_layers,\n",
    "        'ffn_ratio': ffn_ratio,\n",
    "        'dropout': dropout,\n",
    "        'window_size': window_size\n",
    "    }\n",
    "}, \"model.pt\")\n",
    "print(\"[OK] Saved: model.pt\")\n",
    "\n",
    "# Save training result JSON\n",
    "result = {\n",
    "    \"feature\": \"temporal_context\",\n",
    "    \"attempt\": 1,\n",
    "    \"timestamp\": datetime.now().isoformat(),\n",
    "    \"best_params\": best_params,\n",
    "    \"metrics\": final_metrics,\n",
    "    \"optuna_trials_completed\": n_completed,\n",
    "    \"optuna_best_value\": best_value,\n",
    "    \"model_param_count\": n_params,\n",
    "    \"output_shape\": list(output.shape),\n",
    "    \"output_columns\": list(output.columns),\n",
    "    \"output_statistics\": {\n",
    "        \"mean\": float(output['temporal_context_score'].mean()),\n",
    "        \"std\": float(output['temporal_context_score'].std()),\n",
    "        \"min\": float(output['temporal_context_score'].min()),\n",
    "        \"max\": float(output['temporal_context_score'].max()),\n",
    "        \"median\": float(output['temporal_context_score'].median())\n",
    "    },\n",
    "    \"data_info\": {\n",
    "        \"train_samples\": len(train_data),\n",
    "        \"val_samples\": len(val_data),\n",
    "        \"test_samples\": len(test_data),\n",
    "        \"full_samples\": len(full_data),\n",
    "        \"window_size\": window_size,\n",
    "        \"windowed_samples\": len(output)\n",
    "    },\n",
    "    \"quality_checks\": {\n",
    "        \"nan_count\": int(n_nan),\n",
    "        \"inf_count\": int(n_inf),\n",
    "        \"is_constant\": bool(is_constant),\n",
    "        \"in_range_0_1\": bool(output['temporal_context_score'].min() >= 0 and output['temporal_context_score'].max() <= 1)\n",
    "    }\n",
    "}\n",
    "\n",
    "with open(\"training_result.json\", \"w\") as f:\n",
    "    json.dump(result, f, indent=2, default=str)\n",
    "\n",
    "print(\"[OK] Saved: training_result.json\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"TRAINING COMPLETE\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Finished: {datetime.now().isoformat()}\")\n",
    "print(f\"\\nOutputs:\")\n",
    "print(f\"  1. submodel_output.csv ({len(output)} rows)\")\n",
    "print(f\"  2. model.pt ({n_params:,} parameters)\")\n",
    "print(f\"  3. training_result.json\")\n",
    "print(\"\\nReady for evaluator.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
