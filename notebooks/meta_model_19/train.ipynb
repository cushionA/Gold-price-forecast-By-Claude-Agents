{
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gold Meta-Model Training - Attempt 19\n",
    "\n",
    "**Architecture:** Optuna HPO (100 trials) -> Bootstrap Data Subsampling Ensemble (12 models, 80% bootstrap)\n",
    "\n",
    "**Key Changes from Attempt 18:**\n",
    "1. **Optuna HPO (100 trials)** to find optimal hyperparameters for 28-feature space\n",
    "   - Attempt 18 used attempt 7 params optimized for 24 features, NOT 28 features\n",
    "   - Root cause of regression: mismatched feature space and hyperparameters\n",
    "2. **Composite objective** for HPO: DA * 0.6 + Sharpe_norm * 0.3 + (-MAE_norm) * 0.1\n",
    "3. **Bootstrap ensemble** (12 models, 80%) applied AFTER HPO with best params\n",
    "\n",
    "**Feature Set (28 features):**\n",
    "- Base features (5): real_rate_change, dxy_change, vix, yield_spread_change, inflation_exp_change\n",
    "- VIX submodel (3): vix_regime_probability, vix_mean_reversion_z, vix_persistence\n",
    "- Technical submodel (3): tech_trend_regime_prob, tech_mean_reversion_z, tech_volatility_regime\n",
    "- Cross-asset submodel (3): xasset_regime_prob, xasset_recession_signal, xasset_divergence\n",
    "- Yield curve submodel (2): yc_spread_velocity_z, yc_curvature_z\n",
    "- ETF flow submodel (3): etf_regime_prob, etf_capital_intensity, etf_pv_divergence\n",
    "- Inflation expectation submodel (3): ie_regime_prob, ie_anchoring_z, ie_gold_sensitivity_z\n",
    "- Options market submodel (1): options_risk_regime_prob\n",
    "- Temporal context submodel (1): temporal_context_score\n",
    "- Real rate submodel attempt 7 (4): rr_level_change_z, rr_slope_chg_z, rr_curvature_chg_z, rr_slope_level_z\n",
    "\n",
    "**Reference Metrics:**\n",
    "- Attempt 7 (best overall): DA 60.04%, HCDA 64.13%, MAE 0.9429%, Sharpe 2.4636\n",
    "- Attempt 18 (predecessor): DA 58.30%, HCDA 63.04%, MAE 0.9527%, Sharpe 1.8624\n",
    "- Design: Optuna HPO specifically tuned for 28-feature space"
   ],
   "id": "cell-0"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import pandas as pd\nimport numpy as np\nimport xgboost as xgb\nimport optuna\nfrom optuna.samplers import TPESampler\nimport json\nimport os\nimport glob\nfrom datetime import datetime\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# Set random seeds\nnp.random.seed(42)\n\nprint(f\"XGBoost version: {xgb.__version__}\")\nprint(f\"Optuna version: {optuna.__version__}\")\nprint(f\"Started: {datetime.now().isoformat()}\")\nprint(f\"Attempt: 19\")\nprint(f\"Architecture: Optuna HPO (100 trials) + Bootstrap Data Subsampling Ensemble (12 models, 80%)\")",
   "id": "cell-1"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Definitions (28 features)"
   ],
   "id": "cell-2"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FEATURE_COLUMNS = [\n",
    "    # Base features (5)\n",
    "    'real_rate_change',\n",
    "    'dxy_change',\n",
    "    'vix',\n",
    "    'yield_spread_change',\n",
    "    'inflation_exp_change',\n",
    "    # VIX submodel (3)\n",
    "    'vix_regime_probability',\n",
    "    'vix_mean_reversion_z',\n",
    "    'vix_persistence',\n",
    "    # Technical submodel (3)\n",
    "    'tech_trend_regime_prob',\n",
    "    'tech_mean_reversion_z',\n",
    "    'tech_volatility_regime',\n",
    "    # Cross-asset submodel (3)\n",
    "    'xasset_regime_prob',\n",
    "    'xasset_recession_signal',\n",
    "    'xasset_divergence',\n",
    "    # Yield curve submodel (2)\n",
    "    'yc_spread_velocity_z',\n",
    "    'yc_curvature_z',\n",
    "    # ETF flow submodel (3)\n",
    "    'etf_regime_prob',\n",
    "    'etf_capital_intensity',\n",
    "    'etf_pv_divergence',\n",
    "    # Inflation expectation submodel (3)\n",
    "    'ie_regime_prob',\n",
    "    'ie_anchoring_z',\n",
    "    'ie_gold_sensitivity_z',\n",
    "    # Options market submodel (1)\n",
    "    'options_risk_regime_prob',\n",
    "    # Temporal context submodel (1)\n",
    "    'temporal_context_score',\n",
    "    # Real rate submodel attempt 7 (4)\n",
    "    'rr_level_change_z',\n",
    "    'rr_slope_chg_z',\n",
    "    'rr_curvature_chg_z',\n",
    "    'rr_slope_level_z',\n",
    "]\n",
    "\n",
    "TARGET = 'gold_return_next'\n",
    "\n",
    "assert len(FEATURE_COLUMNS) == 28, f\"Expected 28 features, got {len(FEATURE_COLUMNS)}\"\n",
    "print(f\"Features defined: {len(FEATURE_COLUMNS)} features\")"
   ],
   "id": "cell-3"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Data from Kaggle Dataset (no API key needed)"
   ],
   "id": "cell-4"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"LOADING DATA FROM KAGGLE DATASET (no API key needed)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Dataset path resolution (inline - needed before main cell-5 resolution)\n",
    "_PROBE_FILE_BF = 'base_features_raw.csv'\n",
    "_glob_patterns_bf = [\n",
    "    f'/kaggle/input/datasets/bigbigzabuton/gold-prediction-submodels/{_PROBE_FILE_BF}',\n",
    "    f'/kaggle/input/gold-prediction-submodels/{_PROBE_FILE_BF}',\n",
    "    f'/kaggle/input/datasets/*/gold-prediction-submodels/{_PROBE_FILE_BF}',\n",
    "    f'/kaggle/input/*/{_PROBE_FILE_BF}',\n",
    "]\n",
    "\n",
    "DATASET_BASE_EARLY = None\n",
    "for _pattern in _glob_patterns_bf:\n",
    "    _matches = glob.glob(_pattern)\n",
    "    if _matches:\n",
    "        _candidate_base = os.path.dirname(_matches[0])\n",
    "        try:\n",
    "            pd.read_csv(_matches[0], nrows=1)\n",
    "            DATASET_BASE_EARLY = _candidate_base\n",
    "            print(f\"Dataset found at: {DATASET_BASE_EARLY} (pattern: {_pattern})\")\n",
    "            break\n",
    "        except Exception as _e:\n",
    "            print(f\"  Found at {_matches[0]} but read failed: {_e}\")\n",
    "\n",
    "if DATASET_BASE_EARLY is None:\n",
    "    print(\"ERROR: base_features_raw.csv not found! Searched:\")\n",
    "    for _p in _glob_patterns_bf:\n",
    "        print(f\"  {_p} -> {glob.glob(_p)}\")\n",
    "    try:\n",
    "        import subprocess as _sp\n",
    "        _r = _sp.run(['find', '/kaggle/input', '-name', _PROBE_FILE_BF, '-type', 'f'],\n",
    "                     capture_output=True, text=True, timeout=15)\n",
    "        print(f\"  find result: {_r.stdout.strip() or '(nothing found)'}\")\n",
    "    except Exception as _e:\n",
    "        print(f\"  find failed: {_e}\")\n",
    "    raise FileNotFoundError(\n",
    "        \"base_features_raw.csv not found in gold-prediction-submodels dataset. \"\n",
    "        \"Ensure dataset was updated with base_features_raw.csv.\"\n",
    "    )\n",
    "\n",
    "# Load base features (gold price, FRED series) from pre-fetched dataset\n",
    "print(\"\\nLoading base_features_raw.csv from dataset...\")\n",
    "bf = pd.read_csv(f'{DATASET_BASE_EARLY}/base_features_raw.csv')\n",
    "bf['Date'] = pd.to_datetime(bf['Date']).dt.strftime('%Y-%m-%d')\n",
    "bf = bf.set_index('Date')\n",
    "print(f\"  Loaded: {len(bf)} rows, {bf.index.min()} to {bf.index.max()}\")\n",
    "print(f\"  Columns: {list(bf.columns)}\")\n",
    "\n",
    "# Build base_features with same structure as original pipeline\n",
    "base_features = bf[['gold_return_next', 'real_rate_real_rate', 'dxy_dxy', 'vix_vix',\n",
    "                     'yield_curve_yield_spread',\n",
    "                     'inflation_expectation_inflation_expectation']].copy()\n",
    "base_features = base_features.ffill()\n",
    "base_features = base_features.dropna(subset=['gold_return_next'])\n",
    "print(f\"  Base features: {len(base_features)} rows, {len(base_features.columns)} columns\")\n",
    "print(\"\\nData loading complete\")"
   ],
   "id": "cell-5"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Transformation and Submodel Loading"
   ],
   "id": "cell-6"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# DATASET PATH RESOLUTION (robust: use glob + pd.read_csv probe)\n",
    "# API-created kernels: /kaggle/input/datasets/{owner}/{slug}/\n",
    "# Web-UI-created kernels: /kaggle/input/{slug}/\n",
    "# Use glob to find the file, then probe with pd.read_csv to verify\n",
    "# ============================================================\n",
    "import pandas as _pd_probe\n",
    "DATASET_SLUG = 'gold-prediction-submodels'\n",
    "DATASET_OWNER = 'bigbigzabuton'\n",
    "_PROBE_FILE = 'vix.csv'\n",
    "\n",
    "# Use glob to search all plausible locations with absolute paths\n",
    "_glob_patterns = [\n",
    "    f'/kaggle/input/datasets/{DATASET_OWNER}/{DATASET_SLUG}/{_PROBE_FILE}',\n",
    "    f'/kaggle/input/{DATASET_SLUG}/{_PROBE_FILE}',\n",
    "    f'/kaggle/input/datasets/*/{DATASET_SLUG}/{_PROBE_FILE}',\n",
    "    f'/kaggle/input/*/{_PROBE_FILE}',\n",
    "]\n",
    "\n",
    "DATASET_BASE = None\n",
    "for _pattern in _glob_patterns:\n",
    "    _matches = glob.glob(_pattern)\n",
    "    if _matches:\n",
    "        _candidate_base = os.path.dirname(_matches[0])\n",
    "        # Verify by actually reading the file with pandas\n",
    "        try:\n",
    "            _pd_probe.read_csv(_matches[0], nrows=1)\n",
    "            DATASET_BASE = _candidate_base\n",
    "            print(f\"Dataset found at: {DATASET_BASE} (pattern: {_pattern})\")\n",
    "            break\n",
    "        except Exception as _e:\n",
    "            print(f\"  Found at {_matches[0]} but read failed: {_e}\")\n",
    "\n",
    "if DATASET_BASE is None:\n",
    "    print(\"ERROR: Dataset not found via glob! Searched patterns:\")\n",
    "    for _p in _glob_patterns:\n",
    "        print(f\"  {_p} -> {glob.glob(_p)}\")\n",
    "    print(\"\\nFull /kaggle/input/ listing:\")\n",
    "    try:\n",
    "        import subprocess as _sp\n",
    "        _r = _sp.run(['find', '/kaggle/input', '-name', _PROBE_FILE, '-type', 'f'],\n",
    "                     capture_output=True, text=True, timeout=15)\n",
    "        print(f\"  find result: {_r.stdout.strip() or '(nothing found)'}\")\n",
    "        print(f\"  find stderr: {_r.stderr.strip()}\")\n",
    "    except Exception as _e:\n",
    "        print(f\"  find failed: {_e}\")\n",
    "    raise FileNotFoundError(\n",
    "        f\"Dataset '{DATASET_SLUG}' not found. \"\n",
    "        f\"Tried patterns: {_glob_patterns}. \"\n",
    "        \"Ensure dataset_sources includes 'bigbigzabuton/gold-prediction-submodels' in kernel-metadata.json.\"\n",
    "    )",
    "\n\n",
    "print(\"\\nApplying transformations...\")\n",
    "\n",
    "final_df = base_features.copy()\n",
    "\n",
    "final_df['real_rate_change'] = final_df['real_rate_real_rate'].diff()\n",
    "final_df['dxy_change'] = final_df['dxy_dxy'].diff()\n",
    "final_df['vix'] = final_df['vix_vix']\n",
    "final_df['yield_spread_change'] = final_df['yield_curve_yield_spread'].diff()\n",
    "final_df['inflation_exp_change'] = final_df['inflation_expectation_inflation_expectation'].diff()\n",
    "\n",
    "final_df = final_df.drop(columns=['real_rate_real_rate', 'dxy_dxy', 'vix_vix',\n",
    "                                    'yield_curve_yield_spread', 'inflation_expectation_inflation_expectation'])\n",
    "\n",
    "print(f\"  Base transformations applied\")\n",
    "print(f\"  Columns so far: {list(final_df.columns)}\")",
    "\n\n",
    "print(\"\\nLoading submodel outputs from Kaggle Dataset...\")\n",
    "\n",
    "submodel_files = {\n",
    "    'vix': {\n",
    "        'path': f'{DATASET_BASE}/vix.csv',\n",
    "        'columns': ['vix_regime_probability', 'vix_mean_reversion_z', 'vix_persistence'],\n",
    "        'date_col': 'date',\n",
    "        'tz_aware': False,\n",
    "    },\n",
    "    'technical': {\n",
    "        'path': f'{DATASET_BASE}/technical.csv',\n",
    "        'columns': ['tech_trend_regime_prob', 'tech_mean_reversion_z', 'tech_volatility_regime'],\n",
    "        'date_col': 'date',\n",
    "        'tz_aware': True,\n",
    "    },\n",
    "    'cross_asset': {\n",
    "        'path': f'{DATASET_BASE}/cross_asset.csv',\n",
    "        'columns': ['xasset_regime_prob', 'xasset_recession_signal', 'xasset_divergence'],\n",
    "        'date_col': 'Date',\n",
    "        'tz_aware': False,\n",
    "    },\n",
    "    'yield_curve': {\n",
    "        'path': f'{DATASET_BASE}/yield_curve.csv',\n",
    "        'columns': ['yc_spread_velocity_z', 'yc_curvature_z'],\n",
    "        'date_col': 'index',\n",
    "        'tz_aware': False,\n",
    "    },\n",
    "    'etf_flow': {\n",
    "        'path': f'{DATASET_BASE}/etf_flow.csv',\n",
    "        'columns': ['etf_regime_prob', 'etf_capital_intensity', 'etf_pv_divergence'],\n",
    "        'date_col': 'Date',\n",
    "        'tz_aware': False,\n",
    "    },\n",
    "    'inflation_expectation': {\n",
    "        'path': f'{DATASET_BASE}/inflation_expectation.csv',\n",
    "        'columns': ['ie_regime_prob', 'ie_anchoring_z', 'ie_gold_sensitivity_z'],\n",
    "        'date_col': 'Unnamed: 0',\n",
    "        'tz_aware': False,\n",
    "    },\n",
    "    'options_market': {\n",
    "        'path': f'{DATASET_BASE}/options_market.csv',\n",
    "        'columns': ['options_risk_regime_prob'],\n",
    "        'date_col': 'Date',\n",
    "        'tz_aware': True,\n",
    "    },\n",
    "    'temporal_context': {\n",
    "        'path': f'{DATASET_BASE}/temporal_context.csv',\n",
    "        'columns': ['temporal_context_score'],\n",
    "        'date_col': 'date',\n",
    "        'tz_aware': False,\n",
    "    },\n",
    "    'real_rate': {\n",
    "        'path': f'{DATASET_BASE}/real_rate.csv',\n",
    "        'columns': ['rr_level_change_z', 'rr_slope_chg_z', 'rr_curvature_chg_z', 'rr_slope_level_z'],\n",
    "        'date_col': 'date',\n",
    "        'tz_aware': False,\n",
    "    },\n",
    "}\n",
    "\n",
    "submodel_dfs = {}\n",
    "for feature, spec in submodel_files.items():\n",
    "    df = pd.read_csv(spec['path'])\n",
    "    date_col = spec['date_col']\n",
    "    if spec['tz_aware']:\n",
    "        df['Date'] = pd.to_datetime(df[date_col], utc=True).dt.strftime('%Y-%m-%d')\n",
    "    else:\n",
    "        if date_col == 'index':\n",
    "            df['Date'] = pd.to_datetime(df.iloc[:, 0]).dt.strftime('%Y-%m-%d')\n",
    "        elif date_col == 'Unnamed: 0':\n",
    "            df['Date'] = pd.to_datetime(df['Unnamed: 0']).dt.strftime('%Y-%m-%d')\n",
    "        else:\n",
    "            df['Date'] = pd.to_datetime(df[date_col]).dt.strftime('%Y-%m-%d')\n",
    "    df = df[['Date'] + spec['columns']]\n",
    "    df = df.set_index('Date')\n",
    "    submodel_dfs[feature] = df\n",
    "    print(f\"  {feature}: {len(df)} rows\")\n",
    "\n",
    "print(\"\\nMerging submodel outputs...\")\n",
    "for feature, df in submodel_dfs.items():\n",
    "    final_df = final_df.join(df, how='left')\n",
    "print(f\"  Features after merge: {final_df.shape[1]} columns, {len(final_df)} rows\")\n",
    "\n",
    "print(\"\\nApplying NaN imputation...\")\n",
    "nan_before = final_df.isna().sum().sum()\n",
    "print(f\"  NaN before imputation: {nan_before}\")\n",
    "\n",
    "regime_cols = ['vix_regime_probability', 'tech_trend_regime_prob',\n",
    "               'xasset_regime_prob', 'etf_regime_prob', 'ie_regime_prob',\n",
    "               'options_risk_regime_prob', 'temporal_context_score']\n",
    "for col in regime_cols:\n",
    "    if col in final_df.columns:\n",
    "        final_df[col] = final_df[col].fillna(0.5)\n",
    "\n",
    "z_cols = ['vix_mean_reversion_z', 'tech_mean_reversion_z',\n",
    "          'yc_spread_velocity_z', 'yc_curvature_z',\n",
    "          'etf_capital_intensity', 'etf_pv_divergence',\n",
    "          'ie_anchoring_z', 'ie_gold_sensitivity_z']\n",
    "for col in z_cols:\n",
    "    if col in final_df.columns:\n",
    "        final_df[col] = final_df[col].fillna(0.0)\n",
    "\n",
    "div_cols = ['xasset_recession_signal', 'xasset_divergence']\n",
    "for col in div_cols:\n",
    "    if col in final_df.columns:\n",
    "        final_df[col] = final_df[col].fillna(0.0)\n",
    "\n",
    "cont_cols = ['tech_volatility_regime', 'vix_persistence']\n",
    "for col in cont_cols:\n",
    "    if col in final_df.columns:\n",
    "        final_df[col] = final_df[col].fillna(final_df[col].median())\n",
    "\n",
    "# Real rate submodel z-scores: fill with 0.0 (neutral / no signal)\n",
    "rr_z_cols = ['rr_level_change_z', 'rr_slope_chg_z', 'rr_curvature_chg_z', 'rr_slope_level_z']\n",
    "for col in rr_z_cols:\n",
    "    if col in final_df.columns:\n",
    "        final_df[col] = final_df[col].fillna(0.0)\n",
    "\n",
    "final_df = final_df.dropna(subset=['gold_return_next', 'real_rate_change', 'dxy_change',\n",
    "                                     'vix', 'yield_spread_change', 'inflation_exp_change'])\n",
    "\n",
    "nan_after = final_df.isna().sum().sum()\n",
    "print(f\"  NaN after imputation: {nan_after}\")\n",
    "print(f\"  Final dataset: {len(final_df)} rows\")\n",
    "\n",
    "assert all(col in final_df.columns for col in FEATURE_COLUMNS), \"Missing features after merge!\"\n",
    "assert TARGET in final_df.columns, \"Target not found!\"\n",
    "print(f\"\\nAll {len(FEATURE_COLUMNS)} features present\")\n",
    "print(f\"Dataset shape: {final_df.shape}\")\n",
    "print(f\"Date range: {final_df.index.min()} to {final_df.index.max()}\")"
   ],
   "id": "cell-7"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train/Val/Test Split (70/15/15)"
   ],
   "id": "cell-8"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Train/Val/Test Split (70/15/15, time-series order) ===\n",
    "n_total = len(final_df)\n",
    "n_train = int(n_total * 0.70)\n",
    "n_val = int(n_total * 0.15)\n",
    "\n",
    "train_df = final_df.iloc[:n_train].copy()\n",
    "val_df = final_df.iloc[n_train:n_train+n_val].copy()\n",
    "test_df = final_df.iloc[n_train+n_val:].copy()\n",
    "\n",
    "print(f\"\\nData split complete:\")\n",
    "print(f\"  Train: {len(train_df)} rows ({len(train_df)/n_total*100:.1f}%) - {train_df.index.min()} to {train_df.index.max()}\")\n",
    "print(f\"  Val:   {len(val_df)} rows ({len(val_df)/n_total*100:.1f}%) - {val_df.index.min()} to {val_df.index.max()}\")\n",
    "print(f\"  Test:  {len(test_df)} rows ({len(test_df)/n_total*100:.1f}%) - {test_df.index.min()} to {test_df.index.max()}\")\n",
    "print(f\"  Total: {n_total} rows\")\n",
    "print(f\"  Samples per feature: {n_train / len(FEATURE_COLUMNS):.1f}:1 (train)\")\n",
    "\n",
    "# Verify no data leakage\n",
    "assert train_df.index.max() < val_df.index.min(), \"Train-val overlap detected!\"\n",
    "assert val_df.index.max() < test_df.index.min(), \"Val-test overlap detected!\"\n",
    "print(f\"\\nNo time-series leakage detected\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Prepare arrays for training\n",
    "X_train = train_df[FEATURE_COLUMNS].values\n",
    "y_train = train_df[TARGET].values\n",
    "\n",
    "X_val = val_df[FEATURE_COLUMNS].values\n",
    "y_val = val_df[TARGET].values\n",
    "\n",
    "X_test = test_df[FEATURE_COLUMNS].values\n",
    "y_test = test_df[TARGET].values\n",
    "\n",
    "# Store dates for output\n",
    "dates_train = train_df.index\n",
    "dates_val = val_df.index\n",
    "dates_test = test_df.index\n",
    "\n",
    "print(f\"\\nArray shapes:\")\n",
    "print(f\"  X_train: {X_train.shape}, y_train: {y_train.shape}\")\n",
    "print(f\"  X_val:   {X_val.shape}, y_val:   {y_val.shape}\")\n",
    "print(f\"  X_test:  {X_test.shape}, y_test:  {y_test.shape}\")"
   ],
   "id": "cell-9"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metric Functions"
   ],
   "id": "cell-10"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_direction_accuracy(y_true, y_pred):\n",
    "    \"\"\"Direction accuracy, excluding zeros.\"\"\"\n",
    "    mask = (y_true != 0) & (y_pred != 0)\n",
    "    if mask.sum() == 0:\n",
    "        return 0.0\n",
    "    return (np.sign(y_pred[mask]) == np.sign(y_true[mask])).mean()\n",
    "\n",
    "def compute_mae(y_true, y_pred):\n",
    "    \"\"\"Mean Absolute Error.\"\"\"\n",
    "    return np.abs(y_pred - y_true).mean()\n",
    "\n",
    "def compute_sharpe_trade_cost(y_true, y_pred, cost_bps=5.0):\n",
    "    \"\"\"Sharpe ratio with position-change cost (5bps per change).\"\"\"\n",
    "    positions = np.sign(y_pred)\n",
    "\n",
    "    # Strategy returns (position * actual return)\n",
    "    strategy_returns = positions * y_true / 100.0  # Convert % to decimal\n",
    "\n",
    "    # Position changes\n",
    "    position_changes = np.abs(np.diff(positions, prepend=0))\n",
    "    trade_costs = position_changes * (cost_bps / 10000.0)  # 5bps = 0.0005\n",
    "\n",
    "    # Net returns\n",
    "    net_returns = strategy_returns - trade_costs\n",
    "\n",
    "    # Annualized Sharpe (252 trading days)\n",
    "    if len(net_returns) < 2 or net_returns.std() == 0:\n",
    "        return 0.0\n",
    "    return (net_returns.mean() / net_returns.std()) * np.sqrt(252)\n",
    "\n",
    "def compute_hcda(y_true, y_pred, threshold_percentile=80):\n",
    "    \"\"\"High-confidence direction accuracy (top 20% by |prediction|).\"\"\"\n",
    "    threshold = np.percentile(np.abs(y_pred), threshold_percentile)\n",
    "    hc_mask = np.abs(y_pred) > threshold\n",
    "\n",
    "    if hc_mask.sum() == 0:\n",
    "        return 0.0, 0.0\n",
    "\n",
    "    coverage = hc_mask.sum() / len(y_pred)\n",
    "    hc_pred = y_pred[hc_mask]\n",
    "    hc_actual = y_true[hc_mask]\n",
    "\n",
    "    mask = (hc_actual != 0) & (hc_pred != 0)\n",
    "    if mask.sum() == 0:\n",
    "        return 0.0, coverage\n",
    "\n",
    "    da = (np.sign(hc_pred[mask]) == np.sign(hc_actual[mask])).mean()\n",
    "    return da, coverage\n",
    "\n",
    "def compute_hcda_bootstrap(y_true, y_pred, bootstrap_std, threshold_percentile=80):\n",
    "    \"\"\"\n",
    "    HCDA using bootstrap variance-based confidence.\n",
    "    High confidence = LOW variance (certain predictions)\n",
    "    Top 20% by inverse variance: 1 / (1 + std)\n",
    "    \"\"\"\n",
    "    confidence = 1.0 / (1.0 + bootstrap_std)  # Higher confidence when std is low\n",
    "    threshold = np.percentile(confidence, threshold_percentile)\n",
    "    hc_mask = confidence > threshold\n",
    "\n",
    "    if hc_mask.sum() == 0:\n",
    "        return 0.0, 0.0\n",
    "\n",
    "    coverage = hc_mask.sum() / len(y_pred)\n",
    "    hc_pred = y_pred[hc_mask]\n",
    "    hc_actual = y_true[hc_mask]\n",
    "\n",
    "    mask = (hc_actual != 0) & (hc_pred != 0)\n",
    "    if mask.sum() == 0:\n",
    "        return 0.0, coverage\n",
    "\n",
    "    da = (np.sign(hc_pred[mask]) == np.sign(hc_actual[mask])).mean()\n",
    "    return da, coverage\n",
    "\n",
    "print(\"Metric functions defined\")"
   ],
   "id": "cell-11"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STEP 1: Optuna HPO (100 trials) - Tuned for 28-Feature Space"
   ],
   "id": "cell-12"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "optuna.logging.set_verbosity(optuna.logging.WARNING)\n\nprint(\"=\"*60)\nprint(\"OPTUNA HPO (100 trials) - Finding best params for 28 features\")\nprint(\"=\"*60)\n\ndef objective(trial):\n    params = {\n        \"objective\": \"reg:squarederror\",\n        \"max_depth\": trial.suggest_int(\"max_depth\", 2, 4),\n        \"min_child_weight\": trial.suggest_int(\"min_child_weight\", 10, 50),\n        \"subsample\": trial.suggest_float(\"subsample\", 0.60, 0.95),\n        \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.35, 0.70),\n        \"reg_lambda\": trial.suggest_float(\"reg_lambda\", 0.3, 8.0),\n        \"reg_alpha\": trial.suggest_float(\"reg_alpha\", 0.0, 4.0),\n        \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.010, 0.050),\n        \"n_estimators\": 800,\n        \"early_stopping_rounds\": 50,\n        \"tree_method\": \"hist\",\n        \"device\": \"cuda\",\n        \"random_state\": 42,\n        \"verbosity\": 0,\n    }\n    model = xgb.XGBRegressor(**params)\n    model.fit(X_train, y_train, eval_set=[(X_val, y_val)], verbose=False)\n    pred_val = model.predict(X_val)\n\n    da = compute_direction_accuracy(y_val, pred_val)\n    sharpe = compute_sharpe_trade_cost(y_val, pred_val)\n    mae = compute_mae(y_val, pred_val)\n\n    # Composite: higher is better\n    # Sharpe normalized to [-1, 1]: 3.0 maps to 1.0, -3.0 maps to -1.0\n    sharpe_norm = min(max(sharpe / 3.0, -1.0), 1.0)\n    # MAE normalized: lower MAE = higher score; 0.5 maps to 1.0, 1.5 maps to -1.0\n    mae_norm = min(max((1.0 - mae) / 1.0, -1.0), 1.0)\n    score = da * 0.6 + sharpe_norm * 0.3 + mae_norm * 0.1\n\n    # Log additional metrics as user attributes\n    trial.set_user_attr('val_da', float(da))\n    trial.set_user_attr('val_sharpe', float(sharpe))\n    trial.set_user_attr('val_mae', float(mae))\n    trial.set_user_attr('best_iteration', int(model.best_iteration) if model.best_iteration is not None else 800)\n\n    return score\n\nstudy = optuna.create_study(\n    direction=\"maximize\",\n    sampler=TPESampler(seed=42)\n)\nstudy.optimize(objective, n_trials=100, show_progress_bar=False)\n\nbest_params = study.best_params.copy()\nbest_params.update({\n    \"objective\": \"reg:squarederror\",\n    \"n_estimators\": 800,\n    \"early_stopping_rounds\": 50,\n    \"tree_method\": \"hist\",\n    \"device\": \"cuda\",\n    \"random_state\": 42,\n    \"verbosity\": 0,\n})\n\nprint(f\"\\nOptuna complete: {len(study.trials)} trials\")\nprint(f\"Best score: {study.best_value:.4f}\")\nprint(f\"\\nBest params:\")\nfor k, v in study.best_params.items():\n    print(f\"  {k}: {v}\")\n\nbest_trial = study.best_trial\nprint(f\"\\nBest trial validation metrics:\")\nprint(f\"  DA:     {best_trial.user_attrs['val_da']*100:.2f}%\")\nprint(f\"  Sharpe: {best_trial.user_attrs['val_sharpe']:.4f}\")\nprint(f\"  MAE:    {best_trial.user_attrs['val_mae']:.4f}%\")\nprint(f\"  Best iteration: {best_trial.user_attrs['best_iteration']}\")\n\n# Compare with attempt 7 params\natt7_params = {\"max_depth\": 2, \"min_child_weight\": 25, \"subsample\": 0.765,\n               \"colsample_bytree\": 0.450, \"reg_lambda\": 2.049, \"reg_alpha\": 1.107,\n               \"learning_rate\": 0.0215}\nprint(f\"\\nOptuna best vs Attempt 7 params (optimized for 24 features):\")\nfor k in att7_params:\n    att7_v = att7_params[k]\n    new_v = study.best_params.get(k, \"N/A\")\n    print(f\"  {k}: {att7_v} -> {new_v}\")",
   "id": "cell-13"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STEP 2: Bootstrap Data Subsampling Ensemble (12 models, best Optuna params)"
   ],
   "id": "cell-14"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "print(\"=\"*60)\nprint(\"BOOTSTRAP DATA SUBSAMPLING ENSEMBLE (12 models, best Optuna params)\")\nprint(\"=\"*60)\n\nN_ENSEMBLE = 12\nBOOTSTRAP_FRAC = 0.80\n\nrng = np.random.RandomState(42)\nensemble_models = []\n\nn_bootstrap = int(BOOTSTRAP_FRAC * len(X_train))\nprint(f\"\\nEnsemble config:\")\nprint(f\"  Number of models: {N_ENSEMBLE}\")\nprint(f\"  Bootstrap fraction: {BOOTSTRAP_FRAC:.0%}\")\nprint(f\"  Bootstrap size: {n_bootstrap} samples (from {len(X_train)} total)\")\nprint(f\"  XGBoost params: Optuna best (n_estimators=800, early stopping=50)\")\nprint()\n\nfor i in range(N_ENSEMBLE):\n    seed = 42 + i\n    bootstrap_idx = rng.choice(len(X_train), size=n_bootstrap, replace=True)\n    X_boot = X_train[bootstrap_idx]\n    y_boot = y_train[bootstrap_idx]\n\n    model_params = best_params.copy()\n    model_params['random_state'] = seed\n\n    model = xgb.XGBRegressor(**model_params)\n    model.fit(X_boot, y_boot, eval_set=[(X_val, y_val)], verbose=False)\n    ensemble_models.append(model)\n    best_iter = model.best_iteration if model.best_iteration is not None else 800\n    print(f\"  Model {i+1:2d}/{N_ENSEMBLE}: seed={seed}, best_iteration={best_iter}\")\n\nprint(f\"\\nEnsemble training complete: {len(ensemble_models)} models\")",
   "id": "cell-15"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STEP 3: Ensemble Predictions and Bootstrap Variance"
   ],
   "id": "cell-16"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"GENERATING ENSEMBLE PREDICTIONS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# === Generate predictions from all ensemble models ===\n",
    "print(\"\\nGenerating predictions from ensemble...\")\n",
    "ensemble_preds_train = np.array([m.predict(X_train) for m in ensemble_models])\n",
    "ensemble_preds_val = np.array([m.predict(X_val) for m in ensemble_models])\n",
    "ensemble_preds_test = np.array([m.predict(X_test) for m in ensemble_models])\n",
    "\n",
    "# Mean prediction (primary prediction)\n",
    "pred_train = ensemble_preds_train.mean(axis=0)\n",
    "pred_val = ensemble_preds_val.mean(axis=0)\n",
    "pred_test = ensemble_preds_test.mean(axis=0)\n",
    "\n",
    "# Bootstrap variance (confidence)\n",
    "bootstrap_std_train = np.std(ensemble_preds_train, axis=0)\n",
    "bootstrap_std_val = np.std(ensemble_preds_val, axis=0)\n",
    "bootstrap_std_test = np.std(ensemble_preds_test, axis=0)\n",
    "\n",
    "# Bootstrap confidence = 1 / (1 + std)\n",
    "bootstrap_conf_train = 1.0 / (1.0 + bootstrap_std_train)\n",
    "bootstrap_conf_val = 1.0 / (1.0 + bootstrap_std_val)\n",
    "bootstrap_conf_test = 1.0 / (1.0 + bootstrap_std_test)\n",
    "\n",
    "# Combine all for full dataset\n",
    "pred_full = np.concatenate([pred_train, pred_val, pred_test])\n",
    "dates_full = pd.Index(list(dates_train) + list(dates_val) + list(dates_test))\n",
    "y_full = np.concatenate([y_train, y_val, y_test])\n",
    "\n",
    "print(f\"\\nEnsemble predictions generated:\")\n",
    "print(f\"  Train: mean={pred_train.mean():.4f}, std={pred_train.std():.4f}\")\n",
    "print(f\"  Val:   mean={pred_val.mean():.4f}, std={pred_val.std():.4f}\")\n",
    "print(f\"  Test:  mean={pred_test.mean():.4f}, std={pred_test.std():.4f}\")\n",
    "\n",
    "print(f\"\\nBootstrap variance statistics (test set):\")\n",
    "print(f\"  Std range: [{bootstrap_std_test.min():.4f}, {bootstrap_std_test.max():.4f}]\")\n",
    "print(f\"  Std mean:  {bootstrap_std_test.mean():.4f}\")\n",
    "print(f\"  Confidence range: [{bootstrap_conf_test.min():.4f}, {bootstrap_conf_test.max():.4f}]\")\n",
    "print(f\"  Confidence mean:  {bootstrap_conf_test.mean():.4f}\")\n",
    "\n",
    "# Compute HCDA with BOTH methods\n",
    "hcda_bootstrap_test, hcda_bootstrap_cov = compute_hcda_bootstrap(y_test, pred_test, bootstrap_std_test)\n",
    "hcda_pred_test, hcda_pred_cov = compute_hcda(y_test, pred_test)\n",
    "\n",
    "print(f\"\\nHCDA comparison (test set):\")\n",
    "print(f\"  Bootstrap variance: {hcda_bootstrap_test*100:.2f}% (N={int(hcda_bootstrap_cov*len(y_test))})\")\n",
    "print(f\"  |prediction|:       {hcda_pred_test*100:.2f}% (N={int(hcda_pred_cov*len(y_test))})\")\n",
    "print(f\"  Improvement:        {(hcda_bootstrap_test - hcda_pred_test)*100:+.2f}pp\")\n",
    "\n",
    "# Select better HCDA method\n",
    "use_bootstrap_hcda = hcda_bootstrap_test > hcda_pred_test\n",
    "if use_bootstrap_hcda:\n",
    "    print(f\"\\nUsing bootstrap variance for HCDA (better by {(hcda_bootstrap_test - hcda_pred_test)*100:.2f}pp)\")\n",
    "    primary_hcda_method = 'bootstrap'\n",
    "    primary_hcda_value = hcda_bootstrap_test\n",
    "else:\n",
    "    print(f\"\\nUsing |prediction| for HCDA (better by {(hcda_pred_test - hcda_bootstrap_test)*100:.2f}pp)\")\n",
    "    primary_hcda_method = 'pred'\n",
    "    primary_hcda_value = hcda_pred_test"
   ],
   "id": "cell-17"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## POST-TRAINING STEP 1: OLS Output Scaling"
   ],
   "id": "cell-18"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"OLS OUTPUT SCALING\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Compute optimal scaling factor from validation set\n",
    "numerator = np.sum(pred_val * y_val)\n",
    "denominator = np.sum(pred_val ** 2)\n",
    "alpha_ols = numerator / denominator if denominator != 0 else 1.0\n",
    "alpha_ols = np.clip(alpha_ols, 0.5, 10.0)  # Cap at [0.5, 10.0]\n",
    "\n",
    "print(f\"\\nOLS scaling factor: {alpha_ols:.2f}\")\n",
    "\n",
    "# Apply scaling to all predictions (for MAE computation only)\n",
    "scaled_pred_train = pred_train * alpha_ols\n",
    "scaled_pred_val = pred_val * alpha_ols\n",
    "scaled_pred_test = pred_test * alpha_ols\n",
    "scaled_pred_full = pred_full * alpha_ols\n",
    "\n",
    "# MAE comparison\n",
    "mae_raw = np.mean(np.abs(pred_test - y_test))\n",
    "mae_scaled = np.mean(np.abs(scaled_pred_test - y_test))\n",
    "print(f\"\\nMAE (raw):    {mae_raw:.4f}%\")\n",
    "print(f\"MAE (scaled): {mae_scaled:.4f}%\")\n",
    "print(f\"MAE delta:    {mae_scaled - mae_raw:+.4f}%\")\n",
    "\n",
    "# Verify: DA and Sharpe unchanged by scaling\n",
    "da_raw = compute_direction_accuracy(y_test, pred_test)\n",
    "da_scaled = compute_direction_accuracy(y_test, scaled_pred_test)\n",
    "assert abs(da_raw - da_scaled) < 1e-10, \"Scaling changed DA!\"\n",
    "print(\"\\nDA and Sharpe: unchanged by scaling (verified)\")\n",
    "\n",
    "# Select better MAE for reporting\n",
    "use_scaled = mae_scaled < mae_raw\n",
    "if use_scaled:\n",
    "    print(f\"\\nUsing SCALED predictions for MAE (improvement: {mae_raw - mae_scaled:.4f}%)\")\n",
    "else:\n",
    "    print(f\"\\nUsing RAW predictions for MAE (scaling degraded by {mae_scaled - mae_raw:.4f}%)\")"
   ],
   "id": "cell-19"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation on All Splits"
   ],
   "id": "cell-20"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"FINAL EVALUATION\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Compute metrics for all splits\n",
    "metrics_all = {}\n",
    "for split_name, y_true, y_pred_raw, y_pred_scaled in [\n",
    "    ('train', y_train, pred_train, scaled_pred_train),\n",
    "    ('val', y_val, pred_val, scaled_pred_val),\n",
    "    ('test', y_test, pred_test, scaled_pred_test),\n",
    "]:\n",
    "    da = compute_direction_accuracy(y_true, y_pred_raw)\n",
    "    mae_raw_split = compute_mae(y_true, y_pred_raw)\n",
    "    mae_scaled_split = compute_mae(y_true, y_pred_scaled)\n",
    "    mae = min(mae_raw_split, mae_scaled_split)\n",
    "    sharpe = compute_sharpe_trade_cost(y_true, y_pred_raw)\n",
    "    hc_da, hc_coverage = compute_hcda(y_true, y_pred_raw, threshold_percentile=80)\n",
    "\n",
    "    metrics_all[split_name] = {\n",
    "        'direction_accuracy': float(da),\n",
    "        'high_confidence_da': float(hc_da),\n",
    "        'high_confidence_coverage': float(hc_coverage),\n",
    "        'mae': float(mae),\n",
    "        'mae_raw': float(mae_raw_split),\n",
    "        'mae_scaled': float(mae_scaled_split),\n",
    "        'sharpe_ratio': float(sharpe),\n",
    "    }\n",
    "\n",
    "# Print metrics\n",
    "for split_name in ['train', 'val', 'test']:\n",
    "    m = metrics_all[split_name]\n",
    "    print(f\"\\n{split_name.upper()}:\")\n",
    "    print(f\"  DA:     {m['direction_accuracy']*100:.2f}%\")\n",
    "    print(f\"  HCDA:   {m['high_confidence_da']*100:.2f}% (coverage: {m['high_confidence_coverage']*100:.1f}%)\")\n",
    "    print(f\"  MAE:    {m['mae']:.4f}% (raw: {m['mae_raw']:.4f}%, scaled: {m['mae_scaled']:.4f}%)\")\n",
    "    print(f\"  Sharpe: {m['sharpe_ratio']:.2f}\")\n",
    "\n",
    "# Overfitting analysis\n",
    "train_test_da_gap = (metrics_all['train']['direction_accuracy'] - metrics_all['test']['direction_accuracy']) * 100\n",
    "print(f\"\\nOVERFITTING:\")\n",
    "print(f\"  Train-Test DA gap: {train_test_da_gap:.2f}pp (target: <10pp)\")\n",
    "\n",
    "# Target evaluation\n",
    "test_m = metrics_all['test']\n",
    "targets_met = [\n",
    "    test_m['direction_accuracy'] > 0.56,\n",
    "    primary_hcda_value > 0.60,\n",
    "    test_m['mae'] < 0.0075,\n",
    "    test_m['sharpe_ratio'] > 0.8,\n",
    "]\n",
    "\n",
    "print(f\"\\nTARGET STATUS:\")\n",
    "print(f\"  DA > 56%:     {'PASS' if targets_met[0] else 'FAIL'} ({test_m['direction_accuracy']*100:.2f}%)\")\n",
    "print(f\"  HCDA > 60%:   {'PASS' if targets_met[1] else 'FAIL'} ({primary_hcda_value*100:.2f}% via {primary_hcda_method})\")\n",
    "print(f\"  MAE < 0.75%:  {'PASS' if targets_met[2] else 'FAIL'} ({test_m['mae']:.4f}%)\")\n",
    "print(f\"  Sharpe > 0.8: {'PASS' if targets_met[3] else 'FAIL'} ({test_m['sharpe_ratio']:.2f})\")\n",
    "print(f\"\\nTargets passed: {sum(targets_met)}/4\")\n",
    "\n",
    "# Comparison with references\n",
    "print(f\"\\nVs Attempt 7 (best overall):\")\n",
    "print(f\"  DA:     {test_m['direction_accuracy']*100:.2f}% (Attempt 7: 60.04%, delta: {(test_m['direction_accuracy']-0.6004)*100:+.2f}pp)\")\n",
    "print(f\"  HCDA:   {primary_hcda_value*100:.2f}% (Attempt 7: 64.13%, delta: {(primary_hcda_value-0.6413)*100:+.2f}pp)\")\n",
    "print(f\"  MAE:    {test_m['mae']:.4f}% (Attempt 7: 0.9429%, delta: {(test_m['mae']-0.9429)*100:+.4f}pp)\")\n",
    "print(f\"  Sharpe: {test_m['sharpe_ratio']:.2f} (Attempt 7: 2.4636, delta: {test_m['sharpe_ratio']-2.4636:+.2f})\")\n",
    "\n",
    "print(f\"\\nVs Attempt 18 (predecessor with fixed params):\")\n",
    "print(f\"  DA:     {test_m['direction_accuracy']*100:.2f}% (Attempt 18: 58.30%, delta: {(test_m['direction_accuracy']-0.5830)*100:+.2f}pp)\")\n",
    "print(f\"  HCDA:   {primary_hcda_value*100:.2f}% (Attempt 18: 63.04%, delta: {(primary_hcda_value-0.6304)*100:+.2f}pp)\")\n",
    "print(f\"  MAE:    {test_m['mae']:.4f}% (Attempt 18: 0.9527%, delta: {(test_m['mae']-0.9527)*100:+.4f}pp)\")\n",
    "print(f\"  Sharpe: {test_m['sharpe_ratio']:.2f} (Attempt 18: 1.8624, delta: {test_m['sharpe_ratio']-1.8624:+.2f})\")"
   ],
   "id": "cell-21"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Importance Analysis"
   ],
   "id": "cell-22"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"FEATURE IMPORTANCE ANALYSIS (ensemble average)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Average feature importance across ensemble models\n",
    "all_importances = np.array([m.feature_importances_ for m in ensemble_models])\n",
    "mean_importances = all_importances.mean(axis=0)\n",
    "std_importances = all_importances.std(axis=0)\n",
    "\n",
    "feature_ranking = pd.DataFrame({\n",
    "    'feature': FEATURE_COLUMNS,\n",
    "    'importance_mean': mean_importances,\n",
    "    'importance_std': std_importances,\n",
    "    'importance_pct': mean_importances / mean_importances.sum() * 100\n",
    "}).sort_values('importance_mean', ascending=False).reset_index(drop=True)\n",
    "\n",
    "print(f\"\\nTop 15 features (by mean importance across {N_ENSEMBLE} ensemble models):\")\n",
    "for i, row in feature_ranking.head(15).iterrows():\n",
    "    print(f\"  {i+1:2d}. {row['feature']:35s}: {row['importance_pct']:.2f}%\")\n",
    "\n",
    "# Real rate submodel feature analysis\n",
    "rr_features = ['rr_level_change_z', 'rr_slope_chg_z', 'rr_curvature_chg_z', 'rr_slope_level_z']\n",
    "rr_importance_total = feature_ranking[feature_ranking['feature'].isin(rr_features)]['importance_pct'].sum()\n",
    "print(f\"\\nReal rate submodel (4 features) total importance: {rr_importance_total:.2f}%\")\n",
    "for feat in rr_features:\n",
    "    row = feature_ranking[feature_ranking['feature'] == feat]\n",
    "    rank = row.index[0] + 1\n",
    "    imp = row['importance_pct'].values[0]\n",
    "    print(f\"  {feat}: rank {rank}/28, {imp:.2f}%\")\n",
    "\n",
    "print(f\"\\nNaive baseline (always-up):\")\n",
    "naive_always_up_da = (y_test > 0).sum() / len(y_test)\n",
    "print(f\"  Always-up DA: {naive_always_up_da*100:.2f}%\")\n",
    "print(f\"  Model vs naive: {(test_m['direction_accuracy'] - naive_always_up_da)*100:+.2f}pp\")"
   ],
   "id": "cell-23"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Results"
   ],
   "id": "cell-24"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"SAVING RESULTS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# 1. predictions.csv (full dataset)\n",
    "split_labels = ['train'] * len(dates_train) + ['val'] * len(dates_val) + ['test'] * len(dates_test)\n",
    "predictions_df = pd.DataFrame({\n",
    "    'date': dates_full,\n",
    "    'split': split_labels,\n",
    "    'actual': y_full,\n",
    "    'prediction_raw': pred_full,\n",
    "    'prediction_scaled': scaled_pred_full,\n",
    "    'direction_correct': (np.sign(pred_full) == np.sign(y_full)).astype(int),\n",
    "    'abs_prediction': np.abs(pred_full),\n",
    "})\n",
    "\n",
    "# Add high_confidence flags\n",
    "threshold_80_pred = np.percentile(np.abs(pred_full), 80)\n",
    "predictions_df['high_confidence_pred'] = (predictions_df['abs_prediction'] > threshold_80_pred).astype(int)\n",
    "\n",
    "# Bootstrap confidence for full dataset\n",
    "bootstrap_conf_full = np.concatenate([bootstrap_conf_train, bootstrap_conf_val, bootstrap_conf_test])\n",
    "threshold_80_bootstrap = np.percentile(bootstrap_conf_full, 80)\n",
    "predictions_df['bootstrap_confidence'] = bootstrap_conf_full\n",
    "predictions_df['high_confidence_bootstrap'] = (predictions_df['bootstrap_confidence'] > threshold_80_bootstrap).astype(int)\n",
    "\n",
    "# Bootstrap std for full dataset\n",
    "bootstrap_std_full = np.concatenate([bootstrap_std_train, bootstrap_std_val, bootstrap_std_test])\n",
    "predictions_df['bootstrap_std'] = bootstrap_std_full\n",
    "\n",
    "predictions_df.to_csv('predictions.csv', index=False)\n",
    "print(\"Saved predictions.csv\")\n",
    "\n",
    "# 2. test_predictions.csv\n",
    "test_predictions_df = predictions_df[predictions_df['split'] == 'test'].copy()\n",
    "test_predictions_df.to_csv('test_predictions.csv', index=False)\n",
    "print(\"Saved test_predictions.csv\")\n",
    "\n",
    "# 3. submodel_output.csv\n",
    "predictions_df.to_csv('submodel_output.csv', index=False)\n",
    "print(\"Saved submodel_output.csv\")\n",
    "\n",
    "# 4. model.json (first ensemble model)\n",
    "ensemble_models[0].save_model('model.json')\n",
    "print(\"Saved model.json (first ensemble model)\")\n",
    "\n",
    "# 5. training_result.json\n",
    "training_result = {\n",
    "    'feature': 'meta_model',\n",
    "    'attempt': 19,\n",
    "    'timestamp': datetime.now().isoformat(),\n",
    "    'architecture': 'XGBoost Optuna HPO (100 trials) + Bootstrap Data Subsampling Ensemble (12 models, 80%) + OLS scaling',\n",
    "    'phase': '3_meta_model',\n",
    "\n",
    "    'model_config': {\n",
    "        'n_features': 28,\n",
    "        'train_samples': len(X_train),\n",
    "        'val_samples': len(X_val),\n",
    "        'test_samples': len(X_test),\n",
    "        'samples_per_feature_ratio': len(X_train) / 28,\n",
    "        'n_ensemble_models': N_ENSEMBLE,\n",
    "        'bootstrap_fraction': BOOTSTRAP_FRAC,\n",
    "    },\n",
    "\n",
    "    'optuna_study': {\n",
    "        'n_trials': len(study.trials),\n",
    "        'best_score': float(study.best_value),\n",
    "        'best_params': study.best_params,\n",
    "        'best_trial_val_da': float(study.best_trial.user_attrs['val_da']),\n",
    "        'best_trial_val_sharpe': float(study.best_trial.user_attrs['val_sharpe']),\n",
    "        'best_trial_val_mae': float(study.best_trial.user_attrs['val_mae']),\n",
    "        'search_space': {\n",
    "            'max_depth': [2, 4],\n",
    "            'min_child_weight': [10, 50],\n",
    "            'subsample': [0.60, 0.95],\n",
    "            'colsample_bytree': [0.35, 0.70],\n",
    "            'reg_lambda': [0.3, 8.0],\n",
    "            'reg_alpha': [0.0, 4.0],\n",
    "            'learning_rate': [0.010, 0.050],\n",
    "            'n_estimators': 800,\n",
    "            'early_stopping_rounds': 50,\n",
    "        },\n",
    "        'objective_formula': 'DA * 0.6 + Sharpe_norm * 0.3 + MAE_norm * 0.1',\n",
    "        'top_5_trials': [\n",
    "            {\n",
    "                'number': t.number,\n",
    "                'score': float(t.value),\n",
    "                'params': t.params,\n",
    "                'val_da': float(t.user_attrs['val_da']),\n",
    "                'val_sharpe': float(t.user_attrs['val_sharpe']),\n",
    "            }\n",
    "            for t in sorted(study.trials, key=lambda x: x.value if x.value is not None else -999, reverse=True)[:5]\n",
    "        ],\n",
    "    },\n",
    "\n",
    "    'bootstrap_analysis': {\n",
    "        'n_ensemble_models': N_ENSEMBLE,\n",
    "        'bootstrap_fraction': BOOTSTRAP_FRAC,\n",
    "        'bootstrap_std_range_test': [float(bootstrap_std_test.min()), float(bootstrap_std_test.max())],\n",
    "        'bootstrap_std_mean_test': float(bootstrap_std_test.mean()),\n",
    "        'bootstrap_conf_range_test': [float(bootstrap_conf_test.min()), float(bootstrap_conf_test.max())],\n",
    "        'bootstrap_conf_mean_test': float(bootstrap_conf_test.mean()),\n",
    "        'hcda_bootstrap': float(hcda_bootstrap_test),\n",
    "        'hcda_pred': float(hcda_pred_test),\n",
    "        'hcda_improvement_pp': float((hcda_bootstrap_test - hcda_pred_test) * 100),\n",
    "    },\n",
    "\n",
    "    'ols_scaling': {\n",
    "        'alpha_ols': float(alpha_ols),\n",
    "        'mae_raw': float(mae_raw),\n",
    "        'mae_scaled': float(mae_scaled),\n",
    "        'mae_improvement': float(mae_raw - mae_scaled),\n",
    "    },\n",
    "\n",
    "    'primary_hcda_method': primary_hcda_method,\n",
    "    'primary_hcda_value': float(primary_hcda_value),\n",
    "    'primary_mae': float(min(mae_raw, mae_scaled)),\n",
    "\n",
    "    'metrics': metrics_all,\n",
    "\n",
    "    'feature_importance': {\n",
    "        'top_15': feature_ranking.head(15)[['feature', 'importance_pct']].to_dict('records'),\n",
    "        'real_rate_submodel_total_pct': float(rr_importance_total),\n",
    "        'real_rate_submodel_individual': {\n",
    "            feat: {\n",
    "                'rank': int(feature_ranking[feature_ranking['feature'] == feat].index[0] + 1),\n",
    "                'importance_pct': float(feature_ranking[feature_ranking['feature'] == feat]['importance_pct'].values[0]),\n",
    "            }\n",
    "            for feat in rr_features\n",
    "        },\n",
    "    },\n",
    "\n",
    "    'target_evaluation': {\n",
    "        'direction_accuracy': {\n",
    "            'target': '> 56.0%',\n",
    "            'actual': f\"{test_m['direction_accuracy']*100:.2f}%\",\n",
    "            'gap': f\"{(test_m['direction_accuracy'] - 0.56)*100:+.2f}pp\",\n",
    "            'passed': bool(targets_met[0]),\n",
    "        },\n",
    "        'high_confidence_da': {\n",
    "            'target': '> 60.0%',\n",
    "            'actual': f\"{primary_hcda_value*100:.2f}%\",\n",
    "            'gap': f\"{(primary_hcda_value - 0.60)*100:+.2f}pp\",\n",
    "            'passed': bool(targets_met[1]),\n",
    "            'method_used': primary_hcda_method,\n",
    "        },\n",
    "        'mae': {\n",
    "            'target': '< 0.75%',\n",
    "            'actual': f\"{test_m['mae']:.4f}%\",\n",
    "            'gap': f\"{(0.0075 - test_m['mae']):.4f}%\",\n",
    "            'passed': bool(targets_met[2]),\n",
    "        },\n",
    "        'sharpe_ratio': {\n",
    "            'target': '> 0.80',\n",
    "            'actual': f\"{test_m['sharpe_ratio']:.2f}\",\n",
    "            'gap': f\"{(test_m['sharpe_ratio'] - 0.8):+.2f}\",\n",
    "            'passed': bool(targets_met[3]),\n",
    "        },\n",
    "    },\n",
    "\n",
    "    'targets_passed': sum(targets_met),\n",
    "    'targets_total': 4,\n",
    "    'overall_passed': all(targets_met),\n",
    "\n",
    "    'overfitting_analysis': {\n",
    "        'train_test_da_gap_pp': float(train_test_da_gap),\n",
    "        'target_gap_pp': 10.0,\n",
    "        'overfitting_check': 'PASS' if train_test_da_gap < 10 else 'FAIL',\n",
    "    },\n",
    "\n",
    "    'vs_attempt_7': {\n",
    "        'da_delta_pp': float((test_m['direction_accuracy'] - 0.6004) * 100),\n",
    "        'hcda_delta_pp': float((primary_hcda_value - 0.6413) * 100),\n",
    "        'mae_delta': float(test_m['mae'] - 0.9429),\n",
    "        'sharpe_delta': float(test_m['sharpe_ratio'] - 2.4636),\n",
    "    },\n",
    "\n",
    "    'vs_attempt_18': {\n",
    "        'da_delta_pp': float((test_m['direction_accuracy'] - 0.5830) * 100),\n",
    "        'hcda_delta_pp': float((primary_hcda_value - 0.6304) * 100),\n",
    "        'mae_delta': float(test_m['mae'] - 0.9527),\n",
    "        'sharpe_delta': float(test_m['sharpe_ratio'] - 1.8624),\n",
    "    },\n",
    "\n",
    "    'vs_naive': {\n",
    "        'naive_always_up_da': f\"{naive_always_up_da*100:.2f}%\",\n",
    "        'model_vs_naive_pp': float((test_m['direction_accuracy'] - naive_always_up_da) * 100),\n",
    "    },\n",
    "\n",
    "    'prediction_characteristics': {\n",
    "        'mean_raw': float(pred_test.mean()),\n",
    "        'std_raw': float(pred_test.std()),\n",
    "        'min_raw': float(pred_test.min()),\n",
    "        'max_raw': float(pred_test.max()),\n",
    "        'positive_pct': float((pred_test > 0).sum() / len(pred_test) * 100),\n",
    "    },\n",
    "}\n",
    "\n",
    "with open('training_result.json', 'w') as f:\n",
    "    json.dump(training_result, f, indent=2, default=str)\n",
    "print(\"Saved training_result.json\")\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"TRAINING COMPLETE\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"Finished: {datetime.now().isoformat()}\")\n",
    "print(f\"\\nFinal Status:\")\n",
    "print(f\"  Attempt: 19\")\n",
    "print(f\"  Features: 28\")\n",
    "print(f\"  Ensemble: {N_ENSEMBLE} models, {BOOTSTRAP_FRAC:.0%} bootstrap\")\n",
    "print(f\"  Optuna trials: {len(study.trials)}\")\n",
    "print(f\"  Best Optuna score: {study.best_value:.4f}\")\n",
    "print(f\"  OLS alpha: {alpha_ols:.2f}\")\n",
    "print(f\"  HCDA method: {primary_hcda_method.upper()}\")\n",
    "print(f\"  Targets passed: {sum(targets_met)}/4\")\n",
    "if all(targets_met):\n",
    "    print(f\"  ALL TARGETS MET\")\n",
    "else:\n",
    "    failed = [t for t, m in zip(['DA', 'HCDA', 'MAE', 'Sharpe'], targets_met) if not m]\n",
    "    print(f\"  Improvements needed on: {failed}\")"
   ],
   "id": "cell-25"
  }
 ]
}