{
  "feature": "meta_model",
  "items": [
    {
      "priority": 1,
      "type": "data_pipeline_fix",
      "description": "Fix data pipeline to retain ~2000+ training samples instead of 964. Handle timezone mismatches in submodel CSVs and implement NaN imputation for early-period rows (fill regime_prob with 0.5, z-scores with 0, binary signals with 0).",
      "reason": "Attempt 1 lost 45.4% of data (2523->1378 rows) due to inner join + dropna. 964 training samples is insufficient for 39 features.",
      "resume_from": "builder_model",
      "research_needed": false
    },
    {
      "priority": 2,
      "type": "feature_selection",
      "description": "Drop all 11 non-stationary price-level base features (gld_open/high/low/close, silver_close, copper_close, sp500_close, gld_volume, etf_flow_gld_close, etf_flow_volume_ma20, etf_flow_gld_volume) and all 4 CNY features. Reduce from 39 to ~24 features.",
      "reason": "Price-level features dominated top-5 importance but cause regime-dependent overfitting. CNY features degraded DA -2.06% and Sharpe -0.593 in Phase 2.",
      "resume_from": "architect",
      "research_needed": true
    },
    {
      "priority": 3,
      "type": "loss_function_change",
      "description": "Replace directional-weighted MAE (penalty=4.52) with standard reg:squarederror. The custom loss caused 94.3% train DA memorization with only 46.9% val DA.",
      "reason": "Directional penalty amplified overfitting to training directions. Model memorized rather than learned.",
      "resume_from": "architect",
      "research_needed": false
    },
    {
      "priority": 4,
      "type": "regularization_strengthening",
      "description": "Expand regularization ranges: lambda [3,20], alpha [1,10], max_depth [2,4], min_child_weight [10,30], subsample [0.4,0.7], colsample [0.3,0.6].",
      "reason": "Attempt 1 regularization was too weak. Optuna selected lambda=1.56, alpha=0.25 (lower ends). Need stronger constraints with 24 features.",
      "resume_from": "architect",
      "research_needed": false
    },
    {
      "priority": 5,
      "type": "sharpe_formula_alignment",
      "description": "Align Sharpe calculation to CLAUDE.md evaluator spec: cost on position changes only, not daily. Formula: trades = np.abs(np.diff(positions, prepend=0)); ret = positions * actual - trades * cost.",
      "reason": "Training notebook used daily cost (Sharpe=0.428). CLAUDE.md formula gives Sharpe=1.027. Alignment to CLAUDE.md is economically more realistic.",
      "resume_from": "builder_model",
      "research_needed": false
    },
    {
      "priority": 6,
      "type": "optuna_objective_reweight",
      "description": "Change Optuna composite weights to: Sharpe 50%, DA 30%, MAE 10%, HC-DA 10%. Remove directional_penalty from search space.",
      "reason": "Current weights (Sharpe 40%, DA 25%, HC-DA 20%, MAE 15%) over-weighted HC-DA which is hard to optimize directly. Sharpe and DA are the binding constraints.",
      "resume_from": "architect",
      "research_needed": false
    }
  ]
}
