{
  "task_type": "meta_model",
  "feature": "meta_model",
  "attempt": 3,
  "phase": "phase3_meta_model",
  "source": "evaluator",
  "objective": "Improve meta-model HCDA from 55.26% to >60% (the sole failing metric). All other targets already pass: DA=57.26% (>56%), MAE=0.6877% (<0.75%), Sharpe=1.5835 (>0.80). Focus on prediction magnitude calibration and asymmetric confidence improvement.",

  "requirements": "Retain the Attempt 2 architecture (XGBoost reg:squarederror, 22 stationary features, same data pipeline). Do NOT change the core model structure that achieved 3/4 targets. Focus narrowly on improving HCDA through: (1) prediction magnitude calibration to create better high/low confidence separation, (2) addressing asymmetric UP/DOWN accuracy (UP=61.8%, DOWN=53.9%), (3) increasing HCDA weight in Optuna objective from 10% to 30%.",

  "inputs": {
    "base_features": "data/processed/base_features.csv",
    "submodel_outputs": [
      "data/submodel_outputs/vix.csv",
      "data/submodel_outputs/technical.csv",
      "data/submodel_outputs/cross_asset.csv",
      "data/submodel_outputs/yield_curve.csv",
      "data/submodel_outputs/etf_flow.csv",
      "data/submodel_outputs/inflation_expectation.csv"
    ],
    "submodel_columns": {
      "vix": ["vix_regime_probability", "vix_mean_reversion_z", "vix_persistence"],
      "technical": ["tech_trend_regime_prob", "tech_mean_reversion_z", "tech_volatility_regime"],
      "cross_asset": ["xasset_regime_prob", "xasset_recession_signal", "xasset_divergence"],
      "yield_curve": ["yc_spread_velocity_z", "yc_curvature_z"],
      "etf_flow": ["etf_regime_prob", "etf_capital_intensity", "etf_pv_divergence"],
      "inflation_expectation": ["ie_regime_prob", "ie_anchoring_z", "ie_gold_sensitivity_z"]
    },
    "excluded_submodels": ["real_rate", "dxy", "cny_demand"],
    "excluded_columns": ["yc_regime_prob"],
    "target": "data/processed/target.csv"
  },

  "research_questions": [
    "Q1: How to calibrate XGBoost prediction magnitudes to improve HCDA? Options: Platt scaling, isotonic regression, temperature scaling on validation set. Which approach preserves DA and Sharpe while improving confidence separation?",
    "Q2: Why is DOWN-direction accuracy (53.9%) much weaker than UP-direction (61.8%)? Is this due to the bullish market regime in the test period, or a structural model weakness?",
    "Q3: At top-10% confidence (N=38), HCDA is 60.53%. At top-20% (N=76), it drops to 55.26%. What makes the 15th-20th percentile predictions less accurate? Can feature engineering or interaction terms improve this band?",
    "Q4: Should the Optuna objective use HCDA directly (risky: small sample size in top-20% = 70 val samples) or a proxy metric (e.g., correlation between |prediction| and correctness)?"
  ],

  "constraints": [
    "Data split frozen: 70/15/15 (time-series order, no shuffle)",
    "No future information leakage",
    "Self-contained Kaggle Notebook (all code in single notebook)",
    "Optuna HP optimization with minimum 50 trials",
    "NO raw price-level features or CNY features",
    "Use standard reg:squarederror (NO custom loss)",
    "Train-test DA gap MUST remain < 10pp",
    "MUST NOT regress on passing metrics: DA must stay >56%, MAE <0.75%, Sharpe >0.80",
    "Prediction magnitude calibration should be applied post-hoc on validation set"
  ],

  "known_issues": {
    "attempt2_hcda_failure": "HCDA 55.26% vs target 60%. Model has genuine skill at top-10% (60.53%) but prediction magnitudes are compressed (pred_std=0.167, 18.7% of actual_std=0.896), making the top-20% threshold non-discriminating.",
    "attempt2_directional_asymmetry": "UP predictions 61.8% accurate vs DOWN predictions 53.9%. Down-side confidence weaker, drags combined HCDA below target.",
    "attempt2_hcda_overfitting": "Train HCDA 73.47% vs Test HCDA 55.26% (18.21pp gap). HCDA is more prone to overfitting than DA because of smaller sample size (N=76 top-20%).",
    "attempt2_quarterly_variance": "DA ranges from 51.6% (2024Q3) to 65.6% (2024Q4). Model performance varies with market regime."
  },

  "previous_feedback": {
    "attempt": 2,
    "result": "PARTIAL SUCCESS - 3/4 targets met",
    "passed_metrics": {
      "direction_accuracy": {"value": 0.5726, "target": 0.56, "status": "PASS"},
      "mae": {"value": 0.6877, "target": 0.75, "status": "PASS"},
      "sharpe_ratio": {"value": 1.5835, "target": 0.80, "status": "PASS"}
    },
    "failed_metrics": {
      "high_confidence_da": {"value": 0.5526, "target": 0.60, "gap": -0.0474, "status": "FAIL"}
    },
    "improvement_actions": [
      "PRIORITY 1: Add post-hoc prediction calibration (Platt/isotonic) to widen magnitude spread",
      "PRIORITY 2: Address UP/DOWN asymmetry (61.8% vs 53.9%) via sample weighting or regime-aware thresholds",
      "PRIORITY 3: Increase HCDA weight in Optuna objective from 10% to 30%",
      "CAUTION: Do NOT compromise passing metrics (DA, MAE, Sharpe)"
    ],
    "model_config": {
      "architecture": "XGBoost reg:squarederror",
      "n_features": 22,
      "train_samples": 1765,
      "best_params": {
        "max_depth": 2,
        "min_child_weight": 14,
        "reg_lambda": 4.76,
        "reg_alpha": 3.65,
        "subsample": 0.478,
        "colsample_bytree": 0.371,
        "learning_rate": 0.025,
        "n_estimators": 247
      },
      "optuna_trials": 80,
      "optuna_weights": "Sharpe 50%, DA 30%, MAE 10%, HCDA 10%"
    },
    "hcda_analysis": {
      "top_10pct": {"n": 38, "hcda": 0.6053},
      "top_15pct": {"n": 57, "hcda": 0.5965},
      "top_20pct": {"n": 76, "hcda": 0.5526},
      "top_25pct": {"n": 95, "hcda": 0.5789},
      "top_30pct": {"n": 114, "hcda": 0.5789}
    }
  },

  "success_criteria": "Test set must achieve ALL of: DA > 56%, HC-DA > 60%, MAE < 0.75%, Sharpe > 0.8 (after 5bps costs on position changes). Train-test DA gap < 10pp. No regression on currently passing metrics.",

  "expected_artifacts": [
    "docs/design/meta_model_attempt_3.md",
    "notebooks/meta_model_3/train.ipynb",
    "logs/evaluation/meta_model_attempt_3_summary.md"
  ],

  "created_at": "2026-02-15T22:00:00",
  "created_by": "evaluator"
}
