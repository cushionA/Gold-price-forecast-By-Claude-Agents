{
  "feature": "meta_model",
  "attempt": 17,
  "source": "evaluator",
  "phase": "phase3_meta_model",

  "summary": "Combine XGBoost attempt 7 architecture (proven best base model: DA 60.04%, Sharpe 2.46) with bootstrap confidence technique (proven best HCDA method: +8.70pp in attempt 16). This is the ONLY untried combination with strong empirical backing from both components. Use EXACTLY attempt 7's XGBoost hyperparameters with bootstrap DATA SUBSAMPLING (not just seed variation) to generate sufficient ensemble diversity for bootstrap confidence filtering.",

  "previous_feedback": {
    "attempt_16_result": {
      "architecture": "LightGBM GBDT + Bootstrap confidence (5-seed) + OLS scaling",
      "da": "58.52% (PASS but -1.52pp vs attempt 7)",
      "hcda": "68.48% (BEST EVER, +4.35pp vs attempt 7)",
      "mae": "0.953% (FAIL, structural)",
      "sharpe": "1.76 (PASS but -0.70 vs attempt 7)",
      "key_finding": "Bootstrap confidence technique works brilliantly (+8.70pp HCDA). But LightGBM base model is inferior to XGBoost on DA and Sharpe.",
      "single_model_hcda": "59.78% (would FAIL 60% target without bootstrap)",
      "bootstrap_hcda": "68.48% (bootstrap saves HCDA)"
    },
    "attempt_7_result": {
      "architecture": "XGBoost reg:squarederror + |prediction| confidence + OLS scaling",
      "da": "60.04% (best ever, +1.31pp above naive)",
      "hcda": "64.13% (passed 60% target via |prediction| method)",
      "mae": "0.943% (FAIL, structural)",
      "sharpe": "2.46 (best ever, 3.1x target)",
      "bootstrap_issue": "Attempt 7's bootstrap std was too uniform (mean 0.008) -- all 5 seed-varied XGBoost models agreed too closely. Bootstrap variance method produced HCDA of only 55.43%, so |prediction| method was used instead.",
      "key_params": {
        "max_depth": 2,
        "min_child_weight": 25,
        "subsample": 0.765,
        "colsample_bytree": 0.450,
        "reg_lambda": 2.049,
        "reg_alpha": 1.107,
        "learning_rate": 0.0215,
        "n_estimators": 621
      }
    },
    "evaluator_diagnosis": "The regression from attempt 7 to attempt 16 is ENTIRELY attributable to LightGBM being weaker than XGBoost. The bootstrap confidence technique is the innovation and it worked. Solution: apply bootstrap to XGBoost.",
    "key_problem_to_solve": "Attempt 7's XGBoost bootstrap was too uniform (std mean 0.008) because seed-only variation produced nearly identical models. Attempt 17 must create genuine ensemble diversity through DATA SUBSAMPLING (training each model on a different 80% bootstrap sample of the training data)."
  },

  "requirements": {
    "architecture": {
      "base_model": "XGBoost with reg:squarederror objective",
      "hyperparameters": "Use EXACTLY attempt 7 hyperparameters (listed above). Do NOT run Optuna. These params are proven optimal.",
      "ensemble_method": "Train 10-15 XGBoost models, each on a different bootstrap sample of the training data (random 80% with replacement). Use seeds 42-56.",
      "prediction": "For each test sample, compute mean prediction across all ensemble members. Also compute std (bootstrap standard deviation).",
      "high_confidence_selection": "Select top 20% of test samples by LOWEST bootstrap std as high-confidence predictions. Compute HCDA on this subset.",
      "ols_scaling": "Apply OLS scaling to ensemble mean predictions (fit on validation set). Use attempt 7's approach.",
      "features": "Use EXACTLY the same 24 features as attempt 7. No additions, no removals."
    },
    "critical_differences_from_attempt_7": [
      "Attempt 7 used 5 models with ONLY seed variation (42-46), all on FULL training data. This produced std mean 0.008 (too uniform).",
      "Attempt 17 uses 10-15 models with DATA SUBSAMPLING (each model trains on random 80% of training data WITH REPLACEMENT). This should produce std mean ~0.02-0.05 (sufficient diversity)."
    ],
    "critical_differences_from_attempt_16": [
      "Attempt 16 used LightGBM (num_leaves=66, ~depth 6). Attempt 17 uses XGBoost (max_depth=2).",
      "Attempt 16 used 5 seed-varied models. Attempt 17 uses 10-15 data-subsampled models.",
      "Attempt 16 had 100 Optuna trials. Attempt 17 uses fixed attempt 7 hyperparameters (no HPO needed)."
    ],
    "output_requirements": {
      "predictions_csv": "test_predictions.csv with columns: Date, prediction (ensemble mean), bootstrap_std, high_confidence (bool)",
      "training_result_json": "Standard training_result.json with all metrics, bootstrap analysis, feature importance",
      "model_files": "Save all 10-15 individual model files (model_seed_42.json through model_seed_56.json)"
    }
  },

  "success_criteria": {
    "must_beat_attempt_7_on": "HCDA (target: > 64.13%)",
    "must_maintain": {
      "da": ">= 58.0% (attempt 7 was 60.04%)",
      "sharpe": ">= 2.0 (attempt 7 was 2.46)"
    },
    "failure_criteria": "If DA < 57% or Sharpe < 1.5, bootstrap subsampling is degrading XGBoost base. Confirm attempt 7 as final.",
    "ideal_outcome": "DA >= 59%, HCDA >= 68%, Sharpe >= 2.0"
  },

  "constraints": [
    "Do NOT change any XGBoost hyperparameters from attempt 7. The innovation is ONLY the bootstrap ensemble method.",
    "Do NOT add or remove features. Use the same 24 features.",
    "Do NOT run Optuna. Hyperparameters are fixed.",
    "Use bootstrap data subsampling (80% with replacement), not just seed variation.",
    "Train at least 10 ensemble members for robust bootstrap statistics.",
    "Include BOTH HCDA methods in the output: (a) bootstrap std-based, (b) |prediction|-based. Report both.",
    "Include dataset_sources: bigbigzabuton/gold-prediction-submodels in kernel-metadata.json.",
    "Report vs_attempt_7 and vs_attempt_16 comparisons in training_result.json."
  ],

  "created_at": "2026-02-21T19:00:00",
  "created_by": "evaluator"
}
