{
  "task_type": "meta_model",
  "feature": "meta_model",
  "attempt": 6,
  "phase": "phase3_meta_model",
  "source": "user_directed_improvement",

  "objective": "Lightweight improvement of attempt 5 through (1) Shapley-based confidence scoring to fix inverted confidence ordering, and (2) calibrated output scaling to address prediction magnitude mismatch. Target: HCDA >= 60% and MAE <= 0.85% without major architectural changes.",

  "previous_attempt_results": {
    "attempt_5": {
      "test_da": "56.77%",
      "test_hcda": "57.61%",
      "test_mae": "0.9521%",
      "test_sharpe": 1.8343,
      "targets_passed": "2/4",
      "key_issues": [
        "HCDA 2.39pp below 60% target",
        "Confidence ordering inverted: Decile 3 (77.8% DA) > Decile 1 (57.8% DA)",
        "Prediction scale 20x smaller than actuals (std 0.070 vs 1.369)",
        "Val DA 49.23% below random (overfitting indicator)"
      ]
    }
  },

  "improvement_strategy": "lightweight_modifications",

  "proposed_fixes": [
    {
      "issue": "Inverted confidence ordering",
      "root_cause": "Using |prediction| as confidence score assumes model calibration which XGBoost lacks",
      "solution": "Compute TreeSHAP values on validation set to measure feature contribution uncertainty. High SHAP variance = low confidence. Use SHAP-based confidence to select top 20% instead of |prediction|.",
      "implementation": "After training XGBoost, compute shap.TreeExplainer on val set. Confidence = 1 / (1 + std(SHAP values)). Select HC set by this score.",
      "expected_improvement": "HCDA +1-3pp (potentially 59-61%)",
      "complexity": "Low (shap library already available)"
    },
    {
      "issue": "Prediction scale mismatch (MAE inflation)",
      "root_cause": "XGBoost reg:squarederror optimizes for MSE, which penalizes large errors quadratically, leading to conservative predictions",
      "solution": "Post-training calibration: compute val_std_actual / val_std_pred scaling factor. Multiply test predictions by this factor before MAE calculation.",
      "implementation": "scale_factor = np.std(y_val_actual) / np.std(y_val_pred). y_test_pred_scaled = y_test_pred * scale_factor.",
      "expected_improvement": "MAE -0.10 to -0.20% (0.95% -> 0.75-0.85%)",
      "complexity": "Very low (single multiplication)"
    },
    {
      "issue": "Val DA 49.23% below random",
      "root_cause": "Weak early stopping / overfitting to train patterns that don't generalize",
      "solution": "Strengthen early stopping rounds (50 -> 100) and increase min_child_weight search range",
      "implementation": "Adjust Optuna search space: min_child_weight [12, 25] (was [1, 20])",
      "expected_improvement": "More stable val-test consistency",
      "complexity": "Very low (HP range adjustment)"
    }
  ],

  "requirements": {
    "architecture": "Single XGBoost reg:squarederror (same as attempt 5). Add post-training SHAP and scaling layers.",
    "feature_set": "Same 23 features as attempt 5 (no changes)",
    "data_pipeline": "Reuse attempt 5 data loading (no changes)",
    "hyperparameter_optimization": {
      "n_trials": 100,
      "search_space_modifications": [
        "min_child_weight: [12, 25] (strengthened from [1, 20])",
        "early_stopping_rounds: 100 (was 50)",
        "Other params: same as attempt 5"
      ],
      "objective_weights": "Same as attempt 5 (HCDA 20%, DA 30%, MAE 10%, Sharpe 40%)"
    },
    "new_components": [
      "TreeSHAP confidence scoring on validation set",
      "Variance-based scaling factor calibration",
      "HCDA computed using SHAP confidence instead of |prediction|"
    ]
  },

  "evaluation_requirements": {
    "primary_targets": {
      "DA": "> 56%",
      "HCDA": "> 60% (using SHAP confidence scoring)",
      "MAE": "< 0.75% (stretch) or < 0.85% (acceptable improvement)",
      "Sharpe": "> 0.8"
    },
    "comparison_baselines": [
      "Attempt 5 (current best)",
      "Attempt 2 (best overall 3/4)"
    ],
    "diagnostic_outputs": [
      "SHAP confidence vs |prediction| confidence comparison",
      "Decile analysis with both scoring methods",
      "Pre/post scaling MAE comparison",
      "Feature importance (should match attempt 5 closely)"
    ]
  },

  "success_criteria": [
    "HCDA >= 60% OR +2pp improvement from attempt 5",
    "MAE <= 0.85%",
    "DA >= 56%",
    "Sharpe >= 1.5",
    "Train-test DA gap < 10pp"
  ],

  "constraints": [
    "Keep XGBoost architecture (no Transformer yet)",
    "No multi-country expansion (save for future)",
    "Reuse existing 23 features (no new feature engineering)",
    "Target Kaggle runtime < 45 min (SHAP adds ~10-15 min)",
    "Self-contained Kaggle Notebook"
  ],

  "risk_assessment": {
    "primary_risk": "SHAP confidence may not correlate with prediction accuracy any better than |prediction|. The inverted ordering may be fundamental to XGBoost's behavior on this problem.",
    "mitigation": "Compute both confidence scores and compare correlation with actual accuracy. If SHAP doesn't improve, fall back to attempt 5 results.",
    "secondary_risk": "Scaling factor may overfit to validation period volatility and degrade test MAE.",
    "mitigation": "Use conservative scaling (e.g., 0.7 * scale_factor) or clip to max 2.0x to prevent extreme adjustments."
  },

  "research_questions": [
    "Does SHAP value variance correlate with prediction accuracy better than |prediction|?",
    "What is the optimal scaling factor computation method (std ratio vs quantile matching)?",
    "Should confidence threshold remain at 80th percentile or adjust based on SHAP distribution?"
  ],

  "expected_runtime": {
    "optuna_trials": "~25 min (100 trials)",
    "shap_computation": "~10-15 min (TreeExplainer on val set)",
    "total": "~40-45 min"
  },

  "resume_from": "architect",
  "research_needed": false,

  "created_at": "2026-02-16T13:10:00",
  "created_by": "orchestrator"
}
