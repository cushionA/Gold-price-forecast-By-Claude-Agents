"""
Gold Prediction SubModel: real_rate Attempt 5
Feature Engineering Pipeline: Markov Regime + EWM Trend + CUSUM Change Points

Method: HMM + Change Point Detection + State Features (NO interpolation)
Generated by builder_model agent
Date: 2026-02-14
"""

import pandas as pd
import numpy as np
from datetime import datetime
import json
import os
import warnings
from statsmodels.tsa.regime_switching.markov_regression import MarkovRegression
from scipy.stats import zscore

warnings.filterwarnings('ignore')

# Random seeds for reproducibility
np.random.seed(42)

print("=" * 80)
print("Gold SubModel: real_rate Attempt 5 - State Feature Extraction")
print("=" * 80)
print(f"Started: {datetime.now().isoformat()}")
print()

# ============================================================
# 1. LOAD DATA
# ============================================================
print("Loading data...")

# Multi-country monthly data
monthly_file = "data/processed/real_rate_multi_country_features.csv"
monthly_data = pd.read_csv(monthly_file, index_col=0, parse_dates=True)
print(f"Monthly data shape: {monthly_data.shape}")

# Gold daily calendar
gold_file = "data/raw/gold.csv"
gold_data = pd.read_csv(gold_file, parse_dates=['Date'], index_col='Date')
print(f"Gold data shape: {gold_data.shape}")

# Extract 7 rate change columns
rate_change_cols = [
    'us_tips_change',
    'germany_nominal_change',
    'uk_nominal_change',
    'canada_nominal_change',
    'switzerland_nominal_change',
    'norway_nominal_change',
    'sweden_nominal_change'
]

rate_changes = monthly_data[rate_change_cols].copy()
print(f"Rate changes shape: {rate_changes.shape}")
print()

# ============================================================
# 2. COMPUTE GLOBAL MEAN RATE CHANGE
# ============================================================
print("Computing global mean rate change...")
global_mean_change = rate_changes.mean(axis=1)
print(f"Global mean shape: {global_mean_change.shape}")
print(f"Global mean range: [{global_mean_change.min():.4f}, {global_mean_change.max():.4f}]")
print()

# ============================================================
# 3. TRAIN/TEST SPLIT FOR MARKOV MODEL
# ============================================================
train_size = int(len(global_mean_change) * 0.7)
global_mean_train = global_mean_change.iloc[:train_size]
print(f"Train samples: {len(global_mean_train)} (70%)")
print(f"Full samples: {len(global_mean_change)}")
print()

# ============================================================
# 4. STEP 1: MARKOV REGIME DETECTION
# ============================================================
print("Fitting 3-regime Markov Switching model...")

# Fit on training data
mod_train = MarkovRegression(
    global_mean_train.values,
    k_regimes=3,
    trend='c',
    switching_variance=True
)
res_train = mod_train.fit(maxiter=500, disp=False)

# Fit on full data (for smoothed probabilities)
mod_full = MarkovRegression(
    global_mean_change.values,
    k_regimes=3,
    trend='c',
    switching_variance=True
)
res_full = mod_full.fit(maxiter=500, disp=False)

# Get smoothed marginal probabilities
smoothed_probs = res_full.smoothed_marginal_probabilities

# Convert to DataFrame if numpy array
if isinstance(smoothed_probs, np.ndarray):
    smoothed_probs = pd.DataFrame(
        smoothed_probs,
        columns=[f'regime_{i}' for i in range(smoothed_probs.shape[1])],
        index=global_mean_change.index
    )

regime_labels_idx = smoothed_probs.idxmax(axis=1)
regime_labels = regime_labels_idx.str.extract(r'regime_(\d+)')[0].astype(int).values
regime_persistence = smoothed_probs.max(axis=1).values
transition_prob = 1 - regime_persistence

# Regime statistics
regime_means = {}
for regime_id in range(3):
    regime_mask = regime_labels == regime_id
    regime_data = global_mean_change[regime_mask]
    regime_means[f"regime_{regime_id}"] = {
        "mean_change": float(regime_data.mean()) if len(regime_data) > 0 else 0.0,
        "pct_months": float(regime_mask.sum() / len(regime_mask) * 100),
        "std": float(regime_data.std()) if len(regime_data) > 0 else 0.0
    }

print(f"Regime 0: mean={regime_means['regime_0']['mean_change']:.4f}, pct={regime_means['regime_0']['pct_months']:.1f}%")
print(f"Regime 1: mean={regime_means['regime_1']['mean_change']:.4f}, pct={regime_means['regime_1']['pct_months']:.1f}%")
print(f"Regime 2: mean={regime_means['regime_2']['mean_change']:.4f}, pct={regime_means['regime_2']['pct_months']:.1f}%")
print()

# ============================================================
# 5. STEP 2: EWM TREND EXTRACTION
# ============================================================
print("Computing EWM trend (span=3)...")
ewm_trend = global_mean_change.ewm(span=3, adjust=False).mean()
trend_direction = np.sign(ewm_trend).astype(int)

# Replace 0 with previous direction (handle exact zero cases)
for i in range(len(trend_direction)):
    if trend_direction[i] == 0:
        if i > 0:
            trend_direction[i] = trend_direction[i-1]
        else:
            trend_direction[i] = -1  # default to -1 for first value

# Trend strength: normalized by rolling std (24-month window)
rolling_std = global_mean_change.rolling(window=24, min_periods=12).std()
trend_strength = np.abs(ewm_trend) / (rolling_std + 1e-6)
trend_strength = np.clip(trend_strength, 0, 3.0)

print(f"Trend direction values: {np.unique(trend_direction)}")
print(f"Trend strength range: [{trend_strength.min():.4f}, {trend_strength.max():.4f}]")
print()

# ============================================================
# 6. STEP 3: CUSUM CHANGE POINT DETECTION
# ============================================================
print("Running CUSUM change point detection...")

def cusum_changepoints(series, drift=0.05, threshold=0.5):
    """Detect change points using CUSUM algorithm."""
    cusum_pos = np.zeros(len(series))
    cusum_neg = np.zeros(len(series))
    change_points = []

    for i in range(1, len(series)):
        cusum_pos[i] = max(0, cusum_pos[i-1] + series.iloc[i] - drift)
        cusum_neg[i] = max(0, cusum_neg[i-1] - series.iloc[i] - drift)

        if cusum_pos[i] > threshold or cusum_neg[i] > threshold:
            change_points.append(i)
            cusum_pos[i] = 0  # reset after detection
            cusum_neg[i] = 0

    return change_points

# Apply CUSUM to US TIPS changes
us_tips_changes = monthly_data['us_tips_change']
change_point_indices = cusum_changepoints(us_tips_changes, drift=0.05, threshold=0.5)
change_point_dates = monthly_data.index[change_point_indices]

print(f"Detected {len(change_point_indices)} change points")
print(f"Average gap: {len(us_tips_changes) / (len(change_point_indices) + 1):.1f} months")
print()

# ============================================================
# 7. STEP 4: CROSS-COUNTRY AGGREGATION
# ============================================================
print("Computing cross-country features...")

# Regime sync: proportion of countries moving in same direction
rate_signs = np.sign(rate_changes)
proportion_rising = (rate_signs == 1).sum(axis=1) / 7
proportion_falling = (rate_signs == -1).sum(axis=1) / 7
regime_sync = np.maximum(proportion_rising, proportion_falling)

# Change magnitude: normalized absolute change
global_std = global_mean_change.rolling(window=24, min_periods=12).std()
change_magnitude = np.abs(global_mean_change) / (global_std + 1e-6)
change_magnitude = np.clip(change_magnitude, 0, 5.0)

print(f"Regime sync range: [{regime_sync.min():.4f}, {regime_sync.max():.4f}]")
print(f"Change magnitude range: [{change_magnitude.min():.4f}, {change_magnitude.max():.4f}]")
print()

# ============================================================
# 8. BUILD MONTHLY FEATURE DATAFRAME
# ============================================================
print("Building monthly feature DataFrame...")

monthly_features = pd.DataFrame({
    'real_rate_regime_persistence': regime_persistence,
    'real_rate_transition_prob': transition_prob,
    'real_rate_trend_direction': trend_direction,
    'real_rate_trend_strength': trend_strength,
    'real_rate_regime_sync': regime_sync.values,
    'real_rate_change_magnitude': change_magnitude.values
}, index=global_mean_change.index)

print(f"Monthly features shape: {monthly_features.shape}")
print(monthly_features.head())
print()

# ============================================================
# 9. EXPAND TO DAILY FREQUENCY
# ============================================================
print("Expanding to daily frequency...")

# Get daily trading dates from gold data
daily_dates = gold_data.index

# Forward-fill monthly features to daily
daily_features = monthly_features.reindex(daily_dates, method='ffill')

# ============================================================
# 10. COMPUTE DAYS_SINCE_CHANGE (DAILY-UPDATING FEATURE)
# ============================================================
print("Computing days_since_change feature...")

days_since_change = np.zeros(len(daily_dates), dtype=int)

for i, date in enumerate(daily_dates):
    # Find all change points before or on this date
    past_changes = change_point_dates[change_point_dates <= date]

    if len(past_changes) > 0:
        # Days since most recent change
        days_since_change[i] = (date - past_changes[-1]).days
    else:
        # No change point yet, count from start of data
        days_since_change[i] = (date - monthly_data.index[0]).days

daily_features['real_rate_days_since_change'] = days_since_change

print(f"Days since change range: [{days_since_change.min()}, {days_since_change.max()}]")
print(f"Days since change unique values: {len(np.unique(days_since_change))}")
print()

# ============================================================
# 11. CLIP TO SCHEMA RANGE
# ============================================================
print("Clipping to schema range (2015-01-30 to 2025-02-12)...")

schema_start = pd.Timestamp('2015-01-30')
schema_end = pd.Timestamp('2025-02-12')

output = daily_features[(daily_features.index >= schema_start) &
                        (daily_features.index <= schema_end)].copy()

print(f"Output shape: {output.shape}")
print(f"Date range: {output.index[0]} to {output.index[-1]}")
print()

# ============================================================
# 12. VALIDATION
# ============================================================
print("Running validation checks...")

# Shape check
assert output.shape[0] > 2500, f"Expected ~2523 rows, got {output.shape[0]}"
assert output.shape[1] == 7, f"Expected 7 columns, got {output.shape[1]}"

# No NaN
nan_count = output.isna().sum().sum()
assert nan_count == 0, f"Found {nan_count} NaN values"

# No constant columns
for col in output.columns:
    nunique = output[col].nunique()
    assert nunique > 1, f"Constant column: {col}"

# Range checks
assert output['real_rate_regime_persistence'].between(0, 1).all(), "regime_persistence out of range"
assert output['real_rate_transition_prob'].between(0, 1).all(), "transition_prob out of range"
assert output['real_rate_trend_direction'].isin([-1, 1]).all(), "trend_direction invalid values"
assert output['real_rate_trend_strength'].between(0, 3.01).all(), "trend_strength out of range"
assert (output['real_rate_days_since_change'] >= 0).all(), "days_since_change negative"
assert output['real_rate_regime_sync'].between(0.5, 1.01).all(), "regime_sync out of range"
assert (output['real_rate_change_magnitude'] >= 0).all(), "change_magnitude negative"

# days_since_change should have many unique values
days_unique = output['real_rate_days_since_change'].nunique()
assert days_unique > 100, f"days_since_change should have >100 unique values, got {days_unique}"

# State features should have fewer unique values than rows
for col in ['real_rate_regime_persistence', 'real_rate_trend_direction', 'real_rate_regime_sync']:
    unique_ratio = output[col].nunique() / len(output)
    assert unique_ratio < 0.5, f"{col} has too many unique values ({unique_ratio:.2%})"

print("All validation checks PASSED")
print()

# ============================================================
# 13. SAVE OUTPUTS
# ============================================================
print("Saving outputs...")

# Create output directories
os.makedirs("data/submodel_outputs/real_rate", exist_ok=True)

# Save submodel output
output.to_csv("data/submodel_outputs/real_rate.csv")
print(f"Saved: data/submodel_outputs/real_rate.csv")

# Compute output statistics
output_stats = {}
unique_value_counts = {}

for col in output.columns:
    output_stats[col] = {
        'mean': float(output[col].mean()),
        'std': float(output[col].std()),
        'min': float(output[col].min()),
        'max': float(output[col].max())
    }
    unique_value_counts[col] = int(output[col].nunique())

# Save training result JSON
result = {
    "feature": "real_rate",
    "attempt": 5,
    "method": "MarkovRegression_EWM_CUSUM_StateFeatures",
    "timestamp": datetime.now().isoformat(),
    "markov_regimes": regime_means,
    "cusum_change_points": len(change_point_indices),
    "ewm_span": 3,
    "output_shape": list(output.shape),
    "output_columns": list(output.columns),
    "output_stats": output_stats,
    "unique_value_counts": unique_value_counts,
    "n_train_months": train_size,
    "n_total_months": len(global_mean_change),
    "validation": {
        "nan_count": 0,
        "all_checks_passed": True
    }
}

with open("data/submodel_outputs/real_rate/training_result.json", "w") as f:
    json.dump(result, f, indent=2)
print(f"Saved: data/submodel_outputs/real_rate/training_result.json")

# ============================================================
# 14. SUMMARY
# ============================================================
print()
print("=" * 80)
print("SUMMARY")
print("=" * 80)
print(f"Output shape: {output.shape}")
print(f"Columns: {list(output.columns)}")
print()
print("Unique value counts:")
for col, count in unique_value_counts.items():
    pct = count / len(output) * 100
    print(f"  {col}: {count} ({pct:.1f}%)")
print()
print("Regime distribution:")
for regime_id, stats in regime_means.items():
    print(f"  {regime_id}: mean={stats['mean_change']:.4f}, pct={stats['pct_months']:.1f}%")
print()
print(f"Change points detected: {len(change_point_indices)}")
print()
print(f"Finished: {datetime.now().isoformat()}")
print("=" * 80)
