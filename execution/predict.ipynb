{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# 金価格予測 - 日次実行ノートブック\n\n**モデル:** メタモデル Attempt 7 (XGBoost + 8サブモデル + ポジションサイジング)\n\n**テストセット性能:**\n- 方向的中率 (DA): 60.04%\n- 高確信度DA (HCDA): 64.13%\n- シャープレシオ: 2.46 (取引コスト5bps控除後)\n\n**使い方:**\n1. 下のセルで `TARGET_DATE` を設定（空欄なら本日基準）\n2. 「Run All Cells」で全セル実行\n3. 最下部の予測レポートを確認"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# ================================================================\n# ユーザー入力: 予測したい日付を設定\n# ================================================================\n# 書式: 'YYYY-MM-DD'（例: '2026-02-18'）\n# None または '' のままにすると、本日を基準に翌営業日を予測\nTARGET_DATE = None\n\n# ================================================================\n# 設定パラメータ\n# ================================================================\nFRED_API_KEY = None           # FRED APIキー（Noneなら.envから自動読込）\nTOTAL_CAPITAL = 1_000_000     # 運用総資本（円 or ドル）\nMAX_POSITION_PCT = 0.30       # 最大ポジション比率（資本の30%）\nMIN_POSITION_PCT = 0.05       # 最小ポジション比率（資本の5%）\nCOST_BPS = 5                  # 取引コスト（ベーシスポイント）"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# ================================================================\n# 1. ライブラリ読込 & 初期設定\n# ================================================================\nimport pandas as pd\nimport numpy as np\nimport xgboost as xgb\nimport warnings\nimport os\nfrom datetime import datetime, timedelta\n\nwarnings.filterwarnings('ignore')\nnp.random.seed(42)\n\n# --- FRED API（米経済指標取得用）---\ntry:\n    from fredapi import Fred\nexcept ImportError:\n    import subprocess\n    subprocess.run(['pip', 'install', 'fredapi'], check=True)\n    from fredapi import Fred\n\n# --- HMM（隠れマルコフモデル：サブモデルで使用）---\ntry:\n    from hmmlearn.hmm import GaussianHMM\nexcept ImportError:\n    import subprocess\n    subprocess.run(['pip', 'install', 'hmmlearn'], check=True)\n    from hmmlearn.hmm import GaussianHMM\n\n# --- GMM（ガウス混合モデル：VIXサブモデルで使用）---\nfrom sklearn.mixture import GaussianMixture\n\n# --- Yahoo Finance（価格データ取得）---\nimport yfinance as yf\n\n# FRED APIキーの読込\nif FRED_API_KEY is None:\n    try:\n        from dotenv import load_dotenv\n        load_dotenv()\n        FRED_API_KEY = os.getenv('FRED_API_KEY')\n    except ImportError:\n        pass\n\nif FRED_API_KEY is None:\n    raise ValueError('FRED_API_KEY が未設定です。このセルで直接指定するか、.envファイルに設定してください。')\n\nfred = Fred(api_key=FRED_API_KEY)\n\n# 予測日の解決\nif TARGET_DATE is None or TARGET_DATE == '':\n    target_date = pd.Timestamp.now().normalize()\nelse:\n    target_date = pd.Timestamp(TARGET_DATE)\n\n# データ取得期間（予測日の数日先まで取得して最新データを確保）\nfetch_end = (target_date + timedelta(days=5)).strftime('%Y-%m-%d')\nfetch_start = '2014-01-01'  # モデル学習開始日\n\nprint(f'予測基準日: {target_date.strftime(\"%Y-%m-%d\")}（翌営業日の金リターンを予測）')\nprint(f'データ取得範囲: {fetch_start} ～ {fetch_end}')\nprint(f'XGBoost: {xgb.__version__}')"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 2. 生データ取得\n13のAPIソースから市場データを取得します:\n- **Yahoo Finance**: 金先物(GC=F), ドル指数(DXY), GLD ETF, 銀(SI=F), 銅(HG=F), SKEW, GVZ, TNX, IRX, FVX\n- **FRED API**: 実質金利(DFII10), VIX(VIXCLS), 10年国債(DGS10), 2年国債(DGS2), BEI(T10YIE)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# ================================================================\n# 2. 生データ取得（全13ソース）\n# ================================================================\nprint('=' * 60)\nprint('生データ取得中...')\nprint('=' * 60)\n\n# --- 金先物（COMEX GC=F）---\nprint('金先物 (GC=F) を取得中...')\ngold_raw = yf.download('GC=F', start=fetch_start, end=fetch_end, progress=False)\ngold_close = gold_raw['Close'].squeeze()\ngold_close.index = pd.to_datetime(gold_close.index).tz_localize(None)\ngold_return = gold_close.pct_change() * 100          # 日次リターン（%）\ngold_return_next = gold_return.shift(-1)              # 翌日リターン（= 予測ターゲット）\nprint(f'  金: {len(gold_close)}行, 最新: {gold_close.index[-1].strftime(\"%Y-%m-%d\")}')\n\n# --- ドル指数（DXY）--- 金と逆相関の強い指標\nprint('ドル指数 (DX-Y.NYB) を取得中...')\ndxy_raw = yf.download('DX-Y.NYB', start=fetch_start, end=fetch_end, progress=False)\ndxy_close = dxy_raw['Close'].squeeze()\ndxy_close.index = pd.to_datetime(dxy_close.index).tz_localize(None)\nprint(f'  DXY: {len(dxy_close)}行')\n\n# --- GLD ETF --- テクニカル・ETFフロー分析に使用\nprint('GLD ETF を取得中...')\ngld_raw = yf.Ticker('GLD').history(start=fetch_start, end=fetch_end, auto_adjust=True)\ngld_raw.index = gld_raw.index.tz_localize(None)\nprint(f'  GLD: {len(gld_raw)}行')\n\n# --- 銀・銅先物 --- クロスアセット分析に使用\nprint('銀先物 (SI=F) / 銅先物 (HG=F) を取得中...')\nsilver_raw = yf.download('SI=F', start=fetch_start, end=fetch_end, progress=False)\ncopper_raw = yf.download('HG=F', start=fetch_start, end=fetch_end, progress=False)\nsilver_close = silver_raw['Close'].squeeze()\ncopper_close = copper_raw['Close'].squeeze()\nsilver_close.index = pd.to_datetime(silver_close.index).tz_localize(None)\ncopper_close.index = pd.to_datetime(copper_close.index).tz_localize(None)\nprint(f'  銀: {len(silver_close)}行, 銅: {len(copper_close)}行')\n\n# --- FRED: 実質金利（10年TIPS利回り）--- 金と最も強い負の相関\nprint('実質金利 DFII10 を取得中...')\nreal_rate_raw = fred.get_series('DFII10', observation_start=fetch_start)\nreal_rate_raw.index = pd.to_datetime(real_rate_raw.index)\nprint(f'  DFII10: {len(real_rate_raw)}行')\n\n# --- FRED: VIX --- リスクオフ指標\nprint('VIX (VIXCLS) を取得中...')\nvix_raw = fred.get_series('VIXCLS', observation_start=fetch_start)\nvix_raw.index = pd.to_datetime(vix_raw.index)\nprint(f'  VIX: {len(vix_raw)}行')\n\n# --- FRED: イールドカーブ（10年-2年スプレッド）---\nprint('国債利回り DGS10, DGS2 を取得中...')\ndgs10_raw = fred.get_series('DGS10', observation_start=fetch_start)\ndgs2_raw = fred.get_series('DGS2', observation_start=fetch_start)\ndgs10_raw.index = pd.to_datetime(dgs10_raw.index)\ndgs2_raw.index = pd.to_datetime(dgs2_raw.index)\nyield_spread = dgs10_raw - dgs2_raw   # イールドスプレッド\nprint(f'  DGS10: {len(dgs10_raw)}行, DGS2: {len(dgs2_raw)}行')\n\n# --- FRED: ブレークイーブンインフレ率（BEI）---\nprint('BEI (T10YIE) を取得中...')\nie_raw = fred.get_series('T10YIE', observation_start=fetch_start)\nie_raw.index = pd.to_datetime(ie_raw.index)\nprint(f'  T10YIE: {len(ie_raw)}行')\n\n# --- Yahoo: オプション市場指標 --- SKEW（テールリスク）とGVZ（金ボラティリティ）\nprint('SKEW, GVZ を取得中...')\nskew_data = yf.Ticker('^SKEW').history(start=fetch_start, end=fetch_end, auto_adjust=True)\ngvz_data = yf.Ticker('^GVZ').history(start=fetch_start, end=fetch_end, auto_adjust=True)\nskew_data.index = skew_data.index.tz_localize(None)\ngvz_data.index = gvz_data.index.tz_localize(None)\nprint(f'  SKEW: {len(skew_data)}行, GVZ: {len(gvz_data)}行')\n\n# --- Yahoo: 債券利回り代理指標 --- イールドカーブサブモデル用\nprint('TNX, IRX, FVX を取得中...')\ntnx = yf.Ticker('^TNX').history(start=fetch_start, end=fetch_end)   # 10年国債利回り\nirx = yf.Ticker('^IRX').history(start=fetch_start, end=fetch_end)   # 13週Tビル利回り\nfvx = yf.Ticker('^FVX').history(start=fetch_start, end=fetch_end)   # 5年国債利回り\ntnx.index = tnx.index.tz_localize(None)\nirx.index = irx.index.tz_localize(None)\nfvx.index = fvx.index.tz_localize(None)\nprint(f'  TNX: {len(tnx)}行, IRX: {len(irx)}行, FVX: {len(fvx)}行')\n\nprint('\\n全データ取得完了。')"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 3. サブモデル特徴量の計算\n8つのサブモデルが市場のレジーム・パターンを抽出:\n\n| # | サブモデル | 手法 | 出力特徴量 |\n|---|-----------|------|-----------|\n| 1 | VIX | GMM(2成分) | レジーム確率, 平均回帰z, 持続性 |\n| 2 | テクニカル | HMM(2状態) | トレンドレジーム, 平均回帰z, ボラレジーム |\n| 3 | クロスアセット | HMM(3状態) | レジーム確率, 景気後退シグナル, 乖離度 |\n| 4 | イールドカーブ | HMM(2状態) | スプレッド速度z, 曲率z |\n| 5 | ETFフロー | HMM(4状態) | レジーム確率, 資本集中度, PV乖離 |\n| 6 | インフレ期待 | HMM(3状態) | レジーム確率, アンカリングz, 金感応度z |\n| 7 | オプション | HMM(2状態) | リスクレジーム確率 |\n| 8 | 時間コンテキスト | Transformer | コンテキストスコア |"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# ================================================================\n# ヘルパー関数: HMMの複数リスタートフィッティング\n# ================================================================\ndef fit_hmm_best(X, n_components, covariance_type='full', n_restarts=10, n_iter=200, seeds=None):\n    \"\"\"複数の乱数シードでHMMを学習し、対数尤度最大のモデルを返す。\n    HMMは初期値に敏感なため、複数回リスタートが必要。\"\"\"\n    if seeds is None:\n        seeds = list(range(n_restarts))\n    best_model = None\n    best_score = -np.inf\n    for seed in seeds:\n        try:\n            model = GaussianHMM(\n                n_components=n_components,\n                covariance_type=covariance_type,\n                n_iter=n_iter,\n                random_state=seed,\n            )\n            model.fit(X)\n            score = model.score(X)\n            if score > best_score:\n                best_score = score\n                best_model = model\n        except Exception:\n            continue\n    return best_model\n\n\ndef hmm_highest_var_state(model):\n    \"\"\"HMMの状態の中で、共分散行列のトレース（総分散）が最大の状態を返す。\n    = 最もボラタイルなレジーム（高変動状態）のインデックス。\"\"\"\n    n_comp = model.n_components\n    traces = []\n    for i in range(n_comp):\n        if model.covariance_type == 'full':\n            traces.append(np.trace(model.covars_[i]))\n        elif model.covariance_type == 'diag':\n            traces.append(np.sum(model.covars_[i]))\n        else:\n            traces.append(np.sum(model.covars_[i]))\n    return np.argmax(traces)\n\n\nprint('ヘルパー関数定義完了。')"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# ================================================================\n# 3a. VIXサブモデル\n# ================================================================\n# VIXの対数変化率にGMM(2成分)をフィット → 高変動レジームの確率を抽出\n# 出力: vix_regime_probability（高変動状態の確率）\n#        vix_mean_reversion_z（VIX水準の平均回帰z値）\n#        vix_persistence（VIX変化の自己相関 = 持続性）\nprint('VIXサブモデルを計算中...')\n\nvix_series = vix_raw.dropna()\nvix_log_change = np.log(vix_series).diff().dropna()  # 対数変化率\n\n# GMM（2成分ガウス混合モデル）で高変動/低変動レジームを分離\ngmm_vix = GaussianMixture(n_components=2, covariance_type='diag', n_init=3, max_iter=100, random_state=42)\ngmm_vix.fit(vix_log_change.values.reshape(-1, 1))\n\n# 高分散の成分（= 高変動レジーム）のインデックスを特定\nhigh_var_idx = np.argmax(gmm_vix.covariances_.flatten())\nprobs = gmm_vix.predict_proba(vix_log_change.values.reshape(-1, 1))\nvix_regime_prob = pd.Series(probs[:, high_var_idx], index=vix_log_change.index, name='vix_regime_probability')\n\n# 平均回帰zスコア（40日移動平均・標準偏差で標準化）\nvix_z = (vix_series - vix_series.rolling(40).mean()) / vix_series.rolling(40).std()\nvix_z = vix_z.clip(-4, 4)\nvix_z.name = 'vix_mean_reversion_z'\n\n# 持続性 = 30日ローリング自己相関（ラグ1）\nvix_persistence = vix_log_change.rolling(30).apply(\n    lambda x: pd.Series(x).autocorr(lag=1), raw=False\n)\nvix_persistence.name = 'vix_persistence'\n\nvix_submodel = pd.DataFrame({\n    'vix_regime_probability': vix_regime_prob,\n    'vix_mean_reversion_z': vix_z,\n    'vix_persistence': vix_persistence,\n})\nprint(f'  VIXサブモデル: {len(vix_submodel)}行, NaN: {vix_submodel.isna().sum().to_dict()}')"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# ================================================================\n# 3b. テクニカルサブモデル\n# ================================================================\n# GLD ETFの[リターン, GK-Volatility]にHMM(2状態)をフィット\n# 出力: tech_trend_regime_prob（高変動レジーム確率）\n#        tech_mean_reversion_z（リターンの平均回帰z値）\n#        tech_volatility_regime（GK-Volのz値 = ボラティリティレジーム）\nprint('テクニカルサブモデルを計算中...')\n\ngld_close = gld_raw['Close']\ngld_open = gld_raw['Open']\ngld_high = gld_raw['High']\ngld_low = gld_raw['Low']\n\ngld_returns = gld_close.pct_change()  # GLD日次リターン\n\n# Garman-Klass ボラティリティ（日中高安を使った効率的なボラ推定）\ngk_vol = np.sqrt(\n    0.5 * np.log(gld_high / gld_low) ** 2\n    - (2 * np.log(2) - 1) * np.log(gld_close / gld_open) ** 2\n).clip(lower=1e-8)\n\n# HMM（2状態, フル共分散）: [リターン, GK-Vol] → トレンド/ボラレジーム分離\ntech_input = pd.DataFrame({'returns': gld_returns, 'gk_vol': gk_vol}).dropna()\nX_tech = tech_input.values\n\nhmm_tech = fit_hmm_best(X_tech, n_components=2, covariance_type='full', n_restarts=10)\nhigh_var_state = hmm_highest_var_state(hmm_tech)\ntech_probs = hmm_tech.predict_proba(X_tech)\ntech_regime_prob = pd.Series(tech_probs[:, high_var_state], index=tech_input.index, name='tech_trend_regime_prob')\n\n# 平均回帰zスコア（15日ウィンドウ）\ntech_z = (gld_returns - gld_returns.rolling(15).mean()) / gld_returns.rolling(15).std()\ntech_z = tech_z.clip(-4, 4)\ntech_z.name = 'tech_mean_reversion_z'\n\n# ボラティリティレジーム zスコア（60日ウィンドウ）\ngk_vol_z = (gk_vol - gk_vol.rolling(60).mean()) / gk_vol.rolling(60).std()\ngk_vol_z = gk_vol_z.clip(-4, 4)\ngk_vol_z.name = 'tech_volatility_regime'\n\ntech_submodel = pd.DataFrame({\n    'tech_trend_regime_prob': tech_regime_prob,\n    'tech_mean_reversion_z': tech_z,\n    'tech_volatility_regime': gk_vol_z,\n})\nprint(f'  テクニカルサブモデル: {len(tech_submodel)}行')"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# ================================================================\n# 3c. クロスアセットサブモデル\n# ================================================================\n# 金・銀・銅のリターンにHMM(3状態)をフィット → 市場レジーム分離\n# 出力: xasset_regime_prob（高変動レジーム確率）\n#        xasset_recession_signal（金/銅比率のz変化 = 景気後退シグナル）\n#        xasset_divergence（金-銀リターン差のz値 = 相対乖離度）\nprint('クロスアセットサブモデルを計算中...')\n\ngold_ret = gold_close.pct_change()\nsilver_ret = silver_close.pct_change()\ncopper_ret = copper_close.pct_change()\n\n# 共通日付で揃える\nxasset_df = pd.DataFrame({\n    'gold_ret': gold_ret,\n    'silver_ret': silver_ret,\n    'copper_ret': copper_ret,\n    'gold_close': gold_close,\n    'copper_close': copper_close,\n    'silver_close': silver_close,\n}).dropna()\n\n# HMM（3状態, フル共分散）: 全データでフィット\nX_xasset = xasset_df[['gold_ret', 'silver_ret', 'copper_ret']].values\nhmm_xasset = fit_hmm_best(X_xasset, n_components=3, covariance_type='full', n_restarts=10)\nhigh_var_state_xa = hmm_highest_var_state(hmm_xasset)\nxa_probs = hmm_xasset.predict_proba(X_xasset)\nxasset_regime_prob = pd.Series(xa_probs[:, high_var_state_xa], index=xasset_df.index, name='xasset_regime_prob')\n\n# 景気後退シグナル: 金/銅比率のz値の変化（金高・銅安 = リスクオフ）\ngc_ratio = xasset_df['gold_close'] / xasset_df['copper_close']\ngc_z = (gc_ratio - gc_ratio.rolling(90).mean()) / gc_ratio.rolling(90).std()\nxasset_recession = gc_z.diff().clip(-4, 4)\nxasset_recession.name = 'xasset_recession_signal'\n\n# 乖離度: 金-銀リターンスプレッドのz値（20日ウィンドウ）\ngs_diff = xasset_df['gold_ret'] - xasset_df['silver_ret']\ngs_z = (gs_diff - gs_diff.rolling(20).mean()) / gs_diff.rolling(20).std()\nxasset_divergence = gs_z.clip(-4, 4)\nxasset_divergence.name = 'xasset_divergence'\n\nxasset_submodel = pd.DataFrame({\n    'xasset_regime_prob': xasset_regime_prob,\n    'xasset_recession_signal': xasset_recession,\n    'xasset_divergence': xasset_divergence,\n})\nprint(f'  クロスアセットサブモデル: {len(xasset_submodel)}行')"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# ================================================================\n# 3d. イールドカーブサブモデル\n# ================================================================\n# Yahoo TNX/IRX/FVXを利回り代理指標として使用\n# 出力: yc_spread_velocity_z（スプレッド変化速度のz値）\n#        yc_curvature_z（カーブ曲率変化のz値）\nprint('イールドカーブサブモデルを計算中...')\n\n# Yahoo Financeの利回りデータを実際の利回り(%)に変換\ndgs10_yf = tnx['Close'] / 100.0                      # 10年国債利回り\ndgs2_yf = irx['Close'] / 100.0 * (365.0 / 91.0)     # 13週Tビル → 年率換算\ndgs5_yf = fvx['Close'] / 100.0                        # 5年国債利回り\n\nyc_df = pd.DataFrame({'dgs10': dgs10_yf, 'dgs2': dgs2_yf, 'dgs5': dgs5_yf}).dropna()\nyc_spread = yc_df['dgs10'] - yc_df['dgs2']            # 10年-2年スプレッド\nyc_curvature = yc_df['dgs5'] - 0.5 * (yc_df['dgs2'] + yc_df['dgs10'])  # バタフライ曲率\n\ndgs10_change = yc_df['dgs10'].diff()\ndgs2_change = yc_df['dgs2'].diff()\n\n# HMM（2状態, 対角共分散）: 利回り変化でレジーム分離\nyc_hmm_input = pd.DataFrame({'dgs10_chg': dgs10_change, 'dgs2_chg': dgs2_change}).dropna()\nX_yc = yc_hmm_input.values\n\n# 先頭70%で学習（未来リーク防止）\nn_train_yc = int(len(X_yc) * 0.70)\nhmm_yc = fit_hmm_best(X_yc[:n_train_yc], n_components=2, covariance_type='diag',\n                       n_restarts=5, seeds=[0, 42, 123, 456, 789])\nhigh_var_state_yc = hmm_highest_var_state(hmm_yc)\nyc_probs = hmm_yc.predict_proba(X_yc)\nyc_regime_prob = pd.Series(yc_probs[:, high_var_state_yc], index=yc_hmm_input.index, name='yc_regime_prob')\n\n# スプレッド速度z値（5日変化の30日z標準化）\nspread_change_5 = yc_spread.diff(5)\nyc_spread_vel_z = (spread_change_5 - spread_change_5.rolling(30).mean()) / spread_change_5.rolling(30).std()\nyc_spread_vel_z = yc_spread_vel_z.clip(-4, 4)\nyc_spread_vel_z.name = 'yc_spread_velocity_z'\n\n# 曲率z値（1日変化の120日z標準化）\ncurvature_change = yc_curvature.diff()\nyc_curv_z = (curvature_change - curvature_change.rolling(120).mean()) / curvature_change.rolling(120).std()\nyc_curv_z = yc_curv_z.clip(-4, 4)\nyc_curv_z.name = 'yc_curvature_z'\n\nyc_submodel = pd.DataFrame({\n    'yc_spread_velocity_z': yc_spread_vel_z,\n    'yc_curvature_z': yc_curv_z,\n})\nprint(f'  イールドカーブサブモデル: {len(yc_submodel)}行')"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# ================================================================\n# 3e. ETFフローサブモデル\n# ================================================================\n# GLD ETFの出来高パターンからHMM(4状態)で資金流入レジームを推定\n# 出力: etf_regime_prob（蓄積状態の確率 = 機関投資家の買い増し局面）\n#        etf_capital_intensity（ドル建て出来高のz値 = 資本流入強度）\n#        etf_pv_divergence（価格-出来高相関のz値 = PV乖離）\nprint('ETFフローサブモデルを計算中...')\n\ngld_vol = gld_raw['Volume']\ngld_cl = gld_raw['Close']\n\ndollar_volume = gld_cl * gld_vol                       # ドル建て出来高\nvolume_ma20 = gld_vol.rolling(20).mean()               # 20日移動平均出来高\nlog_volume_ratio = np.log(gld_vol / volume_ma20).replace([np.inf, -np.inf], 0)\ngld_ret = gld_cl.pct_change()\n\n# HMM（4状態, フル共分散）: [出来高比, 金リターン] → 蓄積/分配レジーム分離\netf_input = pd.DataFrame({'lvr': log_volume_ratio, 'gold_ret': gold_ret}).reindex(gld_raw.index)\netf_input['gold_ret'] = gold_ret.reindex(gld_raw.index)\netf_input = etf_input.dropna()\nX_etf = etf_input.values\n\n# 先頭70%で学習\nn_train_etf = int(len(X_etf) * 0.70)\nhmm_etf = fit_hmm_best(X_etf[:n_train_etf], n_components=4, covariance_type='full',\n                        n_restarts=11, seeds=list(range(42, 53)))\n\n# 蓄積状態 = 学習期間中で金リターン平均が最も高い状態\ntrain_states = hmm_etf.predict(X_etf[:n_train_etf])\ntrain_gold_ret_by_state = pd.Series(X_etf[:n_train_etf, 1]).groupby(train_states).mean()\naccum_state = train_gold_ret_by_state.idxmax()\n\netf_probs = hmm_etf.predict_proba(X_etf)\netf_regime_prob = pd.Series(etf_probs[:, accum_state], index=etf_input.index, name='etf_regime_prob')\n\n# 資本集中度 z値（60日ウィンドウ）\ncap_z = (dollar_volume - dollar_volume.rolling(60).mean()) / dollar_volume.rolling(60).std()\ncap_z = cap_z.replace([np.inf, -np.inf], 0)\ncap_z.name = 'etf_capital_intensity'\n\n# PV乖離: 価格変化と出来高変化の相関のz値\nvol_changes = gld_vol.pct_change()\nrolling_corr = gld_ret.rolling(10).corr(vol_changes)\npv_div = (rolling_corr - rolling_corr.rolling(40).mean()) / rolling_corr.rolling(40).std()\npv_div = pv_div.replace([np.inf, -np.inf], 0)\npv_div.name = 'etf_pv_divergence'\n\netf_submodel = pd.DataFrame({\n    'etf_regime_prob': etf_regime_prob,\n    'etf_capital_intensity': cap_z,\n    'etf_pv_divergence': pv_div,\n})\nprint(f'  ETFフローサブモデル: {len(etf_submodel)}行')"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# ================================================================\n# 3f. インフレ期待サブモデル\n# ================================================================\n# ブレークイーブンインフレ率(T10YIE)の変化とボラにHMM(3状態)をフィット\n# 出力: ie_regime_prob（高変動レジーム確率）\n#        ie_anchoring_z（インフレ期待のアンカリング度合い = ボラの異常度）\n#        ie_gold_sensitivity_z（インフレ期待と金リターンの短期相関z値）\nprint('インフレ期待サブモデルを計算中...')\n\nie_change = ie_raw.diff().dropna()          # BEIの日次変化\nie_vol_5d = ie_change.rolling(5).std()      # 5日ボラティリティ\n\n# HMM（3状態, フル共分散）: [BEI変化, 5日ボラ]\nie_hmm_input = pd.DataFrame({'ie_chg': ie_change, 'ie_vol': ie_vol_5d}).dropna()\nX_ie = ie_hmm_input.values\n\n# 先頭70%で学習\nn_train_ie = int(len(X_ie) * 0.70)\nhmm_ie = fit_hmm_best(X_ie[:n_train_ie], n_components=3, covariance_type='full',\n                       n_restarts=3, seeds=[42, 43, 44])\nhigh_var_state_ie = hmm_highest_var_state(hmm_ie)\nie_probs = hmm_ie.predict_proba(X_ie)\nie_regime_prob = pd.Series(ie_probs[:, high_var_state_ie], index=ie_hmm_input.index, name='ie_regime_prob')\n\n# アンカリングz値 = 5日ボラの120日z標準化（高い = インフレ期待が不安定）\nie_anchor_z = (ie_vol_5d - ie_vol_5d.rolling(120).mean()) / ie_vol_5d.rolling(120).std()\nie_anchor_z = ie_anchor_z.clip(-4, 4).replace([np.inf, -np.inf], 0)\nie_anchor_z.name = 'ie_anchoring_z'\n\n# 金感応度z値 = BEI変化と金リターンの短期相関（5日）のz標準化\ngold_ret_for_ie = gold_ret.reindex(ie_change.index)\nie_gold_corr = ie_change.rolling(5).corr(gold_ret_for_ie)\nie_sens_z = (ie_gold_corr - ie_gold_corr.rolling(40).mean()) / ie_gold_corr.rolling(40).std()\nie_sens_z = ie_sens_z.clip(-4, 4).replace([np.inf, -np.inf], 0)\nie_sens_z.name = 'ie_gold_sensitivity_z'\n\nie_submodel = pd.DataFrame({\n    'ie_regime_prob': ie_regime_prob,\n    'ie_anchoring_z': ie_anchor_z,\n    'ie_gold_sensitivity_z': ie_sens_z,\n})\nprint(f'  インフレ期待サブモデル: {len(ie_submodel)}行')"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# ================================================================\n# 3g. オプション市場サブモデル\n# ================================================================\n# SKEWインデックス（テールリスク指標）とGVZ（金ボラティリティ）の\n# 変化率にHMM(2状態)をフィット → リスクレジーム確率を抽出\n# 出力: options_risk_regime_prob（高リスクレジーム確率）\nprint('オプション市場サブモデルを計算中...')\n\nskew_change = skew_data['Close'].diff()    # SKEW日次変化\ngvz_change = gvz_data['Close'].diff()      # GVZ日次変化\n\nopt_input = pd.DataFrame({'skew_chg': skew_change, 'gvz_chg': gvz_change}).dropna()\nX_opt = opt_input.values\n\n# 先頭70%で学習\nn_train_opt = int(len(X_opt) * 0.70)\nhmm_opt = GaussianHMM(\n    n_components=2, covariance_type='full', n_iter=100, random_state=42\n)\nhmm_opt.fit(X_opt[:n_train_opt])\n\nhigh_var_state_opt = hmm_highest_var_state(hmm_opt)\nopt_probs = hmm_opt.predict_proba(X_opt)\noptions_regime_prob = pd.Series(opt_probs[:, high_var_state_opt], index=opt_input.index,\n                                 name='options_risk_regime_prob')\n\nopt_submodel = pd.DataFrame({'options_risk_regime_prob': options_regime_prob})\nprint(f'  オプション市場サブモデル: {len(opt_submodel)}行')"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# ================================================================\n# 3h. 時間コンテキストサブモデル（PyTorch Transformer）\n# ================================================================\n# 本来はTransformerモデルの重み(model.pt)で推論するが、\n# ローカルに重みファイルがないため、事前計算済みCSVまたは\n# デフォルト値 0.5（= 最大不確実性）を使用。\n# NaN補完値として0.5を使っているため、メタモデルは0.5入力に対して\n# 適切にキャリブレーション済み。\n\n# 事前計算CSVを複数のパスで探索\ntc_csv_path = os.path.join(\n    os.path.dirname(os.path.abspath('.')),\n    'data', 'dataset_upload_clean', 'temporal_context.csv'\n)\n\ntc_paths = [\n    tc_csv_path,\n    '../data/dataset_upload_clean/temporal_context.csv',\n    'data/dataset_upload_clean/temporal_context.csv',\n]\n\ntc_loaded = False\nfor p in tc_paths:\n    if os.path.exists(p):\n        tc_df = pd.read_csv(p)\n        tc_df['date'] = pd.to_datetime(tc_df['date'])\n        tc_df = tc_df.set_index('date')\n        tc_loaded = True\n        print(f'  時間コンテキスト: CSVから読込 ({p}, {len(tc_df)}行)')\n        break\n\nif not tc_loaded:\n    print('  時間コンテキスト: CSVなし → デフォルト値0.5（中立）を使用')\n    tc_df = pd.DataFrame(index=gold_close.index)\n    tc_df['temporal_context_score'] = 0.5\n\ntc_submodel = tc_df[['temporal_context_score']]"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 4. 特徴量マトリクスの組立\n5つのベース特徴量 + 8サブモデルからの19特徴量 = 合計24次元の特徴量ベクトルを構築。\nNaN補完ルール: レジーム確率→0.5, z値→0.0, 連続値→中央値"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# ================================================================\n# 4. 特徴量マトリクスの組立（メタモデル Attempt 7 と同一構成）\n# ================================================================\nprint('=' * 60)\nprint('特徴量マトリクスを組立中...')\nprint('=' * 60)\n\n# --- ベース特徴量の構築 ---\nbase_df = pd.DataFrame(index=gold_close.index)\nbase_df['gold_return_next'] = gold_return_next  # 予測ターゲット（翌日リターン%）\n\n# 原系列を取り込み（差分計算用）\nbase_df['_real_rate'] = real_rate_raw.reindex(base_df.index)\nbase_df['_dxy'] = dxy_close.reindex(base_df.index)\nbase_df['_vix'] = vix_raw.reindex(base_df.index)\nbase_df['_yield_spread'] = yield_spread.reindex(base_df.index)\nbase_df['_ie'] = ie_raw.reindex(base_df.index)\n\n# 前方補完（FRED系は営業日のみ更新のためギャップあり）\nbase_df = base_df.ffill()\n\n# 定常化のための差分変換\nbase_df['real_rate_change'] = base_df['_real_rate'].diff()       # 実質金利変化\nbase_df['dxy_change'] = base_df['_dxy'].diff()                   # ドル指数変化\nbase_df['vix'] = base_df['_vix']                                  # VIX水準（元々定常的）\nbase_df['yield_spread_change'] = base_df['_yield_spread'].diff()  # スプレッド変化\nbase_df['inflation_exp_change'] = base_df['_ie'].diff()           # BEI変化\n\n# ヘルパー列を削除\nbase_df = base_df.drop(columns=['_real_rate', '_dxy', '_vix', '_yield_spread', '_ie'])\n\n# --- サブモデル特徴量の結合 ---\nfor name, sub_df in [\n    ('vix', vix_submodel),\n    ('technical', tech_submodel),\n    ('cross_asset', xasset_submodel),\n    ('yield_curve', yc_submodel),\n    ('etf_flow', etf_submodel),\n    ('inflation_exp', ie_submodel),\n    ('options', opt_submodel),\n    ('temporal', tc_submodel),\n]:\n    base_df = base_df.join(sub_df, how='left')\n\nprint(f'結合後: {base_df.shape}')\n\n# --- 特徴量カラム定義（Attempt 7 と同一順序）---\nFEATURE_COLUMNS = [\n    'real_rate_change', 'dxy_change', 'vix', 'yield_spread_change', 'inflation_exp_change',\n    'vix_regime_probability', 'vix_mean_reversion_z', 'vix_persistence',\n    'tech_trend_regime_prob', 'tech_mean_reversion_z', 'tech_volatility_regime',\n    'xasset_regime_prob', 'xasset_recession_signal', 'xasset_divergence',\n    'yc_spread_velocity_z', 'yc_curvature_z',\n    'etf_regime_prob', 'etf_capital_intensity', 'etf_pv_divergence',\n    'ie_regime_prob', 'ie_anchoring_z', 'ie_gold_sensitivity_z',\n    'options_risk_regime_prob',\n    'temporal_context_score',\n]\nTARGET = 'gold_return_next'\n\n# --- NaN補完（学習時と同一ルール）---\n# レジーム確率 → 0.5（中立 = 「レジーム不明」）\nregime_cols = ['vix_regime_probability', 'tech_trend_regime_prob', 'xasset_regime_prob',\n               'etf_regime_prob', 'ie_regime_prob', 'options_risk_regime_prob', 'temporal_context_score']\nfor col in regime_cols:\n    if col in base_df.columns:\n        base_df[col] = base_df[col].fillna(0.5)\n\n# z値 → 0.0（平均 = 「異常なし」）\nz_cols = ['vix_mean_reversion_z', 'tech_mean_reversion_z', 'yc_spread_velocity_z',\n          'yc_curvature_z', 'etf_capital_intensity', 'etf_pv_divergence',\n          'ie_anchoring_z', 'ie_gold_sensitivity_z']\nfor col in z_cols:\n    if col in base_df.columns:\n        base_df[col] = base_df[col].fillna(0.0)\n\n# シグナル/乖離 → 0.0（中立）\ndiv_cols = ['xasset_recession_signal', 'xasset_divergence']\nfor col in div_cols:\n    if col in base_df.columns:\n        base_df[col] = base_df[col].fillna(0.0)\n\n# 連続値 → 中央値\ncont_cols = ['tech_volatility_regime', 'vix_persistence']\nfor col in cont_cols:\n    if col in base_df.columns:\n        base_df[col] = base_df[col].fillna(base_df[col].median())\n\n# ベース特徴量にNaNがある行は除外（最初の数日分）\nbase_df = base_df.dropna(subset=['real_rate_change', 'dxy_change', 'vix',\n                                   'yield_spread_change', 'inflation_exp_change'])\n\n# 全特徴量の存在確認\nmissing = [c for c in FEATURE_COLUMNS if c not in base_df.columns]\nif missing:\n    raise ValueError(f'特徴量が不足: {missing}')\n\nprint(f'最終データセット: {len(base_df)}行, {len(FEATURE_COLUMNS)}特徴量')\nprint(f'日付範囲: {base_df.index.min().strftime(\"%Y-%m-%d\")} ～ {base_df.index.max().strftime(\"%Y-%m-%d\")}')\nprint(f'残存NaN: {base_df[FEATURE_COLUMNS].isna().sum().sum()}')"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 5. XGBoostメタモデル学習（Attempt 7 アーキテクチャ）\n- 時系列分割: Train 70% / Val 15% / Test 15%（シャッフルなし）\n- ハイパーパラメータ: Attempt 2 フォールバック基準値（Optuna 100試行で検証済み）\n- Bootstrapアンサンブル: 5モデル（信頼度推定用）\n- OLSスケーリング: バリデーションセットで較正"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# ================================================================\n# 5. Train/Val/Test分割 + XGBoost学習\n# ================================================================\nprint('=' * 60)\nprint('メタモデル学習中（Attempt 7 アーキテクチャ）...')\nprint('=' * 60)\n\n# ターゲットが存在する行のみ（最終行は翌日リターンが未定義）\ntrainable = base_df.dropna(subset=[TARGET]).copy()\n\n# 時系列分割: 70/15/15（シャッフルなし = 未来リーク防止）\nn_total = len(trainable)\nn_train = int(n_total * 0.70)\nn_val = int(n_total * 0.15)\n\ntrain_data = trainable.iloc[:n_train]\nval_data = trainable.iloc[n_train:n_train + n_val]\ntest_data = trainable.iloc[n_train + n_val:]\n\nX_train = train_data[FEATURE_COLUMNS].values\ny_train = train_data[TARGET].values\nX_val = val_data[FEATURE_COLUMNS].values\ny_val = val_data[TARGET].values\nX_test = test_data[FEATURE_COLUMNS].values\ny_test = test_data[TARGET].values\n\nprint(f'Train: {len(train_data)}行 ({train_data.index[0].strftime(\"%Y-%m-%d\")} ～ {train_data.index[-1].strftime(\"%Y-%m-%d\")})')\nprint(f'Val:   {len(val_data)}行 ({val_data.index[0].strftime(\"%Y-%m-%d\")} ～ {val_data.index[-1].strftime(\"%Y-%m-%d\")})')\nprint(f'Test:  {len(test_data)}行 ({test_data.index[0].strftime(\"%Y-%m-%d\")} ～ {test_data.index[-1].strftime(\"%Y-%m-%d\")})')\n\n# --- Attempt 7 ハイパーパラメータ（Attempt 2 フォールバック値）---\n# Optuna 100試行の最良トライアル(#89)とほぼ同等の性能\nMODEL_PARAMS = {\n    'objective': 'reg:squarederror',  # 二乗誤差回帰\n    'max_depth': 2,                    # 浅い木 → 過学習抑制\n    'min_child_weight': 14,            # 最小葉サンプル数\n    'reg_lambda': 4.76,                # L2正則化\n    'reg_alpha': 3.65,                 # L1正則化\n    'subsample': 0.478,                # 行サブサンプリング\n    'colsample_bytree': 0.371,         # 列サブサンプリング\n    'learning_rate': 0.025,            # 学習率\n    'tree_method': 'hist',             # ヒストグラムベース\n    'eval_metric': 'rmse',\n    'verbosity': 0,\n    'seed': 42,\n}\n\n# プライマリモデル学習（早期停止付き）\nprint('\\nプライマリモデル学習中...')\nmodel = xgb.XGBRegressor(**MODEL_PARAMS, n_estimators=300, early_stopping_rounds=100)\nmodel.fit(X_train, y_train, eval_set=[(X_val, y_val)], verbose=False)\n\n# Bootstrapアンサンブル（5モデル: 乱数シード違い → 信頼度推定用）\nprint('Bootstrapアンサンブル学習中（5モデル）...')\nbootstrap_models = []\nfor seed in [42, 43, 44, 45, 46]:\n    params_boot = MODEL_PARAMS.copy()\n    params_boot['seed'] = seed\n    m = xgb.XGBRegressor(**params_boot, n_estimators=300, early_stopping_rounds=100)\n    m.fit(X_train, y_train, eval_set=[(X_val, y_val)], verbose=False)\n    bootstrap_models.append(m)\n\n# OLSスケーリング係数（バリデーションセットで較正）\n# 予測値を実際の変動幅にスケールするための線形回帰係数\npred_val = model.predict(X_val)\nalpha_ols = np.clip(np.sum(pred_val * y_val) / (np.sum(pred_val ** 2) + 1e-10), 0.5, 10.0)\nprint(f'OLSスケーリング係数: {alpha_ols:.3f}')\n\n# --- テストセットでのサニティチェック ---\npred_test = model.predict(X_test)\nmask = (y_test != 0) & (pred_test != 0)\ntest_da = (np.sign(pred_test[mask]) == np.sign(y_test[mask])).mean()\ntest_mae = np.mean(np.abs(pred_test * alpha_ols - y_test))\n\n# シャープレシオ（取引コスト控除後）\npositions = np.sign(pred_test)\nstrat_ret = positions * y_test / 100.0\npos_chg = np.abs(np.diff(positions, prepend=0))\nnet_ret = strat_ret - pos_chg * (COST_BPS / 10000.0)\ntest_sharpe = (net_ret.mean() / net_ret.std()) * np.sqrt(252) if net_ret.std() > 0 else 0\n\nprint(f'\\nテストセット性能:')\nprint(f'  方向的中率(DA): {test_da * 100:.2f}%')\nprint(f'  MAE(スケール後): {test_mae:.4f}%')\nprint(f'  シャープレシオ:  {test_sharpe:.2f}')\nprint(f'\\nモデル学習完了。')"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 6. 予測日の翌営業日リターンを予測"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# ================================================================\n# 6. 予測日の翌営業日リターンを予測\n# ================================================================\nprint('=' * 60)\nprint(f'{target_date.strftime(\"%Y-%m-%d\")} の予測を生成中...')\nprint('=' * 60)\n\n# 予測日（またはその直前の営業日）をデータセットから特定\navailable_dates = base_df.index[base_df.index <= target_date]\nif len(available_dates) == 0:\n    raise ValueError(f'{target_date.strftime(\"%Y-%m-%d\")} 以前のデータがありません。')\n\nactual_date = available_dates[-1]\nif actual_date != target_date:\n    print(f'注意: {target_date.strftime(\"%Y-%m-%d\")} は非営業日です。')\n    print(f'      直前の営業日 {actual_date.strftime(\"%Y-%m-%d\")} を使用します。')\n\n# 特徴量ベクトルを抽出\nX_pred = base_df.loc[[actual_date], FEATURE_COLUMNS].values\n\n# プライマリ予測\npred_raw = model.predict(X_pred)[0]             # 生の予測値\npred_scaled = pred_raw * alpha_ols               # OLSスケール後\n\n# Bootstrap予測（5モデルの予測の分散 → 信頼度推定）\nboot_preds = np.array([m.predict(X_pred)[0] for m in bootstrap_models])\nboot_mean = boot_preds.mean()\nboot_std = boot_preds.std()                      # 小さいほど高信頼\nboot_confidence = 1.0 / (1.0 + boot_std)\n\n# 方向\ndirection = 'UP' if pred_raw > 0 else 'DOWN'\ndirection_jp = '上昇' if pred_raw > 0 else '下落'\n\n# 確信度レベル（テストセットでの予測値分布に基づくパーセンタイル）\nabs_pred = abs(pred_raw)\nif abs_pred > np.percentile(np.abs(model.predict(X_test)), 80):\n    confidence_level = 'HIGH'\n    confidence_level_jp = '高'\nelif abs_pred > np.percentile(np.abs(model.predict(X_test)), 50):\n    confidence_level = 'MEDIUM'\n    confidence_level_jp = '中'\nelse:\n    confidence_level = 'LOW'\n    confidence_level_jp = '低'\n\n# 金価格コンテキスト\nlatest_gold_price = gold_close.loc[:actual_date].iloc[-1]\nexpected_price_change = latest_gold_price * pred_scaled / 100\n\nprint(f'\\n{\"=\" * 50}')\nprint(f'  基準日:           {actual_date.strftime(\"%Y-%m-%d\")}')\nprint(f'  予測対象:         翌営業日の金リターン')\nprint(f'  予測方向:         {direction} ({direction_jp})')\nprint(f'  生リターン:       {pred_raw:+.4f}%')\nprint(f'  スケール後:       {pred_scaled:+.4f}%')\nprint(f'  確信度:           {confidence_level} ({confidence_level_jp})')\nprint(f'  Bootstrap Std:    {boot_std:.4f}')\nprint(f'  Bootstrap 信頼度: {boot_confidence:.4f}')\nprint(f'  ---')\nprint(f'  現在の金価格:     ${latest_gold_price:.2f}')\nprint(f'  予測変動額:       ${expected_price_change:+.2f}')\nprint(f'  予測価格:         ${latest_gold_price + expected_price_change:.2f}')\nprint(f'{\"=\" * 50}')"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 7. ポジションサイジング\n予測の確信度に応じて、資本の5%～30%でポジションサイズを動的に調整。\n確信度スコア = 0.6 × 予測パーセンタイル + 0.4 × Bootstrap信頼度パーセンタイル"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# ================================================================\n# 7. ポジションサイジング（確信度加重）\n# ================================================================\nprint('=' * 60)\nprint('ポジションサイジング')\nprint('=' * 60)\n\n# --- ポジションサイジング戦略 ---\n# 2つの信頼度指標の加重平均でポジション比率を決定:\n#   1. |予測値|の大きさ（テストセット内でのパーセンタイル順位）\n#   2. Bootstrap一致度（5モデルの予測のばらつきの小ささ）\n\n# テストセットでのキャリブレーション\ntest_pred_abs = np.abs(model.predict(X_test))\ntest_boot_preds = np.array([m.predict(X_test) for m in bootstrap_models])\ntest_boot_std = np.std(test_boot_preds, axis=0)\ntest_boot_conf = 1.0 / (1.0 + test_boot_std)\n\n# 今回の予測のパーセンタイル順位\npred_pctile = (test_pred_abs < abs_pred).mean()        # 予測値の強さ\nconf_pctile = (test_boot_conf < boot_confidence).mean() # Bootstrap信頼度\n\n# 統合確信度スコア（0～1）\ncombined_confidence = 0.6 * pred_pctile + 0.4 * conf_pctile\n\n# ポジション比率にマッピング（MIN～MAX）\nposition_pct = MIN_POSITION_PCT + (MAX_POSITION_PCT - MIN_POSITION_PCT) * combined_confidence\nposition_value = TOTAL_CAPITAL * position_pct\n\n# COMEX金先物の契約数換算\ngold_oz_per_contract = 100  # COMEX GC: 100オンス/契約\ngold_contract_value = latest_gold_price * gold_oz_per_contract\nn_contracts = position_value / gold_contract_value if gold_contract_value > 0 else 0\n\n# 取引コスト見積もり\ntrade_cost = position_value * (COST_BPS / 10000.0)\n\n# 期待損益\nexpected_pnl = position_value * pred_scaled / 100\nexpected_pnl_after_cost = expected_pnl - trade_cost\n\nprint(f'\\n  運用資本:         ${TOTAL_CAPITAL:,.0f}')\nprint(f'  統合確信度:       {combined_confidence:.1%}')\nprint(f'    予測パーセンタイル: {pred_pctile:.1%}')\nprint(f'    Boot パーセンタイル: {conf_pctile:.1%}')\nprint(f'')\nprint(f'  ポジション比率:   {position_pct:.1%}（{position_pct * 100:.1f}%）')\nprint(f'  ポジション額:     ${position_value:,.0f}')\nprint(f'  方向:             {\"ロング（買い）\" if pred_raw > 0 else \"ショート（売り）\"}')\nprint(f'  COMEX契約数:      {n_contracts:.2f}枚（概算）')\nprint(f'')\nprint(f'  予測リターン:     {pred_scaled:+.4f}%')\nprint(f'  期待損益:         ${expected_pnl:+,.0f}')\nprint(f'  取引コスト:       ${trade_cost:,.0f}')\nprint(f'  純期待損益:       ${expected_pnl_after_cost:+,.0f}')\n\n# リスク警告\nworst_case_loss = position_value * 0.94 / 100  # MAEベース（平均予測誤差）\ntail_risk_loss = position_value * 3.0 / 100    # テールリスク（~3%の極端な変動）\nprint(f'\\n  リスク見積もり:')\nprint(f'    平均予測誤差(MAE): ${worst_case_loss:,.0f}（金0.94%変動時）')\nprint(f'    テールリスク(3%):  ${tail_risk_loss:,.0f}（極端な変動時）')"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 8. 特徴量診断\n予測日の各特徴量の値とモデルにおける重要度を表示。重要度が高い特徴量ほど予測に大きな影響を与えています。"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# ================================================================\n# 8. 特徴量の値と重要度（診断用）\n# ================================================================\nprint(f'{actual_date.strftime(\"%Y-%m-%d\")} の特徴量値:\\n')\n\nfeat_vals = base_df.loc[actual_date, FEATURE_COLUMNS]\n\n# モデルの特徴量重要度（gain）\nimportances = model.feature_importances_\nfeat_df = pd.DataFrame({\n    'Feature': FEATURE_COLUMNS,\n    'Value': feat_vals.values,\n    'Importance': importances,\n}).sort_values('Importance', ascending=False)\n\n# 重要度順に表示（バーチャートつき）\nfor _, row in feat_df.iterrows():\n    bar = '#' * int(row['Importance'] * 100)\n    print(f'  {row[\"Feature\"]:30s} = {row[\"Value\"]:+10.4f}  重要度={row[\"Importance\"]:.3f} {bar}')\n\nprint(f'\\n特徴量数: {len(FEATURE_COLUMNS)}')"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 9. 予測サマリー\n最終レポート。過去の日付を指定した場合は、実際の翌日リターンとの照合結果も表示します。"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# ================================================================\n# 9. 予測サマリー + 過去日付の場合は実績照合\n# ================================================================\nfrom datetime import timedelta\n\n# 翌営業日の推定（土日スキップ）\nnext_day = actual_date + timedelta(days=1)\nif next_day.weekday() == 5:    # 土曜 → 月曜\n    next_day += timedelta(days=2)\nelif next_day.weekday() == 6:  # 日曜 → 月曜\n    next_day += timedelta(days=1)\n\npos_direction = 'ロング（買い）' if pred_raw > 0 else 'ショート（売り）'\n\n# --- 実績照合（過去日付の場合）---\n# actual_date の翌日リターンがデータに存在するか確認\nactual_return = None\nactual_direction_jp = None\nis_correct = None\nactual_next_price = None\n\nif actual_date in base_df.index:\n    val = base_df.loc[actual_date, 'gold_return_next']\n    if not pd.isna(val):\n        actual_return = val\n        actual_direction_jp = '上昇' if actual_return > 0 else '下落'\n        # 方向の正否判定（予測と実績の符号が一致していれば正解）\n        if pred_raw != 0 and actual_return != 0:\n            is_correct = (pred_raw > 0) == (actual_return > 0)\n        # 翌日の実際の金価格\n        next_dates = gold_close.index[gold_close.index > actual_date]\n        if len(next_dates) > 0:\n            actual_next_price = gold_close.loc[next_dates[0]]\n\n# --- レポート出力 ---\nprint()\nprint('=' * 62)\nprint(f'  金価格予測レポート')\nprint('=' * 62)\nprint(f'  基準日:         {actual_date.strftime(\"%Y-%m-%d\")}（{actual_date.strftime(\"%A\")}）')\nprint(f'  予測対象日:     {next_day.strftime(\"%Y-%m-%d\")}（{next_day.strftime(\"%A\")}）')\nprint('-' * 62)\nprint(f'  予測方向:       {direction_jp}')\nprint(f'  予測リターン:   {pred_scaled:+.4f}%')\nprint(f'  確信度:         {confidence_level_jp}（{confidence_level}）')\nprint(f'  Bootstrap Std:  {boot_std:.4f}')\nprint('-' * 62)\nprint(f'  現在の金価格:   ${latest_gold_price:,.2f}')\nprint(f'  予測変動額:     ${expected_price_change:+,.2f}')\nprint(f'  予測価格:       ${latest_gold_price + expected_price_change:,.2f}')\n\n# --- 実績照合セクション（過去日付のみ表示）---\nif actual_return is not None:\n    actual_change_dollar = latest_gold_price * actual_return / 100\n    print('-' * 62)\n    print(f'  【実績照合】')\n    print(f'  実際の方向:     {actual_direction_jp}')\n    print(f'  実際のリターン: {actual_return:+.4f}%')\n    print(f'  実際の変動額:   ${actual_change_dollar:+,.2f}')\n    if actual_next_price is not None:\n        print(f'  実際の翌日価格: ${actual_next_price:,.2f}')\n    print(f'  予測誤差(MAE):  {abs(pred_scaled - actual_return):.4f}%')\n    if is_correct is not None:\n        result_mark = '○ 正解' if is_correct else '× 不正解'\n        print(f'  方向判定:       {result_mark}')\n    else:\n        print(f'  方向判定:       ー（ゼロリターンのため判定不可）')\n\nprint('-' * 62)\nprint(f'  推奨ポジション: {pos_direction}')\nprint(f'  ポジション比率: {position_pct:.1%}（資本の{position_pct*100:.1f}%）')\nprint(f'  ポジション額:   ${position_value:,.0f}')\nprint(f'  COMEX契約数:    {n_contracts:.2f}枚（概算）')\nprint(f'  取引コスト:     ${trade_cost:,.0f}（{COST_BPS}bps）')\nprint(f'  期待損益（税前）:${expected_pnl_after_cost:+,.0f}')\n\n# 実績ベースのP&L（過去日付のみ）\nif actual_return is not None:\n    actual_pnl = position_value * actual_return / 100\n    actual_pnl_net = actual_pnl - trade_cost\n    # ポジション方向を考慮（ロングなら実際のリターン、ショートなら逆）\n    if pred_raw > 0:  # ロング\n        realized_pnl = actual_pnl - trade_cost\n    else:  # ショート\n        realized_pnl = -actual_pnl - trade_cost\n    print(f'  実現損益（税前）:${realized_pnl:+,.0f}')\n\nprint('-' * 62)\nprint(f'  平均予測誤差:   0.94%（= ${worst_case_loss:,.0f}）')\nprint(f'  テールリスク:   3.0%（= ${tail_risk_loss:,.0f}）')\nprint('=' * 62)\nprint()\n\n# --- フッター ---\nif actual_return is None:\n    print('※ これは定量モデルの出力であり、投資助言ではありません。')\n    print('   過去の実績（的中率60%、Sharpe 2.46）は将来を保証しません。')\n    print('   必ずご自身のリスク管理に基づいて判断してください。')\nelse:\n    print('※ 過去日付が指定されたため、実績との照合結果を表示しました。')\n    print('   モデルの方向的中率はテストセットで約60%です。')\n    print('   個別の予測が外れることは想定内であり、統計的優位性は')\n    print('   多数の取引を通じて発現します。')"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}