# Automation Guide: Auto vs Manual Mode

## Overview

This project supports two execution modes for Kaggle training workflows:

- ğŸ¤– **Full Auto Mode** (default): Fully automated evaluation and loop control
- ğŸ‘¤ **Manual Mode**: User-controlled evaluation and decision-making

---

## ğŸ¤– Full Auto Mode (Recommended)

### Features

âœ… Background monitoring (1-minute intervals, max 3 hours)
âœ… Automatic evaluator execution (no Claude Code restart)
âœ… Automatic decision-making (attempt+1 / next feature / done)
âœ… Intelligent error handling (auto-retry / auto-skip)
âœ… Git persistence (state.json auto-update)
âœ… PC can be closed during Kaggle training

### Usage in Orchestrator

```python
from scripts.orchestrator_kaggle_handler import KaggleSubmissionHandler

handler = KaggleSubmissionHandler()
handler.submit_and_exit(
    notebook_path='notebooks/real_rate_1/',
    feature='real_rate',
    attempt=1,
    auto_mode=True  # â† Full auto mode (default)
)
```

### Command-line

```bash
# Full auto mode (default)
python scripts/orchestrator_kaggle_handler.py notebooks/real_rate_1/ real_rate 1

# Same as above (auto_mode=True is default)
python scripts/orchestrator_kaggle_handler.py notebooks/real_rate_1/ real_rate 1 --no-exit
```

### Workflow

```
1. builder_model generates Kaggle Notebook
   â†“
2. orchestrator calls handler.submit_and_exit(auto_mode=True)
   - Submits to Kaggle
   - Starts auto_resume_after_kaggle.py in background
   - Exits orchestrator
   â†“
3. auto_resume_after_kaggle.py monitors every 1 minute
   - Status check: kaggle kernels status <kernel_id>
   â†“
4. When training completes:
   - Downloads results: kaggle kernels output
   - Git commit & push
   - Runs evaluator INLINE (no Claude restart)
   - Gate 1 â†’ Gate 2 â†’ Gate 3 evaluation
   â†“
5. Automatic decision:
   - Gate 3 PASS â†’ mark completed, move to next feature
   - Gate 3 FAIL â†’ set resume_from=architect, increment attempt
   - No improvement â†’ move to next feature
   â†“
6. state.json updated, git commit & push
   â†“
7. User says "Resume from where we left off"
   - orchestrator reads state.json
   - Resumes from designated agent
```

### Error Handling

| Error Type | Action |
|------------|--------|
| `network_timeout` | Auto-retry (resubmit same notebook) |
| `yfinance_multiindex` | Set resume_from=builder_model (code fix needed) |
| `pandas_api_change` | Set resume_from=builder_model (code fix needed) |
| `out_of_memory` | Skip to next feature (OOM is fatal) |
| `unknown` | Set resume_from=builder_model (manual review) |

---

## ğŸ‘¤ Manual Mode

### Features

âœ… User controls evaluation timing
âœ… Manual review of results before decisions
âœ… No background processes
âœ… Suitable for debugging or custom workflows

### Usage in Orchestrator

```python
from scripts.orchestrator_kaggle_handler import KaggleSubmissionHandler

handler = KaggleSubmissionHandler()
handler.submit_and_exit(
    notebook_path='notebooks/real_rate_1/',
    feature='real_rate',
    attempt=1,
    auto_mode=False  # â† Manual mode
)
```

### Command-line

```bash
# Manual mode
python scripts/orchestrator_kaggle_handler.py notebooks/real_rate_1/ real_rate 1 --manual
```

### Workflow

```
1. builder_model generates Kaggle Notebook
   â†“
2. orchestrator calls handler.submit_and_exit(auto_mode=False)
   - Submits to Kaggle
   - NO background monitoring
   - Prints kernel URL
   â†“
3. User manually checks Kaggle web UI
   - Wait for "complete" status
   â†“
4. User says "Resume from where we left off"
   - orchestrator fetches results
   - evaluator runs (Gate 1/2/3)
   â†“
5. User reviews evaluation results
   - Decide next action manually
   - Continue or adjust strategy
```

---

## Comparison

| Feature | Auto Mode | Manual Mode |
|---------|-----------|-------------|
| Background monitoring | âœ… Yes (1-min intervals) | âŒ No |
| Evaluator auto-run | âœ… Yes (inline) | âŒ No (user triggers) |
| Decision-making | âœ… Automatic | ğŸ‘¤ Manual |
| Error handling | âœ… Intelligent (7 types) | ğŸ‘¤ Manual review |
| PC can be closed | âœ… Yes (monitoring continues) | âš ï¸ No effect (no monitor) |
| Git persistence | âœ… Auto commit/push | ğŸ‘¤ User commits |
| Best for | Production loops | Debugging, custom flows |

---

## Switching Modes

You can switch between modes at any time:

```python
# Start with auto mode
handler.submit_and_exit(..., auto_mode=True)

# Later, if auto-monitor fails, manually resume:
# 1. Check state.json â†’ status="waiting_training"
# 2. Manually run: python scripts/auto_resume_after_kaggle.py
# Or manually fetch and evaluate

# Start next submission with manual mode
handler.submit_and_exit(..., auto_mode=False)
```

---

## Troubleshooting

### Auto mode not starting

**Symptom**: Notebook submitted but no background monitor

**Solution**:
```bash
# Check if monitor is running
ps aux | grep auto_resume  # Unix
tasklist | findstr python  # Windows

# Manually start if needed
python scripts/auto_resume_after_kaggle.py
```

### Monitor timeout (3 hours)

**Symptom**: state.json shows `status="timeout"`

**Solution**:
```bash
# Check Kaggle web UI for actual status
# If still running, wait and manually fetch:
python scripts/kaggle_fetch_results.py <kernel_id>

# If complete, resume:
# Say "Resume from where we left off"
```

### Evaluator decision unclear

**Symptom**: Not sure why auto-evaluator chose attempt+1

**Solution**:
```bash
# Check evaluation log
cat logs/evaluation/<feature>_<attempt>_auto.json

# Review Gate 1/2/3 failures
# Adjust improvement plan in current_task.json if needed
```

---

## Best Practices

### Use Auto Mode When:
- âœ… Running production submodel loops
- âœ… Overnight or multi-day training
- âœ… Consistent failure patterns (auto-retry helps)
- âœ… You want unattended operation

### Use Manual Mode When:
- ğŸ‘¤ Debugging new architectures
- ğŸ‘¤ Testing experimental features
- ğŸ‘¤ Need to review each result carefully
- ğŸ‘¤ Custom evaluation criteria

### Hybrid Approach:
```python
# Phase 2 (submodels): Auto mode for speed
handler.submit_and_exit(..., auto_mode=True)

# Phase 3 (meta-model): Manual mode for careful tuning
handler.submit_and_exit(..., auto_mode=False)
```

---

## Implementation Details

### Auto Mode Internals

1. **Monitor Script**: `scripts/auto_resume_after_kaggle.py`
   - Class: `KaggleMonitor`
   - Check interval: 60 seconds
   - Max wait: 3 hours
   - Background process (detached)

2. **Evaluator Inline**: `KaggleMonitor.run_evaluator_inline()`
   - Simplified Gate 1/2/3 logic
   - Reads `training_result.json`
   - Writes `logs/evaluation/<feature>_<attempt>_auto.json`
   - No Claude Code restart required

3. **Decision Handler**: `KaggleMonitor.handle_evaluation_decision()`
   - Reads evaluation result
   - Updates state.json
   - Git commit & push
   - Sets next action (resume_from)

### Manual Mode Internals

1. **Submission Only**: `orchestrator_kaggle_handler.py`
   - Submits to Kaggle
   - Updates state.json to `waiting_training`
   - Git commit & push
   - Prints kernel URL
   - NO background process

2. **User Triggers Resume**:
   - User says "Resume from where we left off"
   - orchestrator detects `status="waiting_training"`
   - Calls `kaggle kernels output` to fetch results
   - Launches evaluator agent (full Claude Code session)

---

## Migration from Old System

If you're upgrading from the old `auto_resume_after_kaggle_v2.py`:

**Old system**:
```python
# v2 script (deprecated)
handler.submit_and_exit(...)  # Always auto mode
```

**New system**:
```python
# Explicit mode selection
handler.submit_and_exit(..., auto_mode=True)   # Auto
handler.submit_and_exit(..., auto_mode=False)  # Manual
```

**What changed**:
- âœ… Single script: `auto_resume_after_kaggle.py` (v2 removed)
- âœ… Mode selection: `auto_mode` parameter
- âœ… Faster checks: 60s â†’ 60s (was 300s in v1)
- âœ… Better errors: 7 error types with auto-actions
- âœ… No v2 suffix: Clean naming

---

## Summary

- **Default = Auto Mode** â†’ Use unless you need control
- **Manual Mode** â†’ Use for debugging or custom flows
- **Switch anytime** â†’ Just change `auto_mode` parameter
- **State persists** â†’ state.json tracks everything
- **Git is source of truth** â†’ Always commit & push

Choose the mode that fits your workflow, and enjoy automated or manual control as needed!
